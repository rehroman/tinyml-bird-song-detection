{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424f1f80-d145-48f5-b3f2-162591538540",
   "metadata": {},
   "source": [
    "### Full integer quantization of weights and activations into 8-bit integer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594e23c-5ff3-4f30-8d00-afdd74de1f8c",
   "metadata": {},
   "source": [
    "#### Load validation data and convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914f973f-d82a-413d-9e9b-15f8a9eaad4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 09:39:43.828390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-31 09:39:43.873706: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-31 09:39:43.874325: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 09:39:44.528186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.920_0001_270097.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.930_0002_182583971.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.940_0004_534761.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.950_0018_226391901.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.970_0017_647758.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0001_0H2uMhzSitY_520.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0002_--ivFZu-hlc_30.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0002_2RpOd9MJjyQ_10.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0003_-w4HLksto_k_30.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0003_6m5hv5BX7KU_40.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.480_0001_200614_1467_1.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.920_0103_669234.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.940_0015_139518451.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.950_0064_558294.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.970_0001_155008.wav\n",
      "...Done. Loaded 1381 validation samples and 2 labels.\n"
     ]
    }
   ],
   "source": [
    "import data as datapy\n",
    "\n",
    "val_data_path = \"/home/jovyan/cut-data/validation/\"\n",
    "\n",
    "# load validation as representative data for quantization\n",
    "print('Loading validation data...', flush=True)\n",
    "x_val, y_val, labels, file_paths_val = datapy.loadData(val_data_path)\n",
    "print('...Done. Loaded {} validation samples and {} labels.'.format(x_val.shape[0], y_val.shape[1]), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2832e-eef0-4abb-b7be-ede92734a361",
   "metadata": {},
   "source": [
    "### Load dataset generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3f7d8-d3ad-479e-9155-90b7c5dafa49",
   "metadata": {},
   "source": [
    "#### Balance the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ae4736-da5c-436a-94a2-bda04c348e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance the validation data...\n",
      "Balanced validation data:\n",
      "balanced_x_val shape: (944,)\n",
      "balanced_y_val shape: (944, 2)\n",
      "balanced_file_paths_val shape: (944,)\n",
      "...Done. Loaded 944 validation samples and 944 labels.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# balance the validation data:\n",
    "print('Balance the validation data...')\n",
    "\n",
    "y_val_indices = np.argmax(y_val, axis=1)\n",
    "\n",
    "# minimum of one class\n",
    "min_samples = min(np.bincount(y_val_indices))\n",
    "\n",
    "# reduce entries until minimum after shuffle \n",
    "balanced_x_val = []\n",
    "balanced_y_val = []\n",
    "balanced_file_paths_val = []\n",
    "for label in np.unique(y_val_indices):\n",
    "    indices = np.where(y_val_indices == label)[0]\n",
    "    np.random.shuffle(indices)  # Random order for random removal of samples\n",
    "    indices = indices[:min_samples]\n",
    "    balanced_x_val.append(x_val[indices])\n",
    "    balanced_y_val.append(y_val[indices])\n",
    "    balanced_file_paths_val.extend(file_paths_val[indices])\n",
    "\n",
    "# Combine the balanced data for all classes\n",
    "balanced_x_val = np.concatenate(balanced_x_val, axis=0)\n",
    "balanced_y_val = np.concatenate(balanced_y_val, axis=0)\n",
    "balanced_file_paths_val = np.array(balanced_file_paths_val)\n",
    "\n",
    "print('Balanced validation data:')\n",
    "print('balanced_x_val shape:', balanced_x_val.shape)\n",
    "print('balanced_y_val shape:', balanced_y_val.shape)\n",
    "print('balanced_file_paths_val shape:', balanced_file_paths_val.shape)\n",
    "\n",
    "print('...Done. Loaded {} validation samples and {} labels.'.format(balanced_x_val.shape[0], balanced_y_val.shape[0]), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4786b14-b3f4-4a0d-bd98-bff47810619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "x_val = np.array(balanced_x_val, dtype='float32')\n",
    "y_val = np.array(balanced_y_val, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819b4b75-8a70-4c53-ac3f-3ad2c799bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as modelpy\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "\n",
    "\n",
    "val_gen = modelpy.AudioDataGenerator(balanced_file_paths_val, balanced_y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c68221-60b0-4c9e-8492-35449de50a78",
   "metadata": {},
   "source": [
    "##### Load Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaba55cc-6a9c-413c-9d06-9a6331de521e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading keras model\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " INPUT (InputLayer)          [(None, 144000)]             0         []                            \n",
      "                                                                                                  \n",
      " ADVANCED_SPEC1 (LinearSpec  (None, 128, 513, 1)          1         ['INPUT[0][0]']               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " BNORM_SPEC_NOQUANT (BatchN  (None, 128, 513, 1)          4         ['ADVANCED_SPEC1[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " CONV_0 (Conv2D)             (None, 64, 257, 30)          960       ['BNORM_SPEC_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " BNORM_0 (BatchNormalizatio  (None, 64, 257, 30)          120       ['CONV_0[0][0]']              \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " ACT_0 (Activation)          (None, 64, 257, 30)          0         ['BNORM_0[0][0]']             \n",
      "                                                                                                  \n",
      " pool_0_MAX (MaxPooling2D)   (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      "                                                                                                  \n",
      " pool_0_AVG (AveragePooling  (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONCAT (Concatenate  (None, 64, 128, 60)          0         ['pool_0_MAX[0][0]',          \n",
      " )                                                                   'pool_0_AVG[0][0]']          \n",
      "                                                                                                  \n",
      " pool_0_ACT_QUANT (Activati  (None, 64, 128, 60)          0         ['pool_0_CONCAT[0][0]']       \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONV (Conv2D)        (None, 64, 128, 30)          1830      ['pool_0_ACT_QUANT[0][0]']    \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_1 (Conv2D)   (None, 32, 64, 60)           16200     ['pool_0_CONV[0][0]']         \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_1 (Conv2D)   (None, 16, 32, 240)          129600    ['BLOCK_1-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-4_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_1 (Conv2D)   (None, 16, 32, 640)          76800     ['BLOCK_2-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_1 (BatchNorma  (None, 16, 32, 640)          2560      ['BLOCK_3-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_1 (Activatio  (None, 16, 32, 640)          0         ['BLOCK_3-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-5_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-5_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-5_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-5_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-5_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-5_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-5_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-5_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-5_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-5_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-5_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_1 (Conv2D)   (None, 8, 16, 1120)          179200    ['BLOCK_3-5_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_1 (BatchNorma  (None, 8, 16, 1120)          4480      ['BLOCK_4-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_1 (Activatio  (None, 8, 16, 1120)          0         ['BLOCK_4-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BNORM_POST_NOQUANT (BatchN  (None, 4, 8, 280)            1120      ['BLOCK_4-4_ADD[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ACT_POST (Activation)       (None, 4, 8, 280)            0         ['BNORM_POST_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " POST_CONV_1 (Conv2D)        (None, 2, 6, 420)            1058400   ['ACT_POST[0][0]']            \n",
      "                                                                                                  \n",
      " POST_BN_1 (BatchNormalizat  (None, 2, 6, 420)            1680      ['POST_CONV_1[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " POST_ACT_1 (Activation)     (None, 2, 6, 420)            0         ['POST_BN_1[0][0]']           \n",
      "                                                                                                  \n",
      " GLOBAL_LME_POOL (GlobalLog  (None, 420)                  1         ['POST_ACT_1[0][0]']          \n",
      " ExpPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 2)                    842       ['GLOBAL_LME_POOL[0][0]']     \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 2)                    0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6580598 (25.10 MB)\n",
      "Trainable params: 842 (3.29 KB)\n",
      "Non-trainable params: 6579756 (25.10 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# baseline keras file which still has the activation layer in the end\n",
    "keras_baselineModel_activation_path = \"/home/jovyan/models/checkpoints_/baseline_two_class_model_softmax_activation/\"\n",
    "keras_baselineModel_activation = keras.models.load_model(keras_baselineModel_activation_path)\n",
    "\n",
    "print(\"Finished loading keras model\")\n",
    "\n",
    "keras_baselineModel_activation.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca1fb3-7ad0-43f0-989d-1736f538c590",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4e23a7-4a21-491a-b19d-62e720e5bcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversion using Quantization...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqstmllvv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqstmllvv/assets\n",
      "/opt/conda/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-08-31 09:41:47.254395: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-31 09:41:47.254481: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-31 09:41:47.255310: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpqstmllvv\n",
      "2023-08-31 09:41:47.284486: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-31 09:41:47.284541: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpqstmllvv\n",
      "2023-08-31 09:41:47.345042: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-08-31 09:41:47.372869: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-31 09:41:47.811601: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpqstmllvv\n",
      "2023-08-31 09:41:47.993210: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 737900 microseconds.\n",
      "2023-08-31 09:41:48.202522: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of val_gen: 79\n",
      "########NEW BATCH#######\n",
      "Shape of batch: 2\n",
      "########NEW ENTRY######\n",
      "Shape of input_value: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    print(\"Shape of val_gen:\", len(val_gen))\n",
    "    for batch in val_gen:\n",
    "        print(\"########NEW BATCH#######\")\n",
    "        print(\"Shape of batch:\", len(batch))\n",
    "        for input_value in batch:\n",
    "            print(\"########NEW ENTRY######\")\n",
    "            print(\"Shape of input_value:\", len(input_value))\n",
    "            yield [input_value]\n",
    "            break\n",
    "        break\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_baselineModel_activation)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "print('Starting conversion using Quantization...', flush=True)\n",
    "baseline_activation_INT8_tflite = converter.convert()\n",
    "print('...Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f5ef73-1121-4598-95af-2f6d09009cd2",
   "metadata": {},
   "source": [
    "#### Evaluate Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed352fe-7f46-44e5-b8fe-b6a816f512d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the TFLite model: 6.99 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=baseline_activation_INT8_tflite)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "tflite_size = len(baseline_activation_INT8_tflite) / (1024 * 1024)\n",
    "print(f\"Size of the TFLite model: {tflite_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c2344-08e6-4611-921c-a8b5ae7e252d",
   "metadata": {},
   "source": [
    "#### Save 8 intmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c72f756-be8d-412b-a04b-671a81e4a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the quantized model:\n",
    "tflite_model_softmax_INT8_path = \"/home/jovyan/models/checkpoints_/baseline_softmax_activation_INT8.tflite\"\n",
    "with open(tflite_model_softmax_INT8_path, \"wb\") as f:\n",
    "    f.write(baseline_activation_INT8_tflite)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914c9eb-a209-45bb-9dc3-72da7826825a",
   "metadata": {},
   "source": [
    "### Evaluate 8 int model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a30d48-03a0-403a-bbe1-6480472372c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== /home/jovyan/models/checkpoints_/baseline_softmax_activation_INT8.tflite ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the QUANTIZE op takes\n",
      "tensor #0 as input and produces tensor #158 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#431]\n",
      "  Op#0 QUANTIZE(T#0) -> [T#158]\n",
      "  Op#1 REDUCE_MIN(T#158, T#2[1]) -> [T#159]\n",
      "  Op#2 SUB(T#158, T#159) -> [T#160]\n",
      "  Op#3 DEQUANTIZE(T#160) -> [T#161]\n",
      "  Op#4 REDUCE_MAX(T#160, T#2[1]) -> [T#162]\n",
      "  Op#5 DEQUANTIZE(T#162) -> [T#163]\n",
      "  Op#6 DIV(T#161, T#163) -> [T#164]\n",
      "  Op#7 QUANTIZE(T#164) -> [T#165]\n",
      "  Op#8 SHAPE(T#165) -> [T#166]\n",
      "  Op#9 SPLIT_V(T#166, T#3[1, 1, 0], T#4[0]) -> [T#167, T#168, T#169]\n",
      "  Op#10 RESHAPE(T#168, T#5[]) -> [T#170]\n",
      "  Op#11 FLOOR_DIV(T#170, T#6[8]) -> [T#171]\n",
      "  Op#12 PACK(T#171, T#6[8]) -> [T#172]\n",
      "  Op#13 MUL(T#171, T#6[8]) -> [T#173]\n",
      "  Op#14 RESHAPE(T#173, T#7[1]) -> [T#174]\n",
      "  Op#15 CONCATENATION(T#167, T#174) -> [T#175]\n",
      "  Op#16 CONCATENATION(T#167, T#172) -> [T#176]\n",
      "  Op#17 STRIDED_SLICE(T#165, T#8[0, 0], T#175, T#9[1, 1]) -> [T#177]\n",
      "  Op#18 RESHAPE(T#177, T#176) -> [T#178]\n",
      "  Op#19 SUB(T#170, T#10[512]) -> [T#179]\n",
      "  Op#20 FLOOR_DIV(T#179, T#11[280]) -> [T#180]\n",
      "  Op#21 ADD(T#180, T#2[1]) -> [T#181]\n",
      "  Op#22 MAXIMUM(T#181, T#4[0]) -> [T#182]\n",
      "  Op#23 PACK(T#182, T#2[1]) -> [T#183]\n",
      "  Op#24 PACK(T#182, T#10[512]) -> [T#184]\n",
      "  Op#25 CONCATENATION(T#167, T#184) -> [T#185]\n",
      "  Op#26 RANGE(T#4[0], T#182, T#2[1]) -> [T#186]\n",
      "  Op#27 MUL(T#186, T#12[35]) -> [T#187]\n",
      "  Op#28 RESHAPE(T#187, T#183) -> [T#188]\n",
      "  Op#29 ADD(T#188, T#13[0, 1, 2, 3, 4, ...]) -> [T#189]\n",
      "  Op#30 GATHER(T#178, T#189) -> [T#190]\n",
      "  Op#31 RESHAPE(T#190, T#185) -> [T#191]\n",
      "  Op#32 MUL(T#191, T#157) -> [T#192]\n",
      "  Op#33 EXPAND_DIMS(T#192, T#14[-2]) -> [T#193]\n",
      "  Op#34 DEQUANTIZE(T#193) -> [T#194]\n",
      "  Op#35 RFFT2D(T#194, T#15[1, 512]) -> [T#195]\n",
      "  Op#36 SQUEEZE(T#195) -> [T#196]\n",
      "  Op#37 CAST(T#196) -> [T#197]\n",
      "  Op#38 QUANTIZE(T#197) -> [T#198]\n",
      "  Op#39 STRIDED_SLICE(T#198, T#16[0, 0, 0], T#17[0, 0, 128], T#18[1, 1, 1]) -> [T#199]\n",
      "  Op#40 MUL(T#199, T#199) -> [T#200]\n",
      "  Op#41 DEQUANTIZE(T#200) -> [T#201]\n",
      "  Op#42 POW(T#201, T#1) -> [T#202]\n",
      "  Op#43 QUANTIZE(T#202) -> [T#203]\n",
      "  Op#44 TRANSPOSE(T#203, T#19[0, 2, 1]) -> [T#204]\n",
      "  Op#45 EXPAND_DIMS(T#204, T#20[-1]) -> [T#205]\n",
      "  Op#46 MUL(T#205, T#156) -> [T#206]\n",
      "  Op#47 ADD(T#206, T#155) -> [T#207]\n",
      "  Op#48 CONV_2D(T#207, T#154, T#153[-57, 78, -18, 925, 8393, ...]) -> [T#208]\n",
      "  Op#49 AVERAGE_POOL_2D(T#208) -> [T#209]\n",
      "  Op#50 MAX_POOL_2D(T#208) -> [T#210]\n",
      "  Op#51 CONCATENATION(T#210, T#209) -> [T#211]\n",
      "  Op#52 CONV_2D(T#211, T#152, T#151[278, -4, 2995, 182, -431, ...]) -> [T#212]\n",
      "  Op#53 CONV_2D(T#212, T#150, T#149[2458, 3525, 1551, 6604, 3254, ...]) -> [T#213]\n",
      "  Op#54 LOGISTIC(T#213) -> [T#214]\n",
      "  Op#55 MUL(T#213, T#214) -> [T#215]\n",
      "  Op#56 CONV_2D(T#215, T#148, T#147[-753, -285, -1008, -817, 1120, ...]) -> [T#216]\n",
      "  Op#57 CONV_2D(T#216, T#146, T#145[-10980, -6362, 1150, 97, 4093, ...]) -> [T#217]\n",
      "  Op#58 LOGISTIC(T#217) -> [T#218]\n",
      "  Op#59 MUL(T#217, T#218) -> [T#219]\n",
      "  Op#60 CONV_2D(T#219, T#144, T#143[-1596, 2909, -4735, 4866, 1261, ...]) -> [T#220]\n",
      "  Op#61 ADD(T#220, T#216) -> [T#221]\n",
      "  Op#62 CONV_2D(T#221, T#142, T#141[7824, 5539, 7153, -4877, 11788, ...]) -> [T#222]\n",
      "  Op#63 LOGISTIC(T#222) -> [T#223]\n",
      "  Op#64 MUL(T#222, T#223) -> [T#224]\n",
      "  Op#65 CONV_2D(T#224, T#140, T#139[304, -993, -472, 2256, 244, ...]) -> [T#225]\n",
      "  Op#66 ADD(T#225, T#221) -> [T#226]\n",
      "  Op#67 CONV_2D(T#226, T#138, T#137[9237, 12132, 14131, 10294, 13771, ...]) -> [T#227]\n",
      "  Op#68 LOGISTIC(T#227) -> [T#228]\n",
      "  Op#69 MUL(T#227, T#228) -> [T#229]\n",
      "  Op#70 CONV_2D(T#229, T#136, T#135[3538, 7307, -4539, -2034, -804, ...]) -> [T#230]\n",
      "  Op#71 CONV_2D(T#230, T#134, T#133[-7909, 507, 771, -20966, 20893, ...]) -> [T#231]\n",
      "  Op#72 LOGISTIC(T#231) -> [T#232]\n",
      "  Op#73 MUL(T#231, T#232) -> [T#233]\n",
      "  Op#74 CONV_2D(T#233, T#132, T#131[-1533, 833, 592, -1296, 507, ...]) -> [T#234]\n",
      "  Op#75 ADD(T#234, T#230) -> [T#235]\n",
      "  Op#76 CONV_2D(T#235, T#130, T#129[-6433, -16956, -61, -7117, 7631, ...]) -> [T#236]\n",
      "  Op#77 LOGISTIC(T#236) -> [T#237]\n",
      "  Op#78 MUL(T#236, T#237) -> [T#238]\n",
      "  Op#79 CONV_2D(T#238, T#128, T#127[-1287, 1667, 2286, 2905, 1529, ...]) -> [T#239]\n",
      "  Op#80 ADD(T#239, T#235) -> [T#240]\n",
      "  Op#81 CONV_2D(T#240, T#126, T#125[-560, -5769, -1225, 675, -3576, ...]) -> [T#241]\n",
      "  Op#82 LOGISTIC(T#241) -> [T#242]\n",
      "  Op#83 MUL(T#241, T#242) -> [T#243]\n",
      "  Op#84 CONV_2D(T#243, T#124, T#123[-3756, -3276, 1811, -1356, 1689, ...]) -> [T#244]\n",
      "  Op#85 ADD(T#244, T#240) -> [T#245]\n",
      "  Op#86 CONV_2D(T#245, T#122, T#121[2560, -3473, 858, 461, -2591, ...]) -> [T#246]\n",
      "  Op#87 LOGISTIC(T#246) -> [T#247]\n",
      "  Op#88 MUL(T#246, T#247) -> [T#248]\n",
      "  Op#89 DEPTHWISE_CONV_2D(T#248, T#120, T#119[1017, 359, 153, 340, 686, ...]) -> [T#249]\n",
      "  Op#90 LOGISTIC(T#249) -> [T#250]\n",
      "  Op#91 MUL(T#249, T#250) -> [T#251]\n",
      "  Op#92 MEAN(T#251, T#21[1, 2]) -> [T#252]\n",
      "  Op#93 SHAPE(T#252) -> [T#253]\n",
      "  Op#94 STRIDED_SLICE(T#253, T#22[0], T#7[1], T#7[1]) -> [T#254]\n",
      "  Op#95 PACK(T#254, T#2[1], T#2[1], T#23[640]) -> [T#255]\n",
      "  Op#96 RESHAPE(T#252, T#255) -> [T#256]\n",
      "  Op#97 CONV_2D(T#256, T#118, T#113[0, 0, 0, 0, 0, ...]) -> [T#257]\n",
      "  Op#98 LOGISTIC(T#257) -> [T#258]\n",
      "  Op#99 MUL(T#257, T#258) -> [T#259]\n",
      "  Op#100 CONV_2D(T#259, T#112, T#107[0, 0, 0, 0, 0, ...]) -> [T#260]\n",
      "  Op#101 LOGISTIC(T#260) -> [T#261]\n",
      "  Op#102 MUL(T#251, T#261) -> [T#262]\n",
      "  Op#103 CONV_2D(T#262, T#106, T#105[156, -1330, -1509, -2646, -150, ...]) -> [T#263]\n",
      "  Op#104 CONV_2D(T#263, T#104, T#103[-4111, 624, 2548, -1167, -434, ...]) -> [T#264]\n",
      "  Op#105 LOGISTIC(T#264) -> [T#265]\n",
      "  Op#106 MUL(T#264, T#265) -> [T#266]\n",
      "  Op#107 DEPTHWISE_CONV_2D(T#266, T#102, T#101[45, 122, -237, 800, -933, ...]) -> [T#267]\n",
      "  Op#108 LOGISTIC(T#267) -> [T#268]\n",
      "  Op#109 MUL(T#267, T#268) -> [T#269]\n",
      "  Op#110 MEAN(T#269, T#21[1, 2]) -> [T#270]\n",
      "  Op#111 SHAPE(T#270) -> [T#271]\n",
      "  Op#112 STRIDED_SLICE(T#271, T#22[0], T#7[1], T#7[1]) -> [T#272]\n",
      "  Op#113 PACK(T#272, T#2[1], T#2[1], T#23[640]) -> [T#273]\n",
      "  Op#114 RESHAPE(T#270, T#273) -> [T#274]\n",
      "  Op#115 CONV_2D(T#274, T#100, T#114[0, 0, 0, 0, 0, ...]) -> [T#275]\n",
      "  Op#116 LOGISTIC(T#275) -> [T#276]\n",
      "  Op#117 MUL(T#275, T#276) -> [T#277]\n",
      "  Op#118 CONV_2D(T#277, T#99, T#108[0, 0, 0, 0, 0, ...]) -> [T#278]\n",
      "  Op#119 LOGISTIC(T#278) -> [T#279]\n",
      "  Op#120 MUL(T#269, T#279) -> [T#280]\n",
      "  Op#121 CONV_2D(T#280, T#98, T#97[-1130, -35, -199, 646, -377, ...]) -> [T#281]\n",
      "  Op#122 ADD(T#281, T#263) -> [T#282]\n",
      "  Op#123 CONV_2D(T#282, T#96, T#95[4957, 2580, -3496, 1603, -557, ...]) -> [T#283]\n",
      "  Op#124 LOGISTIC(T#283) -> [T#284]\n",
      "  Op#125 MUL(T#283, T#284) -> [T#285]\n",
      "  Op#126 DEPTHWISE_CONV_2D(T#285, T#94, T#93[-91, -343, -157, -791, -164, ...]) -> [T#286]\n",
      "  Op#127 LOGISTIC(T#286) -> [T#287]\n",
      "  Op#128 MUL(T#286, T#287) -> [T#288]\n",
      "  Op#129 MEAN(T#288, T#21[1, 2]) -> [T#289]\n",
      "  Op#130 SHAPE(T#289) -> [T#290]\n",
      "  Op#131 STRIDED_SLICE(T#290, T#22[0], T#7[1], T#7[1]) -> [T#291]\n",
      "  Op#132 PACK(T#291, T#2[1], T#2[1], T#23[640]) -> [T#292]\n",
      "  Op#133 RESHAPE(T#289, T#292) -> [T#293]\n",
      "  Op#134 CONV_2D(T#293, T#92, T#115[0, 0, 0, 0, 0, ...]) -> [T#294]\n",
      "  Op#135 LOGISTIC(T#294) -> [T#295]\n",
      "  Op#136 MUL(T#294, T#295) -> [T#296]\n",
      "  Op#137 CONV_2D(T#296, T#91, T#109[0, 0, 0, 0, 0, ...]) -> [T#297]\n",
      "  Op#138 LOGISTIC(T#297) -> [T#298]\n",
      "  Op#139 MUL(T#288, T#298) -> [T#299]\n",
      "  Op#140 CONV_2D(T#299, T#90, T#89[38, -63, -1043, 1190, -2401, ...]) -> [T#300]\n",
      "  Op#141 ADD(T#300, T#282) -> [T#301]\n",
      "  Op#142 CONV_2D(T#301, T#88, T#87[-1255, 7603, -811, 1029, 455, ...]) -> [T#302]\n",
      "  Op#143 LOGISTIC(T#302) -> [T#303]\n",
      "  Op#144 MUL(T#302, T#303) -> [T#304]\n",
      "  Op#145 DEPTHWISE_CONV_2D(T#304, T#86, T#85[-296, -1006, -166, -185, -140, ...]) -> [T#305]\n",
      "  Op#146 LOGISTIC(T#305) -> [T#306]\n",
      "  Op#147 MUL(T#305, T#306) -> [T#307]\n",
      "  Op#148 MEAN(T#307, T#21[1, 2]) -> [T#308]\n",
      "  Op#149 SHAPE(T#308) -> [T#309]\n",
      "  Op#150 STRIDED_SLICE(T#309, T#22[0], T#7[1], T#7[1]) -> [T#310]\n",
      "  Op#151 PACK(T#310, T#2[1], T#2[1], T#23[640]) -> [T#311]\n",
      "  Op#152 RESHAPE(T#308, T#311) -> [T#312]\n",
      "  Op#153 CONV_2D(T#312, T#84, T#116[0, 0, 0, 0, 0, ...]) -> [T#313]\n",
      "  Op#154 LOGISTIC(T#313) -> [T#314]\n",
      "  Op#155 MUL(T#313, T#314) -> [T#315]\n",
      "  Op#156 CONV_2D(T#315, T#83, T#110[0, 0, 0, 0, 0, ...]) -> [T#316]\n",
      "  Op#157 LOGISTIC(T#316) -> [T#317]\n",
      "  Op#158 MUL(T#307, T#317) -> [T#318]\n",
      "  Op#159 CONV_2D(T#318, T#82, T#81[86, -1400, -544, 946, 343, ...]) -> [T#319]\n",
      "  Op#160 ADD(T#319, T#301) -> [T#320]\n",
      "  Op#161 CONV_2D(T#320, T#80, T#79[-5793, 211, -2504, -5983, -2799, ...]) -> [T#321]\n",
      "  Op#162 LOGISTIC(T#321) -> [T#322]\n",
      "  Op#163 MUL(T#321, T#322) -> [T#323]\n",
      "  Op#164 DEPTHWISE_CONV_2D(T#323, T#78, T#77[313, -810, -9, -91, -71, ...]) -> [T#324]\n",
      "  Op#165 LOGISTIC(T#324) -> [T#325]\n",
      "  Op#166 MUL(T#324, T#325) -> [T#326]\n",
      "  Op#167 MEAN(T#326, T#21[1, 2]) -> [T#327]\n",
      "  Op#168 SHAPE(T#327) -> [T#328]\n",
      "  Op#169 STRIDED_SLICE(T#328, T#22[0], T#7[1], T#7[1]) -> [T#329]\n",
      "  Op#170 PACK(T#329, T#2[1], T#2[1], T#23[640]) -> [T#330]\n",
      "  Op#171 RESHAPE(T#327, T#330) -> [T#331]\n",
      "  Op#172 CONV_2D(T#331, T#76, T#117[0, 0, 0, 0, 0, ...]) -> [T#332]\n",
      "  Op#173 LOGISTIC(T#332) -> [T#333]\n",
      "  Op#174 MUL(T#332, T#333) -> [T#334]\n",
      "  Op#175 CONV_2D(T#334, T#75, T#111[0, 0, 0, 0, 0, ...]) -> [T#335]\n",
      "  Op#176 LOGISTIC(T#335) -> [T#336]\n",
      "  Op#177 MUL(T#326, T#336) -> [T#337]\n",
      "  Op#178 CONV_2D(T#337, T#74, T#73[-117, -287, -371, 14, -84, ...]) -> [T#338]\n",
      "  Op#179 ADD(T#338, T#320) -> [T#339]\n",
      "  Op#180 CONV_2D(T#339, T#72, T#71[-2144, -6440, -7158, -4727, -1736, ...]) -> [T#340]\n",
      "  Op#181 LOGISTIC(T#340) -> [T#341]\n",
      "  Op#182 MUL(T#340, T#341) -> [T#342]\n",
      "  Op#183 DEPTHWISE_CONV_2D(T#342, T#70, T#69[-202, 108, 216, 251, -140, ...]) -> [T#343]\n",
      "  Op#184 LOGISTIC(T#343) -> [T#344]\n",
      "  Op#185 MUL(T#343, T#344) -> [T#345]\n",
      "  Op#186 MEAN(T#345, T#21[1, 2]) -> [T#346]\n",
      "  Op#187 SHAPE(T#346) -> [T#347]\n",
      "  Op#188 STRIDED_SLICE(T#347, T#22[0], T#7[1], T#7[1]) -> [T#348]\n",
      "  Op#189 PACK(T#348, T#2[1], T#2[1], T#24[1120]) -> [T#349]\n",
      "  Op#190 RESHAPE(T#346, T#349) -> [T#350]\n",
      "  Op#191 CONV_2D(T#350, T#68, T#64[0, 0, 0, 0, 0, ...]) -> [T#351]\n",
      "  Op#192 LOGISTIC(T#351) -> [T#352]\n",
      "  Op#193 MUL(T#351, T#352) -> [T#353]\n",
      "  Op#194 CONV_2D(T#353, T#63, T#59[0, 0, 0, 0, 0, ...]) -> [T#354]\n",
      "  Op#195 LOGISTIC(T#354) -> [T#355]\n",
      "  Op#196 MUL(T#345, T#355) -> [T#356]\n",
      "  Op#197 CONV_2D(T#356, T#58, T#57[45, -795, -1864, -349, 761, ...]) -> [T#357]\n",
      "  Op#198 CONV_2D(T#357, T#56, T#55[1894, 829, 1826, -2769, -4819, ...]) -> [T#358]\n",
      "  Op#199 LOGISTIC(T#358) -> [T#359]\n",
      "  Op#200 MUL(T#358, T#359) -> [T#360]\n",
      "  Op#201 DEPTHWISE_CONV_2D(T#360, T#54, T#53[6, -320, -41, -193, 4, ...]) -> [T#361]\n",
      "  Op#202 LOGISTIC(T#361) -> [T#362]\n",
      "  Op#203 MUL(T#361, T#362) -> [T#363]\n",
      "  Op#204 MEAN(T#363, T#21[1, 2]) -> [T#364]\n",
      "  Op#205 SHAPE(T#364) -> [T#365]\n",
      "  Op#206 STRIDED_SLICE(T#365, T#22[0], T#7[1], T#7[1]) -> [T#366]\n",
      "  Op#207 PACK(T#366, T#2[1], T#2[1], T#24[1120]) -> [T#367]\n",
      "  Op#208 RESHAPE(T#364, T#367) -> [T#368]\n",
      "  Op#209 CONV_2D(T#368, T#52, T#65[0, 0, 0, 0, 0, ...]) -> [T#369]\n",
      "  Op#210 LOGISTIC(T#369) -> [T#370]\n",
      "  Op#211 MUL(T#369, T#370) -> [T#371]\n",
      "  Op#212 CONV_2D(T#371, T#51, T#60[0, 0, 0, 0, 0, ...]) -> [T#372]\n",
      "  Op#213 LOGISTIC(T#372) -> [T#373]\n",
      "  Op#214 MUL(T#363, T#373) -> [T#374]\n",
      "  Op#215 CONV_2D(T#374, T#50, T#49[-324, -191, -190, -888, -258, ...]) -> [T#375]\n",
      "  Op#216 ADD(T#375, T#357) -> [T#376]\n",
      "  Op#217 CONV_2D(T#376, T#48, T#47[-1991, -13666, -4272, 2241, -6210, ...]) -> [T#377]\n",
      "  Op#218 LOGISTIC(T#377) -> [T#378]\n",
      "  Op#219 MUL(T#377, T#378) -> [T#379]\n",
      "  Op#220 DEPTHWISE_CONV_2D(T#379, T#46, T#45[192, -75, -13, -375, 311, ...]) -> [T#380]\n",
      "  Op#221 LOGISTIC(T#380) -> [T#381]\n",
      "  Op#222 MUL(T#380, T#381) -> [T#382]\n",
      "  Op#223 MEAN(T#382, T#21[1, 2]) -> [T#383]\n",
      "  Op#224 SHAPE(T#383) -> [T#384]\n",
      "  Op#225 STRIDED_SLICE(T#384, T#22[0], T#7[1], T#7[1]) -> [T#385]\n",
      "  Op#226 PACK(T#385, T#2[1], T#2[1], T#24[1120]) -> [T#386]\n",
      "  Op#227 RESHAPE(T#383, T#386) -> [T#387]\n",
      "  Op#228 CONV_2D(T#387, T#44, T#66[0, 0, 0, 0, 0, ...]) -> [T#388]\n",
      "  Op#229 LOGISTIC(T#388) -> [T#389]\n",
      "  Op#230 MUL(T#388, T#389) -> [T#390]\n",
      "  Op#231 CONV_2D(T#390, T#43, T#61[0, 0, 0, 0, 0, ...]) -> [T#391]\n",
      "  Op#232 LOGISTIC(T#391) -> [T#392]\n",
      "  Op#233 MUL(T#382, T#392) -> [T#393]\n",
      "  Op#234 CONV_2D(T#393, T#42, T#41[733, -1263, -1186, -1574, -1184, ...]) -> [T#394]\n",
      "  Op#235 ADD(T#394, T#376) -> [T#395]\n",
      "  Op#236 CONV_2D(T#395, T#40, T#39[-14337, -548, -13828, -4150, -8390, ...]) -> [T#396]\n",
      "  Op#237 LOGISTIC(T#396) -> [T#397]\n",
      "  Op#238 MUL(T#396, T#397) -> [T#398]\n",
      "  Op#239 DEPTHWISE_CONV_2D(T#398, T#38, T#37[137, -914, 342, -637, -342, ...]) -> [T#399]\n",
      "  Op#240 LOGISTIC(T#399) -> [T#400]\n",
      "  Op#241 MUL(T#399, T#400) -> [T#401]\n",
      "  Op#242 MEAN(T#401, T#21[1, 2]) -> [T#402]\n",
      "  Op#243 SHAPE(T#402) -> [T#403]\n",
      "  Op#244 STRIDED_SLICE(T#403, T#22[0], T#7[1], T#7[1]) -> [T#404]\n",
      "  Op#245 PACK(T#404, T#2[1], T#2[1], T#24[1120]) -> [T#405]\n",
      "  Op#246 RESHAPE(T#402, T#405) -> [T#406]\n",
      "  Op#247 CONV_2D(T#406, T#36, T#67[0, 0, 0, 0, 0, ...]) -> [T#407]\n",
      "  Op#248 LOGISTIC(T#407) -> [T#408]\n",
      "  Op#249 MUL(T#407, T#408) -> [T#409]\n",
      "  Op#250 CONV_2D(T#409, T#35, T#62[0, 0, 0, 0, 0, ...]) -> [T#410]\n",
      "  Op#251 LOGISTIC(T#410) -> [T#411]\n",
      "  Op#252 MUL(T#401, T#411) -> [T#412]\n",
      "  Op#253 CONV_2D(T#412, T#34, T#33[-3242, -8540, -1482, -3508, -3581, ...]) -> [T#413]\n",
      "  Op#254 ADD(T#413, T#395) -> [T#414]\n",
      "  Op#255 MUL(T#414, T#32) -> [T#415]\n",
      "  Op#256 ADD(T#415, T#31) -> [T#416]\n",
      "  Op#257 CONV_2D(T#416, T#30, T#29[37795, 6349, 44074, 53959, -4670, ...]) -> [T#417]\n",
      "  Op#258 REDUCE_MAX(T#417, T#21[1, 2]) -> [T#418]\n",
      "  Op#259 REDUCE_MAX(T#417, T#21[1, 2]) -> [T#419]\n",
      "  Op#260 SUB(T#417, T#418) -> [T#420]\n",
      "  Op#261 MUL(T#420, T#28) -> [T#421]\n",
      "  Op#262 EXP(T#421) -> [T#422]\n",
      "  Op#263 MEAN(T#422, T#21[1, 2]) -> [T#423]\n",
      "  Op#264 DEQUANTIZE(T#423) -> [T#424]\n",
      "  Op#265 LOG(T#424) -> [T#425]\n",
      "  Op#266 QUANTIZE(T#425) -> [T#426]\n",
      "  Op#267 MUL(T#426, T#27) -> [T#427]\n",
      "  Op#268 ADD(T#427, T#419) -> [T#428]\n",
      "  Op#269 FULLY_CONNECTED(T#428, T#26, T#25[661, -746]) -> [T#429]\n",
      "  Op#270 SOFTMAX(T#429) -> [T#430]\n",
      "  Op#271 DEQUANTIZE(T#430) -> [T#431]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_INPUT:0) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#1(truediv_1;truediv_1) shape:[], type:FLOAT32 RO 4 bytes, buffer: 2, data:[0.262867]\n",
      "  T#2(model_1/BLOCK_3-1_SE_RESHAPE/Reshape/shape/1) shape:[], type:INT32 RO 4 bytes, buffer: 3, data:[1]\n",
      "  T#3(stft/frame/packed;stft/frame/packed) shape:[3], type:INT32 RO 12 bytes, buffer: 4, data:[1, 1, 0]\n",
      "  T#4(stft/frame/Maximum/x;stft/frame/Maximum/x) shape:[], type:INT32 RO 4 bytes, buffer: 5, data:[0]\n",
      "  T#5(stft/frame/Reshape/shape_1;stft/frame/Reshape/shape_1) shape:[0], type:INT32\n",
      "  T#6(stft/frame/concat_1/values_1/1;stft/frame/concat_1/values_1/1) shape:[], type:INT32 RO 4 bytes, buffer: 7, data:[8]\n",
      "  T#7(model_1/BLOCK_3-1_SE_RESHAPE/strided_slice/stack_1) shape:[1], type:INT32 RO 4 bytes, buffer: 3, data:[1]\n",
      "  T#8(stft/frame/zeros_like;stft/frame/zeros_like) shape:[2], type:INT32 RO 8 bytes, buffer: 9, data:[0, 0]\n",
      "  T#9(stft/frame/ones_like;stft/frame/ones_like) shape:[2], type:INT32 RO 8 bytes, buffer: 10, data:[1, 1]\n",
      "  T#10(stft/frame_length;stft/frame_length) shape:[], type:INT32 RO 4 bytes, buffer: 11, data:[512]\n",
      "  T#11(stft/frame_step;stft/frame_step) shape:[], type:INT32 RO 4 bytes, buffer: 12, data:[280]\n",
      "  T#12(stft/frame/floordiv_2;stft/frame/floordiv_2) shape:[], type:INT32 RO 4 bytes, buffer: 13, data:[35]\n",
      "  T#13(stft/frame/Reshape_3;stft/frame/Reshape_3) shape:[1, 64], type:INT32 RO 256 bytes, buffer: 14, data:[0, 1, 2, 3, 4, ...]\n",
      "  T#14(stft/rfft;stft/rfft) shape:[], type:INT32 RO 4 bytes, buffer: 15, data:[-2]\n",
      "  T#15(stft/rfft;stft/rfft1) shape:[2], type:INT32 RO 8 bytes, buffer: 16, data:[1, 512]\n",
      "  T#16(strided_slice/stack;strided_slice/stack) shape:[3], type:INT32 RO 12 bytes, buffer: 17, data:[0, 0, 0]\n",
      "  T#17(strided_slice/stack_1;strided_slice/stack_1) shape:[3], type:INT32 RO 12 bytes, buffer: 18, data:[0, 0, 128]\n",
      "  T#18(strided_slice/stack_2;strided_slice/stack_2) shape:[3], type:INT32 RO 12 bytes, buffer: 19, data:[1, 1, 1]\n",
      "  T#19(transpose/perm;transpose/perm) shape:[3], type:INT32 RO 12 bytes, buffer: 20, data:[0, 2, 1]\n",
      "  T#20(ExpandDims/dim;ExpandDims/dim) shape:[], type:INT32 RO 4 bytes, buffer: 21, data:[-1]\n",
      "  T#21(model_1/BLOCK_3-1_SE_AVG_POOL_1/Mean/reduction_indices) shape:[2], type:INT32 RO 8 bytes, buffer: 22, data:[1, 2]\n",
      "  T#22(model_1/BLOCK_3-1_SE_RESHAPE/strided_slice/stack) shape:[1], type:INT32 RO 4 bytes, buffer: 5, data:[0]\n",
      "  T#23(model_1/BLOCK_3-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 24, data:[640]\n",
      "  T#24(model_1/BLOCK_4-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 25, data:[1120]\n",
      "  T#25(model_1/dense/BiasAdd/ReadVariableOp) shape:[2], type:INT32 RO 8 bytes, buffer: 26, data:[661, -746]\n",
      "  T#26(model_1/dense/MatMul) shape:[2, 420], type:INT8 RO 840 bytes, buffer: 27, data:[., 5, F, S, ., ...]\n",
      "  T#27(truediv;truediv;ReadVariableOp;ReadVariableOp) shape:[1], type:INT8 RO 1 bytes, buffer: 28, data:[.]\n",
      "  T#28(ReadVariableOp;ReadVariableOp) shape:[1], type:INT8 RO 1 bytes, buffer: 28, data:[.]\n",
      "  T#29(model_1/POST_BN_1/FusedBatchNormV3) shape:[420], type:INT32 RO 1680 bytes, buffer: 30, data:[37795, 6349, 44074, 53959, -4670, ...]\n",
      "  T#30(model_1/POST_CONV_1/Conv2D) shape:[420, 3, 3, 280], type:INT8 RO 1058400 bytes, buffer: 31, data:[., ., 0, 8, 7, ...]\n",
      "  T#31(model_1/BNORM_POST_NOQUANT/FusedBatchNormV31) shape:[280], type:INT8 RO 280 bytes, buffer: 32, data:[., ., ., ., ., ...]\n",
      "  T#32(model_1/BNORM_POST_NOQUANT/FusedBatchNormV3) shape:[280], type:INT8 RO 280 bytes, buffer: 33, data:[., ., ., ., ., ...]\n",
      "  T#33(model_1/BLOCK_4-4_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 34, data:[-3242, -8540, -1482, -3508, -3581, ...]\n",
      "  T#34(model_1/BLOCK_4-4_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 35, data:[., ., \n",
      ", ., ., ...]\n",
      "  T#35(model_1/BLOCK_4-4_SE_CONV_2/Conv2D1) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 36, data:[., ., ., ., ., ...]\n",
      "  T#36(model_1/BLOCK_4-4_SE_CONV_1/Conv2D1) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 37, data:[., ., ., ., ., ...]\n",
      "  T#37(model_1/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 38, data:[137, -914, 342, -637, -342, ...]\n",
      "  T#38(model_1/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-4_CONV_2/depthwise;model_1/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 39, data:[., ., ., ., ., ...]\n",
      "  T#39(model_1/BLOCK_4-4_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 40, data:[-14337, -548, -13828, -4150, -8390, ...]\n",
      "  T#40(model_1/BLOCK_4-4_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:INT8 RO 313600 bytes, buffer: 41, data:[X, ., ., ., ., ...]\n",
      "  T#41(model_1/BLOCK_4-3_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 42, data:[733, -1263, -1186, -1574, -1184, ...]\n",
      "  T#42(model_1/BLOCK_4-3_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 43, data:[., ., ., \n",
      ", ., ...]\n",
      "  T#43(model_1/BLOCK_4-3_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 44, data:[F, ., ., ., ., ...]\n",
      "  T#44(model_1/BLOCK_4-3_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 45, data:[., ., ., ., ., ...]\n",
      "  T#45(model_1/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 46, data:[192, -75, -13, -375, 311, ...]\n",
      "  T#46(model_1/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-3_CONV_2/depthwise;model_1/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 47, data:[., +, ., E, 5, ...]\n",
      "  T#47(model_1/BLOCK_4-3_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 48, data:[-1991, -13666, -4272, 2241, -6210, ...]\n",
      "  T#48(model_1/BLOCK_4-3_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:INT8 RO 313600 bytes, buffer: 49, data:[(, ., ., B, ., ...]\n",
      "  T#49(model_1/BLOCK_4-2_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 50, data:[-324, -191, -190, -888, -258, ...]\n",
      "  T#50(model_1/BLOCK_4-2_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 51, data:[., ., \n",
      ", ., !, ...]\n",
      "  T#51(model_1/BLOCK_4-2_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 52, data:[., ., ., <, Q, ...]\n",
      "  T#52(model_1/BLOCK_4-2_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 53, data:[., ., ., ,, ., ...]\n",
      "  T#53(model_1/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 54, data:[6, -320, -41, -193, 4, ...]\n",
      "  T#54(model_1/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-2_CONV_2/depthwise;model_1/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 55, data:[., ., ., ., ., ...]\n",
      "  T#55(model_1/BLOCK_4-2_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 56, data:[1894, 829, 1826, -2769, -4819, ...]\n",
      "  T#56(model_1/BLOCK_4-2_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:INT8 RO 313600 bytes, buffer: 57, data:[/, ., /, ., ., ...]\n",
      "  T#57(model_1/BLOCK_4-1_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 58, data:[45, -795, -1864, -349, 761, ...]\n",
      "  T#58(model_1/BLOCK_4-1_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 59, data:[;, ., ., ., ., ...]\n",
      "  T#59(model_1/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1120], type:INT32 RO 4480 bytes, buffer: 60, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#60(model_1/BLOCK_4-4_SE_CONV_2/Conv2D2) shape:[1120], type:INT32 RO 4480 bytes, buffer: 60, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#61(model_1/BLOCK_4-4_SE_CONV_2/Conv2D3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 60, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#62(model_1/BLOCK_4-4_SE_CONV_2/Conv2D4) shape:[1120], type:INT32 RO 4480 bytes, buffer: 60, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#63(model_1/BLOCK_4-1_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 64, data:[., ., ., ., ., ...]\n",
      "  T#64(model_1/BLOCK_4-4_SE_CONV_1/Conv2D) shape:[70], type:INT32 RO 280 bytes, buffer: 65, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#65(model_1/BLOCK_4-4_SE_CONV_1/Conv2D2) shape:[70], type:INT32 RO 280 bytes, buffer: 65, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#66(model_1/BLOCK_4-4_SE_CONV_1/Conv2D3) shape:[70], type:INT32 RO 280 bytes, buffer: 65, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#67(model_1/BLOCK_4-4_SE_CONV_1/Conv2D4) shape:[70], type:INT32 RO 280 bytes, buffer: 65, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#68(model_1/BLOCK_4-1_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 69, data:[., ., ., ., ., ...]\n",
      "  T#69(model_1/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 70, data:[-202, 108, 216, 251, -140, ...]\n",
      "  T#70(model_1/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-1_CONV_2/depthwise;model_1/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 71, data:[., ., i, ., ., ...]\n",
      "  T#71(model_1/BLOCK_4-1_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 72, data:[-2144, -6440, -7158, -4727, -1736, ...]\n",
      "  T#72(model_1/BLOCK_4-1_CONV_1/Conv2D) shape:[1120, 1, 1, 160], type:INT8 RO 179200 bytes, buffer: 73, data:[., #, a, ., ., ...]\n",
      "  T#73(model_1/BLOCK_3-5_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 74, data:[-117, -287, -371, 14, -84, ...]\n",
      "  T#74(model_1/BLOCK_3-5_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 75, data:[., ., ., ., ., ...]\n",
      "  T#75(model_1/BLOCK_3-5_SE_CONV_2/Conv2D1) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 76, data:[., !, ., ., ., ...]\n",
      "  T#76(model_1/BLOCK_3-5_SE_CONV_1/Conv2D1) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 77, data:[', ., ., ., ., ...]\n",
      "  T#77(model_1/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 78, data:[313, -810, -9, -91, -71, ...]\n",
      "  T#78(model_1/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-5_CONV_2/depthwise;model_1/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 79, data:[7, ., ., ., N, ...]\n",
      "  T#79(model_1/BLOCK_3-5_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 80, data:[-5793, 211, -2504, -5983, -2799, ...]\n",
      "  T#80(model_1/BLOCK_3-5_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 81, data:[., ., ., ., ., ...]\n",
      "  T#81(model_1/BLOCK_3-4_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 82, data:[86, -1400, -544, 946, 343, ...]\n",
      "  T#82(model_1/BLOCK_3-4_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 83, data:[., ., ., ., ., ...]\n",
      "  T#83(model_1/BLOCK_3-4_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 84, data:[., <, ., ., &, ...]\n",
      "  T#84(model_1/BLOCK_3-4_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 85, data:[., ., ., ., ., ...]\n",
      "  T#85(model_1/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 86, data:[-296, -1006, -166, -185, -140, ...]\n",
      "  T#86(model_1/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-4_CONV_2/depthwise;model_1/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 87, data:[., ., ., ., ., ...]\n",
      "  T#87(model_1/BLOCK_3-4_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 88, data:[-1255, 7603, -811, 1029, 455, ...]\n",
      "  T#88(model_1/BLOCK_3-4_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 89, data:[., ., ., ., ., ...]\n",
      "  T#89(model_1/BLOCK_3-3_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 90, data:[38, -63, -1043, 1190, -2401, ...]\n",
      "  T#90(model_1/BLOCK_3-3_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 91, data:[5, ., ., ., ., ...]\n",
      "  T#91(model_1/BLOCK_3-3_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 92, data:[., ., ., ., ., ...]\n",
      "  T#92(model_1/BLOCK_3-3_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 93, data:[., ., ., ., \n",
      ", ...]\n",
      "  T#93(model_1/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 94, data:[-91, -343, -157, -791, -164, ...]\n",
      "  T#94(model_1/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-3_CONV_2/depthwise;model_1/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 95, data:[., ., ., ., ., ...]\n",
      "  T#95(model_1/BLOCK_3-3_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 96, data:[4957, 2580, -3496, 1603, -557, ...]\n",
      "  T#96(model_1/BLOCK_3-3_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 97, data:[., ., ., ., ., ...]\n",
      "  T#97(model_1/BLOCK_3-2_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 98, data:[-1130, -35, -199, 646, -377, ...]\n",
      "  T#98(model_1/BLOCK_3-2_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 99, data:[., ., \", &, ., ...]\n",
      "  T#99(model_1/BLOCK_3-2_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 100, data:[., ., ., ., ., ...]\n",
      "  T#100(model_1/BLOCK_3-2_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 101, data:[\", ., 1, ., -, ...]\n",
      "  T#101(model_1/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 102, data:[45, 122, -237, 800, -933, ...]\n",
      "  T#102(model_1/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-2_CONV_2/depthwise;model_1/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 103, data:[#, ., ., ., ., ...]\n",
      "  T#103(model_1/BLOCK_3-2_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 104, data:[-4111, 624, 2548, -1167, -434, ...]\n",
      "  T#104(model_1/BLOCK_3-2_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 105, data:[>, ., ., ., ., ...]\n",
      "  T#105(model_1/BLOCK_3-1_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 106, data:[156, -1330, -1509, -2646, -150, ...]\n",
      "  T#106(model_1/BLOCK_3-1_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 107, data:[/, ., ., ., (, ...]\n",
      "  T#107(model_1/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[640], type:INT32 RO 2560 bytes, buffer: 108, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#108(model_1/BLOCK_3-5_SE_CONV_2/Conv2D2) shape:[640], type:INT32 RO 2560 bytes, buffer: 108, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#109(model_1/BLOCK_3-5_SE_CONV_2/Conv2D3) shape:[640], type:INT32 RO 2560 bytes, buffer: 108, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#110(model_1/BLOCK_3-5_SE_CONV_2/Conv2D4) shape:[640], type:INT32 RO 2560 bytes, buffer: 108, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#111(model_1/BLOCK_3-5_SE_CONV_2/Conv2D5) shape:[640], type:INT32 RO 2560 bytes, buffer: 108, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#112(model_1/BLOCK_3-1_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 113, data:[G, s, >, ., ., ...]\n",
      "  T#113(model_1/BLOCK_3-5_SE_CONV_1/Conv2D) shape:[40], type:INT32 RO 160 bytes, buffer: 114, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#114(model_1/BLOCK_3-5_SE_CONV_1/Conv2D2) shape:[40], type:INT32 RO 160 bytes, buffer: 114, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#115(model_1/BLOCK_3-5_SE_CONV_1/Conv2D3) shape:[40], type:INT32 RO 160 bytes, buffer: 114, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#116(model_1/BLOCK_3-5_SE_CONV_1/Conv2D4) shape:[40], type:INT32 RO 160 bytes, buffer: 114, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#117(model_1/BLOCK_3-5_SE_CONV_1/Conv2D5) shape:[40], type:INT32 RO 160 bytes, buffer: 114, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#118(model_1/BLOCK_3-1_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 119, data:[., .,  , ., ., ...]\n",
      "  T#119(model_1/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 120, data:[1017, 359, 153, 340, 686, ...]\n",
      "  T#120(model_1/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-1_CONV_2/depthwise;model_1/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 121, data:[., d, ., ., J, ...]\n",
      "  T#121(model_1/BLOCK_3-1_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 122, data:[2560, -3473, 858, 461, -2591, ...]\n",
      "  T#122(model_1/BLOCK_3-1_CONV_1/Conv2D) shape:[640, 1, 1, 120], type:INT8 RO 76800 bytes, buffer: 123, data:[;, ., O, ?, v, ...]\n",
      "  T#123(model_1/BLOCK_2-4_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 124, data:[-3756, -3276, 1811, -1356, 1689, ...]\n",
      "  T#124(model_1/BLOCK_2-4_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 125, data:[I, ., ., ., ., ...]\n",
      "  T#125(model_1/BLOCK_2-4_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 126, data:[-560, -5769, -1225, 675, -3576, ...]\n",
      "  T#126(model_1/BLOCK_2-4_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:INT8 RO 259200 bytes, buffer: 127, data:[., ., !, ., ., ...]\n",
      "  T#127(model_1/BLOCK_2-3_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 128, data:[-1287, 1667, 2286, 2905, 1529, ...]\n",
      "  T#128(model_1/BLOCK_2-3_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 129, data:[., ., [, ,, J, ...]\n",
      "  T#129(model_1/BLOCK_2-3_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 130, data:[-6433, -16956, -61, -7117, 7631, ...]\n",
      "  T#130(model_1/BLOCK_2-3_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:INT8 RO 259200 bytes, buffer: 131, data:[., ., ., ., ., ...]\n",
      "  T#131(model_1/BLOCK_2-2_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 132, data:[-1533, 833, 592, -1296, 507, ...]\n",
      "  T#132(model_1/BLOCK_2-2_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 133, data:[., ., ., ., ., ...]\n",
      "  T#133(model_1/BLOCK_2-2_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 134, data:[-7909, 507, 771, -20966, 20893, ...]\n",
      "  T#134(model_1/BLOCK_2-2_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:INT8 RO 259200 bytes, buffer: 135, data:[., ., ', ., ., ...]\n",
      "  T#135(model_1/BLOCK_2-1_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 136, data:[3538, 7307, -4539, -2034, -804, ...]\n",
      "  T#136(model_1/BLOCK_2-1_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 137, data:[., ., ., ., ., ...]\n",
      "  T#137(model_1/BLOCK_2-1_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 138, data:[9237, 12132, 14131, 10294, 13771, ...]\n",
      "  T#138(model_1/BLOCK_2-1_CONV_1/Conv2D) shape:[240, 3, 3, 60], type:INT8 RO 129600 bytes, buffer: 139, data:[., ., ', ., ., ...]\n",
      "  T#139(model_1/BLOCK_1-3_BN_3/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 140, data:[304, -993, -472, 2256, 244, ...]\n",
      "  T#140(model_1/BLOCK_1-3_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:INT8 RO 3600 bytes, buffer: 141, data:[., ., ., ., ., ...]\n",
      "  T#141(model_1/BLOCK_1-3_BN_1/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 142, data:[7824, 5539, 7153, -4877, 11788, ...]\n",
      "  T#142(model_1/BLOCK_1-3_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:INT8 RO 32400 bytes, buffer: 143, data:[\n",
      ", #, ., ., ), ...]\n",
      "  T#143(model_1/BLOCK_1-2_BN_3/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 144, data:[-1596, 2909, -4735, 4866, 1261, ...]\n",
      "  T#144(model_1/BLOCK_1-2_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:INT8 RO 3600 bytes, buffer: 145, data:[., ., ., ., ., ...]\n",
      "  T#145(model_1/BLOCK_1-2_BN_1/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 146, data:[-10980, -6362, 1150, 97, 4093, ...]\n",
      "  T#146(model_1/BLOCK_1-2_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:INT8 RO 32400 bytes, buffer: 147, data:[., ., ., ., ., ...]\n",
      "  T#147(model_1/BLOCK_1-1_BN_3/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 148, data:[-753, -285, -1008, -817, 1120, ...]\n",
      "  T#148(model_1/BLOCK_1-1_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:INT8 RO 3600 bytes, buffer: 149, data:[., ., K, &, ., ...]\n",
      "  T#149(model_1/BLOCK_1-1_BN_1/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 150, data:[2458, 3525, 1551, 6604, 3254, ...]\n",
      "  T#150(model_1/BLOCK_1-1_CONV_1/Conv2D) shape:[60, 3, 3, 30], type:INT8 RO 16200 bytes, buffer: 151, data:[., ), ., ., ., ...]\n",
      "  T#151(model_1/pool_0_CONV/BiasAdd/ReadVariableOp) shape:[30], type:INT32 RO 120 bytes, buffer: 152, data:[278, -4, 2995, 182, -431, ...]\n",
      "  T#152(model_1/pool_0_CONV/Conv2D) shape:[30, 1, 1, 60], type:INT8 RO 1800 bytes, buffer: 153, data:[4, ., ., \n",
      ", ., ...]\n",
      "  T#153(model_1/BNORM_0/FusedBatchNormV3) shape:[30], type:INT32 RO 120 bytes, buffer: 154, data:[-57, 78, -18, 925, 8393, ...]\n",
      "  T#154(model_1/CONV_0/Conv2D) shape:[30, 4, 8, 1], type:INT8 RO 960 bytes, buffer: 155, data:[., ., ., ., ., ...]\n",
      "  T#155(model_1/BNORM_SPEC_NOQUANT/FusedBatchNormV31) shape:[1], type:INT8 RO 1 bytes, buffer: 156, data:[.]\n",
      "  T#156(model_1/BNORM_SPEC_NOQUANT/FusedBatchNormV3) shape:[1], type:INT8 RO 1 bytes, buffer: 28, data:[.]\n",
      "  T#157(stft/hann_window/sub_2;stft/hann_window/sub_2) shape:[512], type:INT8 RO 512 bytes, buffer: 158, data:[., ., ., ., ., ...]\n",
      "  T#158(tfl.quantize) shape_signature:[-1, 144000], type:INT8\n",
      "  T#159(Min;Min) shape_signature:[-1, 1], type:INT8\n",
      "  T#160(Sub;Sub) shape_signature:[-1, 144000], type:INT8\n",
      "  T#161(tfl.dequantize) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#162(Max;Max) shape_signature:[-1, 1], type:INT8\n",
      "  T#163(Max;Max1) shape_signature:[-1, 1], type:FLOAT32\n",
      "  T#164(truediv;truediv) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#165(tfl.quantize1) shape_signature:[-1, 144000], type:INT8\n",
      "  T#166(stft/frame/Shape;stft/frame/Shape) shape:[2], type:INT32\n",
      "  T#167(stft/frame/split;stft/frame/split;stft/frame/split;stft/frame/split1;stft/frame/split;stft/frame/split2) shape:[1], type:INT32\n",
      "  T#168(stft/frame/split;stft/frame/split;stft/frame/split;stft/frame/split1;stft/frame/split;stft/frame/split21) shape:[1], type:INT32\n",
      "  T#169(stft/frame/split;stft/frame/split;stft/frame/split;stft/frame/split1;stft/frame/split;stft/frame/split22) shape:[0], type:INT32\n",
      "  T#170(stft/frame/Reshape;stft/frame/Reshape) shape:[], type:INT32\n",
      "  T#171(stft/frame/floordiv_3;stft/frame/floordiv_3) shape:[], type:INT32\n",
      "  T#172(stft/frame/concat_1/values_1;stft/frame/concat_1/values_1) shape:[2], type:INT32\n",
      "  T#173(stft/frame/mul;stft/frame/mul) shape:[], type:INT32\n",
      "  T#174(stft/frame/concat/values_1;stft/frame/concat/values_1) shape:[1], type:INT32\n",
      "  T#175(stft/frame/concat;stft/frame/concat) shape:[2], type:INT32\n",
      "  T#176(stft/frame/concat_1;stft/frame/concat_1) shape:[3], type:INT32\n",
      "  T#177(stft/frame/StridedSlice;stft/frame/StridedSlice) shape_signature:[-1, -1], type:INT8\n",
      "  T#178(stft/frame/Reshape_1;stft/frame/Reshape_1) shape_signature:[-1, -1, 8], type:INT8\n",
      "  T#179(stft/frame/sub_2;stft/frame/sub_2) shape:[], type:INT32\n",
      "  T#180(stft/frame/floordiv;stft/frame/floordiv) shape:[], type:INT32\n",
      "  T#181(stft/frame/add;stft/frame/add) shape:[], type:INT32\n",
      "  T#182(stft/frame/Maximum;stft/frame/Maximum) shape:[], type:INT32\n",
      "  T#183(stft/frame/Reshape_2/shape;stft/frame/Reshape_2/shape) shape:[2], type:INT32\n",
      "  T#184(stft/frame/concat_2/values_1;stft/frame/concat_2/values_1) shape:[2], type:INT32\n",
      "  T#185(stft/frame/concat_2;stft/frame/concat_2) shape:[3], type:INT32\n",
      "  T#186(stft/frame/range_1;stft/frame/range_1) shape_signature:[-1], type:INT32\n",
      "  T#187(stft/frame/mul_1;stft/frame/mul_1) shape_signature:[-1], type:INT32\n",
      "  T#188(stft/frame/Reshape_2;stft/frame/Reshape_2) shape_signature:[-1, 1], type:INT32\n",
      "  T#189(stft/frame/add_1;stft/frame/add_1) shape_signature:[-1, 64], type:INT32\n",
      "  T#190(stft/frame/GatherV2;stft/frame/GatherV2;model_1/BLOCK_3-1_SE_RESHAPE/Reshape/shape/1) shape_signature:[-1, -1, 64, 8], type:INT8\n",
      "  T#191(stft/frame/Reshape_4;stft/frame/Reshape_4) shape_signature:[-1, -1, 512], type:INT8\n",
      "  T#192(stft/mul;stft/mul) shape_signature:[-1, -1, 512], type:INT8\n",
      "  T#193(stft/rfft;stft/rfft2) shape_signature:[-1, -1, 1, 512], type:INT8\n",
      "  T#194(stft/rfft;stft/rfft21) shape_signature:[-1, -1, 1, 512], type:FLOAT32\n",
      "  T#195(stft/rfft;stft/rfft3) shape_signature:[-1, -1, 1, 257], type:COMPLEX64\n",
      "  T#196(stft/rfft;stft/rfft4) shape_signature:[-1, -1, 257], type:COMPLEX64\n",
      "  T#197(Cast;Cast) shape_signature:[-1, -1, 257], type:FLOAT32\n",
      "  T#198(tfl.quantize2) shape_signature:[-1, -1, 257], type:INT8\n",
      "  T#199(strided_slice;strided_slice) shape_signature:[-1, -1, 128], type:INT8\n",
      "  T#200(Pow;Pow;Pow/y;Pow/y) shape_signature:[-1, -1, 128], type:INT8\n",
      "  T#201(tfl.dequantize1) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#202(Pow_1;Pow_1) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#203(tfl.quantize3) shape_signature:[-1, -1, 128], type:INT8\n",
      "  T#204(transpose;transpose) shape_signature:[-1, 128, -1], type:INT8\n",
      "  T#205(ExpandDims;ExpandDims) shape_signature:[-1, 128, -1, 1], type:INT8\n",
      "  T#206(model_1/BNORM_SPEC_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 128, -1, 1], type:INT8\n",
      "  T#207(model_1/BNORM_SPEC_NOQUANT/FusedBatchNormV33) shape_signature:[-1, 128, -1, 1], type:INT8\n",
      "  T#208(model_1/ACT_0/Relu;model_1/BNORM_0/FusedBatchNormV3;model_1/pool_0_CONV/Conv2D;model_1/CONV_0/Conv2D) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#209(model_1/pool_0_AVG/AvgPool) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#210(model_1/pool_0_MAX/MaxPool) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#211(model_1/pool_0_CONCAT/concat) shape_signature:[-1, 64, -1, 60], type:INT8\n",
      "  T#212(model_1/pool_0_CONV/BiasAdd;model_1/pool_0_CONV/Conv2D;model_1/pool_0_CONV/BiasAdd/ReadVariableOp) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#213(model_1/BLOCK_1-1_BN_1/FusedBatchNormV3;model_1/BLOCK_1-3_CONV_3/Conv2D;model_1/BLOCK_1-1_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#214(model_1/BLOCK_1-1_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#215(model_1/BLOCK_1-1_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#216(model_1/BLOCK_1-1_BN_3/FusedBatchNormV3;model_1/BLOCK_1-3_CONV_3/Conv2D;model_1/BLOCK_1-1_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#217(model_1/BLOCK_1-2_BN_1/FusedBatchNormV3;model_1/BLOCK_1-3_CONV_3/Conv2D;model_1/BLOCK_1-2_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#218(model_1/BLOCK_1-2_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#219(model_1/BLOCK_1-2_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#220(model_1/BLOCK_1-2_BN_3/FusedBatchNormV3;model_1/BLOCK_1-3_CONV_3/Conv2D;model_1/BLOCK_1-2_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#221(model_1/BLOCK_1-2_ADD/add) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#222(model_1/BLOCK_1-3_BN_1/FusedBatchNormV3;model_1/BLOCK_1-3_CONV_3/Conv2D;model_1/BLOCK_1-3_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#223(model_1/BLOCK_1-3_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#224(model_1/BLOCK_1-3_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#225(model_1/BLOCK_1-3_BN_3/FusedBatchNormV3;model_1/BLOCK_1-3_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#226(model_1/BLOCK_1-3_ADD/add) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#227(model_1/BLOCK_2-1_BN_1/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_1/Conv2D;model_1/BLOCK_2-1_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#228(model_1/BLOCK_2-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#229(model_1/BLOCK_2-1_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#230(model_1/BLOCK_2-1_BN_3/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_3/Conv2D;model_1/BLOCK_2-1_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#231(model_1/BLOCK_2-2_BN_1/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_1/Conv2D;model_1/BLOCK_2-2_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#232(model_1/BLOCK_2-2_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#233(model_1/BLOCK_2-2_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#234(model_1/BLOCK_2-2_BN_3/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_3/Conv2D;model_1/BLOCK_2-2_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#235(model_1/BLOCK_2-2_ADD/add) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#236(model_1/BLOCK_2-3_BN_1/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_1/Conv2D;model_1/BLOCK_2-3_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#237(model_1/BLOCK_2-3_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#238(model_1/BLOCK_2-3_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#239(model_1/BLOCK_2-3_BN_3/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_3/Conv2D;model_1/BLOCK_2-3_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#240(model_1/BLOCK_2-3_ADD/add) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#241(model_1/BLOCK_2-4_BN_1/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#242(model_1/BLOCK_2-4_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#243(model_1/BLOCK_2-4_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#244(model_1/BLOCK_2-4_BN_3/FusedBatchNormV3;model_1/BLOCK_2-4_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#245(model_1/BLOCK_2-4_ADD/add) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#246(model_1/BLOCK_3-1_BN_1/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-1_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 640], type:INT8\n",
      "  T#247(model_1/BLOCK_3-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 640], type:INT8\n",
      "  T#248(model_1/BLOCK_3-1_ACT_1/mul_1) shape_signature:[-1, 16, -1, 640], type:INT8\n",
      "  T#249(model_1/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-1_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#250(model_1/BLOCK_3-1_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#251(model_1/BLOCK_3-1_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#252(model_1/BLOCK_3-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#253(model_1/BLOCK_3-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#254(model_1/BLOCK_3-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#255(model_1/BLOCK_3-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#256(model_1/BLOCK_3-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#257(model_1/BLOCK_3-1_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#258(model_1/BLOCK_3-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#259(model_1/BLOCK_3-1_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#260(model_1/BLOCK_3-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#261(model_1/BLOCK_3-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#262(model_1/BLOCK_3-1_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#263(model_1/BLOCK_3-1_BN_3/FusedBatchNormV3;model_1/BLOCK_3-5_CONV_3/Conv2D;model_1/BLOCK_3-1_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#264(model_1/BLOCK_3-2_BN_1/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-2_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#265(model_1/BLOCK_3-2_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#266(model_1/BLOCK_3-2_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#267(model_1/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-2_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#268(model_1/BLOCK_3-2_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#269(model_1/BLOCK_3-2_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#270(model_1/BLOCK_3-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#271(model_1/BLOCK_3-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#272(model_1/BLOCK_3-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#273(model_1/BLOCK_3-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#274(model_1/BLOCK_3-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#275(model_1/BLOCK_3-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#276(model_1/BLOCK_3-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#277(model_1/BLOCK_3-2_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#278(model_1/BLOCK_3-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#279(model_1/BLOCK_3-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#280(model_1/BLOCK_3-2_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#281(model_1/BLOCK_3-2_BN_3/FusedBatchNormV3;model_1/BLOCK_3-5_CONV_3/Conv2D;model_1/BLOCK_3-2_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#282(model_1/BLOCK_3-2_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#283(model_1/BLOCK_3-3_BN_1/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-3_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#284(model_1/BLOCK_3-3_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#285(model_1/BLOCK_3-3_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#286(model_1/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-3_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#287(model_1/BLOCK_3-3_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#288(model_1/BLOCK_3-3_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#289(model_1/BLOCK_3-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#290(model_1/BLOCK_3-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#291(model_1/BLOCK_3-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#292(model_1/BLOCK_3-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#293(model_1/BLOCK_3-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#294(model_1/BLOCK_3-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#295(model_1/BLOCK_3-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#296(model_1/BLOCK_3-3_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#297(model_1/BLOCK_3-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#298(model_1/BLOCK_3-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#299(model_1/BLOCK_3-3_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#300(model_1/BLOCK_3-3_BN_3/FusedBatchNormV3;model_1/BLOCK_3-5_CONV_3/Conv2D;model_1/BLOCK_3-3_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#301(model_1/BLOCK_3-3_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#302(model_1/BLOCK_3-4_BN_1/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-4_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#303(model_1/BLOCK_3-4_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#304(model_1/BLOCK_3-4_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#305(model_1/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-4_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#306(model_1/BLOCK_3-4_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#307(model_1/BLOCK_3-4_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#308(model_1/BLOCK_3-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#309(model_1/BLOCK_3-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#310(model_1/BLOCK_3-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#311(model_1/BLOCK_3-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#312(model_1/BLOCK_3-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#313(model_1/BLOCK_3-4_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#314(model_1/BLOCK_3-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#315(model_1/BLOCK_3-4_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#316(model_1/BLOCK_3-4_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#317(model_1/BLOCK_3-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#318(model_1/BLOCK_3-4_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#319(model_1/BLOCK_3-4_BN_3/FusedBatchNormV3;model_1/BLOCK_3-5_CONV_3/Conv2D;model_1/BLOCK_3-4_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#320(model_1/BLOCK_3-4_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#321(model_1/BLOCK_3-5_BN_1/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-5_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#322(model_1/BLOCK_3-5_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#323(model_1/BLOCK_3-5_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#324(model_1/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_3-5_SE_CONV_2/Conv2D;model_1/BLOCK_3-5_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#325(model_1/BLOCK_3-5_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#326(model_1/BLOCK_3-5_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#327(model_1/BLOCK_3-5_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#328(model_1/BLOCK_3-5_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#329(model_1/BLOCK_3-5_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#330(model_1/BLOCK_3-5_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#331(model_1/BLOCK_3-5_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#332(model_1/BLOCK_3-5_SE_CONV_1/Conv2D21) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#333(model_1/BLOCK_3-5_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#334(model_1/BLOCK_3-5_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#335(model_1/BLOCK_3-5_SE_CONV_2/Conv2D21) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#336(model_1/BLOCK_3-5_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#337(model_1/BLOCK_3-5_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#338(model_1/BLOCK_3-5_BN_3/FusedBatchNormV3;model_1/BLOCK_3-5_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#339(model_1/BLOCK_3-5_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#340(model_1/BLOCK_4-1_BN_1/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-1_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 1120], type:INT8\n",
      "  T#341(model_1/BLOCK_4-1_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 1120], type:INT8\n",
      "  T#342(model_1/BLOCK_4-1_ACT_1/mul_1) shape_signature:[-1, 8, -1, 1120], type:INT8\n",
      "  T#343(model_1/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-1_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#344(model_1/BLOCK_4-1_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#345(model_1/BLOCK_4-1_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#346(model_1/BLOCK_4-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#347(model_1/BLOCK_4-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#348(model_1/BLOCK_4-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#349(model_1/BLOCK_4-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#350(model_1/BLOCK_4-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#351(model_1/BLOCK_4-1_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#352(model_1/BLOCK_4-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#353(model_1/BLOCK_4-1_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#354(model_1/BLOCK_4-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#355(model_1/BLOCK_4-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#356(model_1/BLOCK_4-1_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#357(model_1/BLOCK_4-1_BN_3/FusedBatchNormV3;model_1/BLOCK_4-4_CONV_3/Conv2D;model_1/BLOCK_4-1_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#358(model_1/BLOCK_4-2_BN_1/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-2_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#359(model_1/BLOCK_4-2_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#360(model_1/BLOCK_4-2_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#361(model_1/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-2_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#362(model_1/BLOCK_4-2_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#363(model_1/BLOCK_4-2_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#364(model_1/BLOCK_4-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#365(model_1/BLOCK_4-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#366(model_1/BLOCK_4-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#367(model_1/BLOCK_4-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#368(model_1/BLOCK_4-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#369(model_1/BLOCK_4-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#370(model_1/BLOCK_4-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#371(model_1/BLOCK_4-2_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#372(model_1/BLOCK_4-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#373(model_1/BLOCK_4-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#374(model_1/BLOCK_4-2_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#375(model_1/BLOCK_4-2_BN_3/FusedBatchNormV3;model_1/BLOCK_4-4_CONV_3/Conv2D;model_1/BLOCK_4-2_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#376(model_1/BLOCK_4-2_ADD/add) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#377(model_1/BLOCK_4-3_BN_1/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-3_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#378(model_1/BLOCK_4-3_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#379(model_1/BLOCK_4-3_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#380(model_1/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-3_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#381(model_1/BLOCK_4-3_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#382(model_1/BLOCK_4-3_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#383(model_1/BLOCK_4-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#384(model_1/BLOCK_4-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#385(model_1/BLOCK_4-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#386(model_1/BLOCK_4-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#387(model_1/BLOCK_4-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#388(model_1/BLOCK_4-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#389(model_1/BLOCK_4-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#390(model_1/BLOCK_4-3_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#391(model_1/BLOCK_4-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#392(model_1/BLOCK_4-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#393(model_1/BLOCK_4-3_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#394(model_1/BLOCK_4-3_BN_3/FusedBatchNormV3;model_1/BLOCK_4-4_CONV_3/Conv2D;model_1/BLOCK_4-3_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#395(model_1/BLOCK_4-3_ADD/add) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#396(model_1/BLOCK_4-4_BN_1/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-4_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#397(model_1/BLOCK_4-4_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#398(model_1/BLOCK_4-4_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#399(model_1/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model_1/BLOCK_4-4_SE_CONV_2/Conv2D;model_1/BLOCK_4-4_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#400(model_1/BLOCK_4-4_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#401(model_1/BLOCK_4-4_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#402(model_1/BLOCK_4-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#403(model_1/BLOCK_4-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#404(model_1/BLOCK_4-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#405(model_1/BLOCK_4-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#406(model_1/BLOCK_4-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#407(model_1/BLOCK_4-4_SE_CONV_1/Conv2D21) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#408(model_1/BLOCK_4-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#409(model_1/BLOCK_4-4_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#410(model_1/BLOCK_4-4_SE_CONV_2/Conv2D21) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#411(model_1/BLOCK_4-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#412(model_1/BLOCK_4-4_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#413(model_1/BLOCK_4-4_BN_3/FusedBatchNormV3;model_1/BLOCK_4-4_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#414(model_1/BLOCK_4-4_ADD/add) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#415(model_1/BNORM_POST_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#416(model_1/ACT_POST/Relu;model_1/BNORM_POST_NOQUANT/FusedBatchNormV3) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#417(model_1/POST_ACT_1/Relu;model_1/POST_BN_1/FusedBatchNormV3;model_1/POST_CONV_1/Conv2D) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#418(Max;Max11) shape_signature:[-1, 1, 1, 420], type:INT8\n",
      "  T#419(Max_1;Max_1) shape_signature:[-1, 420], type:INT8\n",
      "  T#420(sub;sub) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#421(mul;mul) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#422(Exp;Exp) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#423(Mean;Mean) shape_signature:[-1, 420], type:INT8\n",
      "  T#424(tfl.dequantize2) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#425(Log;Log) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#426(tfl.quantize4) shape_signature:[-1, 420], type:INT8\n",
      "  T#427(truediv;truediv;ReadVariableOp;ReadVariableOp1) shape_signature:[-1, 420], type:INT8\n",
      "  T#428(add;add) shape_signature:[-1, 420], type:INT8\n",
      "  T#429(model_1/dense/MatMul;model_1/dense/BiasAdd) shape_signature:[-1, 2], type:INT8\n",
      "  T#430(StatefulPartitionedCall:01) shape_signature:[-1, 2], type:INT8\n",
      "  T#431(StatefulPartitionedCall:0) shape_signature:[-1, 2], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has '1' signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'INPUT' : T#0\n",
      "- Outputs: \n",
      "    'activation' : T#431\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:    7331104 bytes\n",
      "    Non-data buffer size:     742486 bytes (10.13 %)\n",
      "  Total data buffer size:    6588618 bytes (89.87 %)\n",
      "    (Zero value buffers):       7504 bytes (00.10 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(model_path=tflite_model_softmax_INT8_path,\n",
    "                                      model_content=None,\n",
    "                                      gpu_compatibility=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b83c64ef-1ac5-4167-b9a4-00ac254e6967",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0001_703520.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0057_645986.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.930_0263_741788.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.950_0002_645965.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.960_0024_103739801.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_-X5Ay0Wuew0_20.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_4TQzd0lB8IQ_30.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0002_1MF9_29YUZU_10.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_-8S_tLKfeJg_200.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_2hBkeX3k48M_180.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.540_0001_200624_1647_11.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.920_0282_R21_2022_02_25_08_07_04.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.940_0009_784426.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.950_0034_470177.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.970_0015_419564251.wav\n",
      "Balance the test data...\n",
      "Balanced test data:\n",
      "balanced_x_test shape: (916,)\n",
      "balanced_y_test shape: (916, 2)\n",
      "balanced_file_paths_test shape: (916,)\n",
      "...Done. Loaded 916 test samples and 916 labels.\n",
      "Processing batch 1 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.920_0057_141420.wav\n",
      "Entry: 100\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.99609375 0.        ]]\n",
      "Processing batch 11 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.930_0186_741788.wav\n",
      "Entry: 200\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.98828125 0.01171875]]\n",
      "Processing batch 21 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.950_0002_595388.wav\n",
      "Entry: 300\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.98828125 0.01171875]]\n",
      "Processing batch 31 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.960_0018_782604.wav\n",
      "Entry: 400\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.99609375 0.        ]]\n",
      "Processing batch 41 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0001_-WmL01c-4ZE_20.wav\n",
      "Entry: 500\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.890625 0.109375]]\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0001_4M0njWKFsME_30.wav\n",
      "Entry: 600\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.9609375 0.0390625]]\n",
      "Processing batch 51 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0002_1C6VhOCffIE_60.wav\n",
      "Entry: 700\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.75390625 0.24609375]]\n",
      "Processing batch 61 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0003_-7z662AsuTE_380.wav\n",
      "Entry: 800\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.984375 0.015625]]\n",
      "Processing batch 71 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0003_2hBVVym00rc_30.wav\n",
      "Entry: 900\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.92578125 0.07421875]]\n",
      "Accuracy: 52.73%\n",
      "Recall: 105.46%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[457   1]\n",
      " [432  26]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_target       0.51      1.00      0.68       458\n",
      "      target       0.96      0.06      0.11       458\n",
      "\n",
      "    accuracy                           0.53       916\n",
      "   macro avg       0.74      0.53      0.39       916\n",
      "weighted avg       0.74      0.53      0.39       916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import evaluateTFliteModel\n",
    "\n",
    "test_data_path = \"/home/jovyan/cut-data/testing/\"\n",
    "batch_size = 12\n",
    "\n",
    "evaluateTFliteModel.evaluate_tflite_model(tflite_model_softmax_INT8_path, test_data_path, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51643722-dcd5-4cca-9a19-225eb263f002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

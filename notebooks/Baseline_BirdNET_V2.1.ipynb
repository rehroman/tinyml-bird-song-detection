{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39063826-fc13-4dde-8c0e-0ac8214b022c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96af62d4-f914-49fc-81d7-4965d3714a9c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 11:49:55.694970: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-28 11:49:55.737952: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-28 11:49:55.738703: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-28 11:49:56.482868: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_1_layer_call_and_return_conditional_losses_28960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_1_layer_call_and_return_conditional_losses_31016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_2_layer_call_and_return_conditional_losses_12037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_1_layer_call_and_return_conditional_losses_11995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_SE_CONV_1_layer_call_and_return_conditional_losses_29653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_1_layer_call_and_return_conditional_losses_28443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_2_layer_call_and_return_conditional_losses_29616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_1_layer_call_and_return_conditional_losses_13373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-2_ACT_1_layer_call_and_return_conditional_losses_26078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_2_layer_call_and_return_conditional_losses_28582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_1_layer_call_and_return_conditional_losses_31533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-1_ACT_1_layer_call_and_return_conditional_losses_11405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_2_layer_call_and_return_conditional_losses_29099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_SE_CONV_1_layer_call_and_return_conditional_losses_11879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-3_ACT_1_layer_call_and_return_conditional_losses_26390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_2_layer_call_and_return_conditional_losses_12433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_1_layer_call_and_return_conditional_losses_32050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_SE_CONV_1_layer_call_and_return_conditional_losses_12861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-3_ACT_1_layer_call_and_return_conditional_losses_27314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-1_ACT_1_layer_call_and_return_conditional_losses_26702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-1_ACT_1_layer_call_and_return_conditional_losses_25778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-2_ACT_1_layer_call_and_return_conditional_losses_11201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_SE_CONV_1_layer_call_and_return_conditional_losses_28619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-4_ACT_1_layer_call_and_return_conditional_losses_27626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-2_ACT_1_layer_call_and_return_conditional_losses_11499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_SE_CONV_1_layer_call_and_return_conditional_losses_32226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_2_layer_call_and_return_conditional_losses_30133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_1_layer_call_and_return_conditional_losses_29477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_1_layer_call_and_return_conditional_losses_12589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_1_layer_call_and_return_conditional_losses_12787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_2_layer_call_and_return_conditional_losses_31672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_SE_CONV_1_layer_call_and_return_conditional_losses_31709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-1_ACT_1_layer_call_and_return_conditional_losses_11107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_2_layer_call_and_return_conditional_losses_12631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_1_layer_call_and_return_conditional_losses_27938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_1_layer_call_and_return_conditional_losses_13175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_SE_CONV_1_layer_call_and_return_conditional_losses_13447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_2_layer_call_and_return_conditional_losses_11847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_2_layer_call_and_return_conditional_losses_13019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_SE_CONV_1_layer_call_and_return_conditional_losses_30170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_1_layer_call_and_return_conditional_losses_11805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_2_layer_call_and_return_conditional_losses_30650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_SE_CONV_1_layer_call_and_return_conditional_losses_29136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_1_layer_call_and_return_conditional_losses_12193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_SE_CONV_1_layer_call_and_return_conditional_losses_31192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-3_ACT_1_layer_call_and_return_conditional_losses_11601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_2_layer_call_and_return_conditional_losses_31155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_SE_CONV_1_layer_call_and_return_conditional_losses_13051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_2_layer_call_and_return_conditional_losses_13415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_1_layer_call_and_return_conditional_losses_12391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_SE_CONV_1_layer_call_and_return_conditional_losses_12267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_SE_CONV_1_layer_call_and_return_conditional_losses_12069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-4_ACT_1_layer_call_and_return_conditional_losses_11703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_2_layer_call_and_return_conditional_losses_28077) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-2_ACT_1_layer_call_and_return_conditional_losses_27002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_SE_CONV_1_layer_call_and_return_conditional_losses_12465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_1_layer_call_and_return_conditional_losses_30511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_1_layer_call_and_return_conditional_losses_12977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_4834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_SE_CONV_1_layer_call_and_return_conditional_losses_13249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_SE_CONV_1_layer_call_and_return_conditional_losses_12663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_SE_CONV_1_layer_call_and_return_conditional_losses_28114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_2_layer_call_and_return_conditional_losses_12235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-3_ACT_1_layer_call_and_return_conditional_losses_11303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_SE_CONV_1_layer_call_and_return_conditional_losses_30687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_1_layer_call_and_return_conditional_losses_29994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_2_layer_call_and_return_conditional_losses_32189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_2_layer_call_and_return_conditional_losses_13217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_2_layer_call_and_return_conditional_losses_12829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.models import Model as Kerasmodel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "original_model = tf.keras.models.load_model(\"/home/jovyan/models/origin/BirdNET-Analyzer/checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_Model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14e1f7-bb4c-4191-8193-11cf65d0c75b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove last layer and save\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "517f0f01-410d-4efe-9326-97abb1d42f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8mpcgoj9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8mpcgoj9/assets\n",
      "2023-07-28 15:29:37.772854: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-28 15:29:37.772921: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-28 15:29:37.773208: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp8mpcgoj9\n",
      "2023-07-28 15:29:37.799316: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-07-28 15:29:37.799363: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp8mpcgoj9\n",
      "2023-07-28 15:29:37.878367: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-28 15:29:38.280768: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp8mpcgoj9\n",
      "2023-07-28 15:29:38.458471: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 685262 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Converting\n",
      "Finished Saving\n"
     ]
    }
   ],
   "source": [
    "no_class_model = Kerasmodel(original_model.input, original_model.layers[-2].output)\n",
    "no_class_model_path = \"/home/jovyan/models/checkpoints/no_class_model.tflite\"\n",
    "\n",
    "# Convert the keras model to a tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(no_class_model)\n",
    "tflite_no_class_model = converter.convert()\n",
    "\n",
    "print(\"Finished Converting\")\n",
    "\n",
    "with open(no_class_model_path, 'wb') as f:\n",
    "    f.write(tflite_no_class_model)\n",
    "print(\"Finished Saving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3948df-40bd-4887-a487-3d4298a51bd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load training data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c6fb1e7-ad7a-49af-9140-0da2aae61cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0001_127764.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0003_82178411.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0006_718263.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0010_540556.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0016_324707.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0022_355153.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0031_270434051.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0043_647427.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.920_0076_36928.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0002_472272481.wav\n",
      "Processed 1000 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0005_552529.wav\n",
      "Processed 1100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0008_716296.wav\n",
      "Processed 1200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0013_121693.wav\n",
      "Processed 1300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0017_713037.wav\n",
      "Processed 1400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0026_247411901.wav\n",
      "Processed 1500 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0038_723553.wav\n",
      "Processed 1600 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.930_0063_60212751.wav\n",
      "Processed 1700 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.940_0002_102741151.wav\n",
      "Processed 1800 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.940_0005_529329181.wav\n",
      "Processed 1900 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.940_0009_472003041.wav\n",
      "Processed 2000 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.940_0014_723553.wav\n",
      "Processed 2100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.940_0020_523504.wav\n",
      "Processed 2200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.940_0030_578424.wav\n",
      "Processed 2300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.940_0046_722476.wav\n",
      "Processed 2400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.950_0002_134047.wav\n",
      "Processed 2500 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.950_0006_153920411.wav\n",
      "Processed 2600 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.950_0012_171486.wav\n",
      "Processed 2700 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.950_0020_489618321.wav\n",
      "Processed 2800 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.950_0037_461903821.wav\n",
      "Processed 2900 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.950_0087_140045.wav\n",
      "Processed 3000 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.960_0005_463339521.wav\n",
      "Processed 3100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.960_0012_256683.wav\n",
      "Processed 3200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.960_0028_386459751.wav\n",
      "Processed 3300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.960_0103_310083.wav\n",
      "Processed 3400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.970_0009_275634.wav\n",
      "Processed 3500 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.970_0025_82178411.wav\n",
      "Processed 3600 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.980_0003_474070721.wav\n",
      "Processed 3700 files. Currently processing file: /home/jovyan/cut-data/training/non_target/0.980_0025_474070721.wav\n",
      "Processed 3800 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_--yCGUs46y4_30.wav\n",
      "Processed 3900 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_-CUp_Tmg2Y0_30.wav\n",
      "Processed 4000 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_-Ub8LKPkhos_60.wav\n",
      "Processed 4100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_-sRFfU8k0Zs_90.wav\n",
      "Processed 4200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_0F3WEUPxWCM_0.wav\n",
      "Processed 4300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_0fm0oU8FO0U_30.wav\n",
      "Processed 4400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_1DxLwZhTj0A_30.wav\n",
      "Processed 4500 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_1kjnqM-ptrk_110.wav\n",
      "Processed 4600 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_2RpOd9MJjyQ_10.wav\n",
      "Processed 4700 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_35t2aAFoIW4_0.wav\n",
      "Processed 4800 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_4AllUpjCvI4_280.wav\n",
      "Processed 4900 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_619xf0ifoSQ_10.wav\n",
      "Processed 5000 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0001_zPhwKiiWzoA_30.wav\n",
      "Processed 5100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_-7wUQP6G5EQ_30.wav\n",
      "Processed 5200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_-KaRoM5LnHc_30.wav\n",
      "Processed 5300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_-gfBxHm8lhg_90.wav\n",
      "Processed 5400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_01xpKyI0rXA_180.wav\n",
      "Processed 5500 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_0QSZ9Fr1qeQ_30.wav\n",
      "Processed 5600 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_0qZ3tI4nAZE_6.wav\n",
      "Processed 5700 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_1PeBvAdub4w_370.wav\n",
      "Processed 5800 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_23Yu8RnEv3k_30.wav\n",
      "Processed 5900 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_2hyHI8DNWD4_200.wav\n",
      "Processed 6000 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_3Zt4Y3Jajrk_20.wav\n",
      "Processed 6100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_551pSwSFXc0_30.wav\n",
      "Processed 6200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0002_96vB5wR_J4w_290.wav\n",
      "Processed 6300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_-5-vmt2iKT0_30.wav\n",
      "Processed 6400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_-G3Ph35cTy0_30.wav\n",
      "Processed 6500 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_-_nPg0thx-s_410.wav\n",
      "Processed 6600 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_-xUhOdzwLtw_0.wav\n",
      "Processed 6700 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_0Lt4MP0-6Tc_590.wav\n",
      "Processed 6800 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_0m9CbkMad_k_150.wav\n",
      "Processed 6900 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_1OHxLcGzhv0_30.wav\n",
      "Processed 7000 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_1ya5YEWkTG0_490.wav\n",
      "Processed 7100 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_2_7jHXNdC_w_40.wav\n",
      "Processed 7200 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_3JLEt6u9CwY_240.wav\n",
      "Processed 7300 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_4M7jykYpnNU_0.wav\n",
      "Processed 7400 files. Currently processing file: /home/jovyan/cut-data/training/non_target/1.000_0003_6o6DsSnbpxE_60.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/training/target/0.390_0001_200622_1615_7.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/training/target/0.810_0001_200622_1605_7.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/training/target/0.920_0004_556978.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/training/target/0.920_0012_633369.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/training/target/0.920_0022_86290.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/training/target/0.920_0036_555437551.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/training/target/0.920_0052_R21_2022_02_25_09_55_07.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/training/target/0.920_0086_R21_2022_02_25_07_31_02.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/training/target/0.920_0164_R21_2022_02_23_08_14_49.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/training/target/0.930_0006_418056311.wav\n",
      "Processed 1000 files. Currently processing file: /home/jovyan/cut-data/training/target/0.930_0014_459920281.wav\n",
      "Processed 1100 files. Currently processing file: /home/jovyan/cut-data/training/target/0.930_0024_690624.wav\n",
      "Processed 1200 files. Currently processing file: /home/jovyan/cut-data/training/target/0.930_0040_517125591.wav\n",
      "Processed 1300 files. Currently processing file: /home/jovyan/cut-data/training/target/0.930_0063_R21_2022_02_22_07_49_45.wav\n",
      "Processed 1400 files. Currently processing file: /home/jovyan/cut-data/training/target/0.930_0097_R21_2022_02_25_08_22_06.wav\n",
      "Processed 1500 files. Currently processing file: /home/jovyan/cut-data/training/target/0.930_0240_R21_2022_02_23_08_14_49.wav\n",
      "Processed 1600 files. Currently processing file: /home/jovyan/cut-data/training/target/0.940_0006_676693.wav\n",
      "Processed 1700 files. Currently processing file: /home/jovyan/cut-data/training/target/0.940_0016_716129.wav\n",
      "Processed 1800 files. Currently processing file: /home/jovyan/cut-data/training/target/0.940_0030_27576.wav\n",
      "Processed 1900 files. Currently processing file: /home/jovyan/cut-data/training/target/0.940_0049_517127011.wav\n",
      "Processed 2000 files. Currently processing file: /home/jovyan/cut-data/training/target/0.940_0081_696775.wav\n",
      "Processed 2100 files. Currently processing file: /home/jovyan/cut-data/training/target/0.940_0126_555571531.wav\n",
      "Processed 2200 files. Currently processing file: /home/jovyan/cut-data/training/target/0.950_0002_420362.wav\n",
      "Processed 2300 files. Currently processing file: /home/jovyan/cut-data/training/target/0.950_0015_456706281.wav\n",
      "Processed 2400 files. Currently processing file: /home/jovyan/cut-data/training/target/0.950_0029_155008.wav\n",
      "Processed 2500 files. Currently processing file: /home/jovyan/cut-data/training/target/0.950_0050_558294.wav\n",
      "Processed 2600 files. Currently processing file: /home/jovyan/cut-data/training/target/0.950_0085_366916.wav\n",
      "Processed 2700 files. Currently processing file: /home/jovyan/cut-data/training/target/0.950_0170_558294.wav\n",
      "Processed 2800 files. Currently processing file: /home/jovyan/cut-data/training/target/0.960_0007_420362.wav\n",
      "Processed 2900 files. Currently processing file: /home/jovyan/cut-data/training/target/0.960_0023_384110291.wav\n",
      "Processed 3000 files. Currently processing file: /home/jovyan/cut-data/training/target/0.960_0045_R21_2022_02_25_07_31_02.wav\n",
      "Processed 3100 files. Currently processing file: /home/jovyan/cut-data/training/target/0.960_0078_R21_2022_02_25_08_22_06.wav\n",
      "Processed 3200 files. Currently processing file: /home/jovyan/cut-data/training/target/0.960_0118_R21_2022_02_23_07_59_47.wav\n",
      "Processed 3300 files. Currently processing file: /home/jovyan/cut-data/training/target/0.970_0006_556978.wav\n",
      "Processed 3400 files. Currently processing file: /home/jovyan/cut-data/training/target/0.970_0030_517125591.wav\n",
      "Processed 3500 files. Currently processing file: /home/jovyan/cut-data/training/target/0.970_0070_R21_2022_02_26_08_25_32.wav\n",
      "Processed 3600 files. Currently processing file: /home/jovyan/cut-data/training/target/0.970_0180_R21_2022_02_23_07_59_47.wav\n",
      "Processed 3700 files. Currently processing file: /home/jovyan/cut-data/training/target/0.980_0032_R21_2022_02_23_07_59_47.wav\n",
      "Processed 3800 files. Currently processing file: /home/jovyan/cut-data/training/target/0.990_0031_436601051.wav\n",
      "...Done. Loaded 11292 training samples and 2 labels.\n"
     ]
    }
   ],
   "source": [
    "import data as data\n",
    "\n",
    "train_data_path = \"/home/jovyan/cut-data/training/\"\n",
    "\n",
    "# Load training data\n",
    "print('Loading training data...', flush=True)\n",
    "x_train, y_train, labels, file_paths_train = data.loadData(train_data_path)\n",
    "print('...Done. Loaded {} training samples and {} labels.'.format(x_train.shape[0], y_train.shape[1]), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29415c-818b-4eb1-b5cd-e09edb8e8373",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load validation data and convert\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66a6d263-f0f1-4a2a-942d-a58d063c8c2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.920_0001_270097.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.930_0002_182583971.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.940_0004_534761.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.950_0018_226391901.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.970_0017_647758.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0001_0H2uMhzSitY_520.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0002_--ivFZu-hlc_30.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0002_2RpOd9MJjyQ_10.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0003_-w4HLksto_k_30.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0003_6m5hv5BX7KU_40.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.480_0001_200614_1467_1.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.920_0103_669234.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.940_0015_139518451.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.950_0064_558294.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.970_0001_155008.wav\n",
      "...Done. Loaded 1381 validation samples and 2 labels.\n"
     ]
    }
   ],
   "source": [
    "val_data_path = \"/home/jovyan/cut-data/validation/\"\n",
    "\n",
    "print('Loading validation data...', flush=True)\n",
    "x_val, y_val, labels, file_paths_val = data.loadData(val_data_path)\n",
    "print('...Done. Loaded {} validation samples and {} labels.'.format(x_val.shape[0], y_val.shape[1]), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3007ef4f-194f-4e3d-93c2-b19d94d1371e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done. Loaded 11292 training files and 2 labels.\n",
      "...Done. Loaded 1381 validation files and 2 labels.\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array(x_train, dtype='float32')\n",
    "y_train = np.array(y_train, dtype='float32')\n",
    "\n",
    "x_val = np.array(x_val, dtype='float32')\n",
    "y_val = np.array(y_val, dtype='float32')\n",
    "\n",
    "print('...Done. Loaded {} training files and {} labels.'.format(x_train.shape[0], y_train.shape[1]), flush=True)\n",
    "print('...Done. Loaded {} validation files and {} labels.'.format(x_val.shape[0], y_val.shape[1]), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77eb377-49d4-44aa-8008-6674390b8e81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create new 2 Class Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e85cc-0fea-46d3-974d-cbaebb7b9125",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build custom classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "615b3a1f-3cb5-45bf-b9ad-da3f9f207672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "\n",
    "train_hidden_units = 3\n",
    "\n",
    "# Build two class model\n",
    "print('Building model...', flush=True)    \n",
    "two_class_model = model.addLinearClassifier(no_class_model,\n",
    "                                            y_train.shape[1], #number of labels\n",
    "                                            train_hidden_units) #number of hidden units\n",
    "\n",
    "print('...Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312ec4a-225b-4134-80d5-4ca6ed98cc8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### check new shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e5490c9-2b43-4325-9d32-c30505a2ed9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " INPUT (InputLayer)          [(None, 144000)]             0         []                            \n",
      "                                                                                                  \n",
      " ADVANCED_SPEC1 (LinearSpec  (None, 128, 513, 1)          1         ['INPUT[0][0]']               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " BNORM_SPEC_NOQUANT (BatchN  (None, 128, 513, 1)          4         ['ADVANCED_SPEC1[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " CONV_0 (Conv2D)             (None, 64, 257, 30)          960       ['BNORM_SPEC_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " BNORM_0 (BatchNormalizatio  (None, 64, 257, 30)          120       ['CONV_0[0][0]']              \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " ACT_0 (Activation)          (None, 64, 257, 30)          0         ['BNORM_0[0][0]']             \n",
      "                                                                                                  \n",
      " pool_0_MAX (MaxPooling2D)   (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      "                                                                                                  \n",
      " pool_0_AVG (AveragePooling  (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONCAT (Concatenate  (None, 64, 128, 60)          0         ['pool_0_MAX[0][0]',          \n",
      " )                                                                   'pool_0_AVG[0][0]']          \n",
      "                                                                                                  \n",
      " pool_0_ACT_QUANT (Activati  (None, 64, 128, 60)          0         ['pool_0_CONCAT[0][0]']       \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONV (Conv2D)        (None, 64, 128, 30)          1830      ['pool_0_ACT_QUANT[0][0]']    \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_1 (Conv2D)   (None, 32, 64, 60)           16200     ['pool_0_CONV[0][0]']         \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_1 (Conv2D)   (None, 16, 32, 240)          129600    ['BLOCK_1-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-4_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_1 (Conv2D)   (None, 16, 32, 640)          76800     ['BLOCK_2-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_1 (BatchNorma  (None, 16, 32, 640)          2560      ['BLOCK_3-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_1 (Activatio  (None, 16, 32, 640)          0         ['BLOCK_3-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-5_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-5_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-5_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-5_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-5_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-5_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-5_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-5_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-5_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-5_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-5_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_1 (Conv2D)   (None, 8, 16, 1120)          179200    ['BLOCK_3-5_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_1 (BatchNorma  (None, 8, 16, 1120)          4480      ['BLOCK_4-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_1 (Activatio  (None, 8, 16, 1120)          0         ['BLOCK_4-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BNORM_POST_NOQUANT (BatchN  (None, 4, 8, 280)            1120      ['BLOCK_4-4_ADD[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ACT_POST (Activation)       (None, 4, 8, 280)            0         ['BNORM_POST_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " POST_CONV_1 (Conv2D)        (None, 2, 6, 420)            1058400   ['ACT_POST[0][0]']            \n",
      "                                                                                                  \n",
      " POST_BN_1 (BatchNormalizat  (None, 2, 6, 420)            1680      ['POST_CONV_1[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " POST_ACT_1 (Activation)     (None, 2, 6, 420)            0         ['POST_BN_1[0][0]']           \n",
      "                                                                                                  \n",
      " GLOBAL_LME_POOL (GlobalLog  (None, 420)                  1         ['POST_ACT_1[0][0]']          \n",
      " ExpPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 3)                    1263      ['GLOBAL_LME_POOL[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2)                    8         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 2)                    0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6581027 (25.10 MB)\n",
      "Trainable params: 1271 (4.96 KB)\n",
      "Non-trainable params: 6579756 (25.10 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "two_class_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998e8495-d045-42de-ab5a-05f67ca6a700",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Two Class Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203f07c-c99e-442c-bcc1-5a0b22fc1b4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fc29e-5ed6-4dbf-82ed-47cd8f5fafdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NaN DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24e428-9479-4134-987a-2672e3a0d2d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Trainingsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3bee08-80e5-4a98-92c7-ea05ce3652df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import model\n",
    "# # Disable Model Debug\n",
    "# tf.debugging.disable_check_numerics()\n",
    "\n",
    "# nan_samples = model.debug_model(two_class_model, file_paths_train, y_train, train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7dbed-6b4c-46bd-a5bc-bd50bacb09d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Validationdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174f55d6-5294-4f7f-beed-32fa5db00fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import model\n",
    "# # Disable Model Debug\n",
    "# tf.debugging.disable_check_numerics()\n",
    "\n",
    "# nan_samples = model.debug_model(two_class_model, file_paths_val, y_val, train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccbe63-813c-4f5a-a33a-7454e8ce9f31",
   "metadata": {},
   "source": [
    "### Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ca90807-1816-4c2b-948d-920dda1a2893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training labels:  (11292,)\n",
      "Shape of validation labels:  (1381,)\n",
      "...Done. Loaded 11292 training files and 2 labels.\n",
      "...Done. Loaded 1381 validation files and 2 labels.\n"
     ]
    }
   ],
   "source": [
    "train_epochs = 100\n",
    "train_batch_size = 12\n",
    "train_learning_rate = 0.01\n",
    "    \n",
    "# Number of last layers to be trained, rest will be frozen\n",
    "train_layers_num = 3\n",
    "\n",
    "on_epoch_end = None\n",
    "\n",
    "#print(\"Shape of training labels: \", y_train.shape)\n",
    "#print(\"Shape of validation labels: \", y_val.shape)\n",
    "\n",
    "print(\"Shape of training labels: \", x_train.shape)\n",
    "print(\"Shape of validation labels: \", x_val.shape)\n",
    "\n",
    "print('...Done. Loaded {} training files and {} labels.'.format(x_train.shape[0], y_train.shape[1]), flush=True)\n",
    "print('...Done. Loaded {} validation files and {} labels.'.format(x_val.shape[0], y_val.shape[1]), flush=True)\n",
    "\n",
    "#print(\"First 5 training labels: \", y_train[:5])\n",
    "#print(\"First 5 validation labels: \", y_val[:5])\n",
    "\n",
    "#print(\"First 5 training labels: \", y_train[:5])\n",
    "#print(\"First 5 validation labels: \", y_val[:5])\n",
    "\n",
    "#print(\"Are there any NaN values in the training labels? \", np.isnan(y_train).any())\n",
    "#print(\"Are there any NaN values in the validation labels? \", np.isnan(y_val).any())\n",
    "\n",
    "#print(\"Are there any inf values in the training data? \", np.isinf(x_train).any())\n",
    "#print(\"Are there any inf values in the validation data? \", np.isinf(x_val).any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6047337-069c-4122-afb9-b52132ed6af5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Length of trainable Weightslen  4\n",
      "Epoch 1/100\n",
      "941/941 [==============================] - 127s 132ms/step - loss: 0.0653 - accuracy: 0.9820 - prec: 0.9841 - recall: 0.9726 - val_loss: 4.9460e-04 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/100\n",
      "941/941 [==============================] - 121s 129ms/step - loss: 1.3188e-04 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 6.8960e-05 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "941/941 [==============================] - 122s 129ms/step - loss: 5.7351e-05 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.4602e-05 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "941/941 [==============================] - 123s 131ms/step - loss: 3.0512e-05 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.0074e-05 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 1.7385e-05 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 1.5142e-05 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "941/941 [==============================] - 127s 134ms/step - loss: 8.2682e-06 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 8.9724e-06 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "941/941 [==============================] - 128s 136ms/step - loss: 5.5650e-06 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 6.3171e-06 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 3.9040e-06 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 1.4907e-05 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "941/941 [==============================] - 125s 133ms/step - loss: 2.1407e-06 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 1.8586e-06 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/100\n",
      "941/941 [==============================] - 125s 132ms/step - loss: 1.0455e-06 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 1.8042e-06 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "941/941 [==============================] - 124s 132ms/step - loss: 7.3503e-07 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 1.2615e-06 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/100\n",
      "941/941 [==============================] - 122s 130ms/step - loss: 3.7381e-07 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.3617e-06 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "941/941 [==============================] - 124s 131ms/step - loss: 4.6903e-07 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.8206e-07 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 1.0142e-07 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.8775e-07 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "941/941 [==============================] - 126s 134ms/step - loss: 7.0465e-08 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 5.7457e-07 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "941/941 [==============================] - 128s 135ms/step - loss: 6.1516e-08 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.5920e-07 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/100\n",
      "941/941 [==============================] - 128s 136ms/step - loss: 3.9288e-08 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.2066e-07 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/100\n",
      "941/941 [==============================] - 130s 138ms/step - loss: 1.7806e-08 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 9.4198e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 1.0115e-08 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 4.5087e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "941/941 [==============================] - 126s 134ms/step - loss: 6.2133e-09 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.7369e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/100\n",
      "941/941 [==============================] - 128s 136ms/step - loss: 4.4469e-09 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.9074e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/100\n",
      "941/941 [==============================] - 129s 137ms/step - loss: 3.7744e-09 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.1931e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/100\n",
      "941/941 [==============================] - 125s 133ms/step - loss: 1.3578e-09 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.2225e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 9.9112e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 1.0453e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 6.6825e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 8.1393e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 4.2967e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 1.2701e-08 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/100\n",
      "941/941 [==============================] - 128s 136ms/step - loss: 3.4955e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 8.2722e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 2.2986e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 4.3270e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 1.7784e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 4.0084e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "941/941 [==============================] - 130s 138ms/step - loss: 1.2415e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.7052e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 1.0388e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.9872e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "941/941 [==============================] - 125s 133ms/step - loss: 9.3771e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.8399e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "941/941 [==============================] - 126s 134ms/step - loss: 1.0666e-10 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.1059e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "941/941 [==============================] - 125s 133ms/step - loss: 6.8157e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.9073e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "941/941 [==============================] - 126s 134ms/step - loss: 4.9703e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 3.0990e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "941/941 [==============================] - 126s 133ms/step - loss: 6.5101e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.6034e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "941/941 [==============================] - 126s 134ms/step - loss: 4.2736e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.7372e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "941/941 [==============================] - 124s 132ms/step - loss: 5.2621e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.0037e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "941/941 [==============================] - 125s 133ms/step - loss: 4.3558e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.0834e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "941/941 [==============================] - 124s 132ms/step - loss: 3.7231e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.2981e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "941/941 [==============================] - 124s 132ms/step - loss: 4.2258e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.3038e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "941/941 [==============================] - 123s 131ms/step - loss: 3.8654e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.0964e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "941/941 [==============================] - 127s 135ms/step - loss: 4.2458e-11 - accuracy: 1.0000 - prec: 1.0000 - recall: 1.0000 - val_loss: 2.2412e-09 - val_accuracy: 1.0000 - val_prec: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print('Training model...', flush=True)\n",
    "\n",
    "# Check for Errors to find NaN problem\n",
    "# tf.debugging.enable_check_numerics()\n",
    "\n",
    "# Disable Model Debug\n",
    "tf.debugging.disable_check_numerics()\n",
    "\n",
    "trained_two_class_model, history = model.trainNewModel(\n",
    "                                      two_class_model,\n",
    "                                      train_layers_num,\n",
    "                                      x_train, \n",
    "                                      y_train,\n",
    "                                      x_val,\n",
    "                                      y_val,\n",
    "                                      file_paths_train,\n",
    "                                      file_paths_val,\n",
    "                                      epochs=train_epochs,\n",
    "                                      batch_size=train_batch_size,\n",
    "                                      learning_rate=train_learning_rate,\n",
    "                                      on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c45da0-907b-433b-a00f-770f8af474b7",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75f9b040-37df-498e-9463-3ba7840da799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1arew5ow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1arew5ow/assets\n",
      "2023-07-28 20:38:03.434817: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-28 20:38:03.434883: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-28 20:38:03.435222: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp1arew5ow\n",
      "2023-07-28 20:38:03.464237: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-07-28 20:38:03.464285: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp1arew5ow\n",
      "2023-07-28 20:38:03.549749: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-28 20:38:03.983919: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp1arew5ow\n",
      "2023-07-28 20:38:04.169967: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 734744 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Converting\n",
      "Finished Saving\n"
     ]
    }
   ],
   "source": [
    "trained_two_class_model_path = \"/home/jovyan/models/checkpoints/baseline_two_class_model.tflite\"\n",
    "\n",
    "# Convert the keras model to a tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(trained_two_class_model)\n",
    "tflite_trained_two_class_model = converter.convert()\n",
    "\n",
    "print(\"Finished Converting\")\n",
    "\n",
    "with open(trained_two_class_model_path, 'wb') as f:\n",
    "    f.write(tflite_trained_two_class_model)\n",
    "print(\"Finished Saving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2f997-7e49-42a6-913d-996d02e1279e",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "954feffb-f12f-4aa1-8a61-21caf155eb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0001_703520.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0057_645986.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.930_0263_741788.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.950_0002_645965.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.960_0024_103739801.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_-X5Ay0Wuew0_20.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_4TQzd0lB8IQ_30.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0002_1MF9_29YUZU_10.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_-8S_tLKfeJg_200.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_2hBkeX3k48M_180.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.540_0001_200624_1647_11.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.920_0282_R21_2022_02_25_08_07_04.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.940_0009_784426.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.950_0034_470177.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.970_0015_419564251.wav\n",
      "Shape of y_data:  (1393, 2)\n",
      "Unique values in y_data:  [0. 1.]\n",
      "Shape of file_paths:  (1393,)\n",
      "Unique values in file_paths:  ['/home/jovyan/cut-data/testing/non_target/0.920_0001_703520.wav'\n",
      " '/home/jovyan/cut-data/testing/non_target/0.920_0001_780310.wav'\n",
      " '/home/jovyan/cut-data/testing/non_target/0.920_0002_110879971.wav' ...\n",
      " '/home/jovyan/cut-data/testing/target/0.990_0001_127306.wav'\n",
      " '/home/jovyan/cut-data/testing/target/0.990_0077_555571531.wav'\n",
      " '/home/jovyan/cut-data/testing/target/0.990_0154_R21_2022_02_23_07_59_47.wav']\n",
      "117/117 [==============================] - 14s 116ms/step - loss: nan - accuracy: 1.0000 - prec: 1.0000 - recall: 0.9993\n",
      "Test Loss:  nan\n",
      "Test Accuracy:  1.0\n",
      "Test Precision:  1.0\n",
      "Test Recall:  0.9992821216583252\n",
      "117/117 [==============================] - 14s 116ms/step\n",
      "Shape of y_true:  (1393, 2)\n",
      "Unique values in y_true:  [0. 1.]\n",
      "Shape of y_pred_classes:  (1393,)\n",
      "Unique values in y_pred_classes:  [0 1]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       935\n",
      "           1       1.00      1.00      1.00       458\n",
      "\n",
      "    accuracy                           1.00      1393\n",
      "   macro avg       1.00      1.00      1.00      1393\n",
      "weighted avg       1.00      1.00      1.00      1393\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[935   0]\n",
      " [  0 458]]\n"
     ]
    }
   ],
   "source": [
    "import evaluateModel\n",
    "\n",
    "test_data_path = \"/home/jovyan/cut-data/testing/\"\n",
    "\n",
    "evaluateModel.evaluateModel(trained_two_class_model, test_data_path, train_batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b5b459-aa3c-4224-93db-08d4955e572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0001_703520.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0057_645986.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.930_0263_741788.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.950_0002_645965.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.960_0024_103739801.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_-X5Ay0Wuew0_20.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_4M0njWKFsME_30.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0002_1C6VhOCffIE_60.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_-7z662AsuTE_380.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_2dhsSsHXKVk_150.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.540_0001_200624_1647_11.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.920_0282_R21_2022_02_25_08_07_04.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.940_0009_784426.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.950_0034_470177.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.970_0015_419564251.wav\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'model' has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_true, y_pred_classes))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mevaluateModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [4], line 17\u001b[0m, in \u001b[0;36mevaluateModel\u001b[0;34m(trained_model, test_data_path, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m test_gen \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mAudioDataGenerator(file_paths, y_data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluate on the testdata\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m loss, accuracy, precision, recall \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m(test_gen)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'model' has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import data as data\n",
    "import model as model\n",
    "\n",
    "\n",
    "def evaluateModel(trained_model, test_data_path, batch_size):\n",
    "    # Load data\n",
    "    x_data, y_data, labels, file_paths = data.loadData(test_data_path)\n",
    "\n",
    "    # Initialize AudioDataGenerator\n",
    "    test_gen = model.AudioDataGenerator(file_paths, y_data, batch_size=batch_size)\n",
    "\n",
    "    # Evaluate on the testdata\n",
    "    loss, accuracy, precision, recall = model.evaluate(test_gen)\n",
    "\n",
    "    print(\"Test Loss: \", loss)\n",
    "    print(\"Test Accuracy: \", accuracy)\n",
    "    print(\"Test Precision: \", precision)\n",
    "    print(\"Test Recall: \", recall)\n",
    "\n",
    "    # Predictions on testdata\n",
    "    y_pred = trained_model.predict(test_gen)\n",
    "\n",
    "    # Classification report and confusion matrix\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.concatenate([np.array(batch[1]) for batch in test_gen])\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred_classes))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred_classes))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

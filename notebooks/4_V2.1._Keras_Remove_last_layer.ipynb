{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aede01d-bdd7-4dd7-b784-781aad5d60f9",
   "metadata": {},
   "source": [
    "# Try to remove last layer with Keras model BirdNET V2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7156e42a-85e5-40a0-8e8b-3e87185cfc5b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 15:08:37.064999: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-07 15:08:37.112944: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-07 15:08:37.114072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 15:08:37.954890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_1_layer_call_and_return_conditional_losses_28960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_1_layer_call_and_return_conditional_losses_31016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_2_layer_call_and_return_conditional_losses_12037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_1_layer_call_and_return_conditional_losses_11995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_SE_CONV_1_layer_call_and_return_conditional_losses_29653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_1_layer_call_and_return_conditional_losses_28443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_2_layer_call_and_return_conditional_losses_29616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_1_layer_call_and_return_conditional_losses_13373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-2_ACT_1_layer_call_and_return_conditional_losses_26078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_ACT_2_layer_call_and_return_conditional_losses_28582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_1_layer_call_and_return_conditional_losses_31533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-1_ACT_1_layer_call_and_return_conditional_losses_11405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_2_layer_call_and_return_conditional_losses_29099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_SE_CONV_1_layer_call_and_return_conditional_losses_11879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-3_ACT_1_layer_call_and_return_conditional_losses_26390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_2_layer_call_and_return_conditional_losses_12433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_1_layer_call_and_return_conditional_losses_32050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_SE_CONV_1_layer_call_and_return_conditional_losses_12861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-3_ACT_1_layer_call_and_return_conditional_losses_27314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-1_ACT_1_layer_call_and_return_conditional_losses_26702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-1_ACT_1_layer_call_and_return_conditional_losses_25778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-2_ACT_1_layer_call_and_return_conditional_losses_11201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_SE_CONV_1_layer_call_and_return_conditional_losses_28619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-4_ACT_1_layer_call_and_return_conditional_losses_27626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-2_ACT_1_layer_call_and_return_conditional_losses_11499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_SE_CONV_1_layer_call_and_return_conditional_losses_32226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_2_layer_call_and_return_conditional_losses_30133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_1_layer_call_and_return_conditional_losses_29477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_1_layer_call_and_return_conditional_losses_12589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_1_layer_call_and_return_conditional_losses_12787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_2_layer_call_and_return_conditional_losses_31672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_SE_CONV_1_layer_call_and_return_conditional_losses_31709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-1_ACT_1_layer_call_and_return_conditional_losses_11107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_22684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_2_layer_call_and_return_conditional_losses_12631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_1_layer_call_and_return_conditional_losses_27938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_1_layer_call_and_return_conditional_losses_13175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_SE_CONV_1_layer_call_and_return_conditional_losses_13447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_2_layer_call_and_return_conditional_losses_11847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_2_layer_call_and_return_conditional_losses_13019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_SE_CONV_1_layer_call_and_return_conditional_losses_30170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_1_layer_call_and_return_conditional_losses_11805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_2_layer_call_and_return_conditional_losses_30650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_SE_CONV_1_layer_call_and_return_conditional_losses_29136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_1_layer_call_and_return_conditional_losses_12193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_24033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_SE_CONV_1_layer_call_and_return_conditional_losses_31192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-3_ACT_1_layer_call_and_return_conditional_losses_11601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_2_layer_call_and_return_conditional_losses_31155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_SE_CONV_1_layer_call_and_return_conditional_losses_13051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_2_layer_call_and_return_conditional_losses_13415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_ACT_1_layer_call_and_return_conditional_losses_12391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_SE_CONV_1_layer_call_and_return_conditional_losses_12267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-2_SE_CONV_1_layer_call_and_return_conditional_losses_12069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-4_ACT_1_layer_call_and_return_conditional_losses_11703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_ACT_2_layer_call_and_return_conditional_losses_28077) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_2-2_ACT_1_layer_call_and_return_conditional_losses_27002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-4_SE_CONV_1_layer_call_and_return_conditional_losses_12465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_1_layer_call_and_return_conditional_losses_30511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-2_ACT_1_layer_call_and_return_conditional_losses_12977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_4834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_SE_CONV_1_layer_call_and_return_conditional_losses_13249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_SE_CONV_1_layer_call_and_return_conditional_losses_12663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-1_SE_CONV_1_layer_call_and_return_conditional_losses_28114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-3_ACT_2_layer_call_and_return_conditional_losses_12235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_1-3_ACT_1_layer_call_and_return_conditional_losses_11303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_SE_CONV_1_layer_call_and_return_conditional_losses_30687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_3-5_ACT_1_layer_call_and_return_conditional_losses_29994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-4_ACT_2_layer_call_and_return_conditional_losses_32189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-3_ACT_2_layer_call_and_return_conditional_losses_13217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_BLOCK_4-1_ACT_2_layer_call_and_return_conditional_losses_12829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "model = tf.keras.models.load_model(\"/home/jovyan/models/origin/BirdNET-Analyzer/checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_Model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca8900-a0dc-4d00-a17c-89e0876da216",
   "metadata": {},
   "source": [
    "# Layers before removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3c6e3a-cf84-48fb-b34a-20039ca76f70",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " INPUT (InputLayer)          [(None, 144000)]             0         []                            \n",
      "                                                                                                  \n",
      " ADVANCED_SPEC1 (LinearSpec  (None, 128, 513, 1)          1         ['INPUT[0][0]']               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " BNORM_SPEC_NOQUANT (BatchN  (None, 128, 513, 1)          4         ['ADVANCED_SPEC1[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " CONV_0 (Conv2D)             (None, 64, 257, 30)          960       ['BNORM_SPEC_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " BNORM_0 (BatchNormalizatio  (None, 64, 257, 30)          120       ['CONV_0[0][0]']              \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " ACT_0 (Activation)          (None, 64, 257, 30)          0         ['BNORM_0[0][0]']             \n",
      "                                                                                                  \n",
      " pool_0_MAX (MaxPooling2D)   (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      "                                                                                                  \n",
      " pool_0_AVG (AveragePooling  (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONCAT (Concatenate  (None, 64, 128, 60)          0         ['pool_0_MAX[0][0]',          \n",
      " )                                                                   'pool_0_AVG[0][0]']          \n",
      "                                                                                                  \n",
      " pool_0_ACT_QUANT (Activati  (None, 64, 128, 60)          0         ['pool_0_CONCAT[0][0]']       \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONV (Conv2D)        (None, 64, 128, 30)          1830      ['pool_0_ACT_QUANT[0][0]']    \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_1 (Conv2D)   (None, 32, 64, 60)           16200     ['pool_0_CONV[0][0]']         \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_1 (Conv2D)   (None, 16, 32, 240)          129600    ['BLOCK_1-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-4_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_1 (Conv2D)   (None, 16, 32, 640)          76800     ['BLOCK_2-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_1 (BatchNorma  (None, 16, 32, 640)          2560      ['BLOCK_3-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_1 (Activatio  (None, 16, 32, 640)          0         ['BLOCK_3-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-5_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-5_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-5_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-5_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-5_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-5_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-5_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-5_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-5_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-5_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-5_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_1 (Conv2D)   (None, 8, 16, 1120)          179200    ['BLOCK_3-5_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_1 (BatchNorma  (None, 8, 16, 1120)          4480      ['BLOCK_4-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_1 (Activatio  (None, 8, 16, 1120)          0         ['BLOCK_4-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BNORM_POST_NOQUANT (BatchN  (None, 4, 8, 280)            1120      ['BLOCK_4-4_ADD[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ACT_POST (Activation)       (None, 4, 8, 280)            0         ['BNORM_POST_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " POST_CONV_1 (Conv2D)        (None, 2, 6, 420)            1058400   ['ACT_POST[0][0]']            \n",
      "                                                                                                  \n",
      " POST_BN_1 (BatchNormalizat  (None, 2, 6, 420)            1680      ['POST_CONV_1[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " POST_ACT_1 (Activation)     (None, 2, 6, 420)            0         ['POST_BN_1[0][0]']           \n",
      "                                                                                                  \n",
      " GLOBAL_LME_POOL (GlobalLog  (None, 420)                  1         ['POST_ACT_1[0][0]']          \n",
      " ExpPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " CLASS_DENSE_1 (Dense)       (None, 2434)                 1024714   ['GLOBAL_LME_POOL[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7604470 (29.01 MB)\n",
      "Trainable params: 7564848 (28.86 MB)\n",
      "Non-trainable params: 39622 (154.77 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7479e6-c2be-4175-9188-d7f1d985a83e",
   "metadata": {},
   "source": [
    "# Remove last fully connected Layer  \"CLASS_DENSE_1 (Dense)\"  with shape     (None, 2434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4e06c0-092c-4bfd-88bd-4bf7d89b8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model2 = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636f19a2-c7b3-44c3-b57c-4247e9d755d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " INPUT (InputLayer)          [(None, 144000)]             0         []                            \n",
      "                                                                                                  \n",
      " ADVANCED_SPEC1 (LinearSpec  (None, 128, 513, 1)          1         ['INPUT[0][0]']               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " BNORM_SPEC_NOQUANT (BatchN  (None, 128, 513, 1)          4         ['ADVANCED_SPEC1[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " CONV_0 (Conv2D)             (None, 64, 257, 30)          960       ['BNORM_SPEC_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " BNORM_0 (BatchNormalizatio  (None, 64, 257, 30)          120       ['CONV_0[0][0]']              \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " ACT_0 (Activation)          (None, 64, 257, 30)          0         ['BNORM_0[0][0]']             \n",
      "                                                                                                  \n",
      " pool_0_MAX (MaxPooling2D)   (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      "                                                                                                  \n",
      " pool_0_AVG (AveragePooling  (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONCAT (Concatenate  (None, 64, 128, 60)          0         ['pool_0_MAX[0][0]',          \n",
      " )                                                                   'pool_0_AVG[0][0]']          \n",
      "                                                                                                  \n",
      " pool_0_ACT_QUANT (Activati  (None, 64, 128, 60)          0         ['pool_0_CONCAT[0][0]']       \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONV (Conv2D)        (None, 64, 128, 30)          1830      ['pool_0_ACT_QUANT[0][0]']    \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_1 (Conv2D)   (None, 32, 64, 60)           16200     ['pool_0_CONV[0][0]']         \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_1 (Conv2D)   (None, 16, 32, 240)          129600    ['BLOCK_1-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-4_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_1 (Conv2D)   (None, 16, 32, 640)          76800     ['BLOCK_2-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_1 (BatchNorma  (None, 16, 32, 640)          2560      ['BLOCK_3-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_1 (Activatio  (None, 16, 32, 640)          0         ['BLOCK_3-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-5_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-5_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-5_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-5_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-5_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-5_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-5_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-5_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-5_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-5_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-5_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_1 (Conv2D)   (None, 8, 16, 1120)          179200    ['BLOCK_3-5_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_1 (BatchNorma  (None, 8, 16, 1120)          4480      ['BLOCK_4-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_1 (Activatio  (None, 8, 16, 1120)          0         ['BLOCK_4-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BNORM_POST_NOQUANT (BatchN  (None, 4, 8, 280)            1120      ['BLOCK_4-4_ADD[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ACT_POST (Activation)       (None, 4, 8, 280)            0         ['BNORM_POST_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " POST_CONV_1 (Conv2D)        (None, 2, 6, 420)            1058400   ['ACT_POST[0][0]']            \n",
      "                                                                                                  \n",
      " POST_BN_1 (BatchNormalizat  (None, 2, 6, 420)            1680      ['POST_CONV_1[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " POST_ACT_1 (Activation)     (None, 2, 6, 420)            0         ['POST_BN_1[0][0]']           \n",
      "                                                                                                  \n",
      " GLOBAL_LME_POOL (GlobalLog  (None, 420)                  1         ['POST_ACT_1[0][0]']          \n",
      " ExpPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6579756 (25.10 MB)\n",
      "Trainable params: 6540134 (24.95 MB)\n",
      "Non-trainable params: 39622 (154.77 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfec071-c973-48d2-95ba-a993d60f0848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd4s2nu6_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd4s2nu6_/assets\n",
      "2023-10-07 15:11:16.351078: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-10-07 15:11:16.351180: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-10-07 15:11:16.352051: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpd4s2nu6_\n",
      "2023-10-07 15:11:16.384959: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-10-07 15:11:16.385045: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpd4s2nu6_\n",
      "2023-10-07 15:11:16.450268: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-10-07 15:11:16.476855: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-10-07 15:11:16.914069: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpd4s2nu6_\n",
      "2023-10-07 15:11:17.094200: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 742148 microseconds.\n",
      "2023-10-07 15:11:17.314918: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Converting\n"
     ]
    }
   ],
   "source": [
    "# Convert the keras model to a tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
    "tflite_model2 = converter.convert()\n",
    "\n",
    "print(\"Finished Converting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b85b81-cd6b-431b-8876-ea04690776ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Saving\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "with open('/home/jovyan/20230717_test_layer_remove.tflite', 'wb') as f:\n",
    "    f.write(tflite_model2)\n",
    "print(\"Finished Saving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc550b-c5cd-4961-a987-d4f5d353fdb5",
   "metadata": {},
   "source": [
    "# Analyze the saved tflite models, original vs. removed dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175fca4e-b01d-4499-8bd6-0240878c4103",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== /home/jovyan/models/origin/BirdNET-Analyzer/checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_Model_FP32.tflite ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the REDUCE_MIN op takes\n",
      "tensor #0 and tensor #117 as input and produces tensor #143 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#404]\n",
      "  Op#0 REDUCE_MIN(T#0, T#117[1]) -> [T#143]\n",
      "  Op#1 SUB(T#0, T#143) -> [T#144]\n",
      "  Op#2 REDUCE_MAX(T#144, T#117[1]) -> [T#145]\n",
      "  Op#3 DIV(T#144, T#145) -> [T#146]\n",
      "  Op#4 SHAPE(T#146) -> [T#147]\n",
      "  Op#5 SPLIT_V(T#147, T#116[1, 1, 0], T#120[0]) -> [T#148, T#149, T#150]\n",
      "  Op#6 RESHAPE(T#149, T#121[]) -> [T#151]\n",
      "  Op#7 FLOOR_DIV(T#151, T#122[8]) -> [T#152]\n",
      "  Op#8 PACK(T#152, T#122[8]) -> [T#153]\n",
      "  Op#9 MUL(T#152, T#122[8]) -> [T#154]\n",
      "  Op#10 RESHAPE(T#154, T#124[1]) -> [T#155]\n",
      "  Op#11 CONCATENATION(T#148, T#155) -> [T#156]\n",
      "  Op#12 CONCATENATION(T#148, T#153) -> [T#157]\n",
      "  Op#13 STRIDED_SLICE(T#146, T#125[0, 0], T#156, T#118[1, 1]) -> [T#158]\n",
      "  Op#14 RESHAPE(T#158, T#157) -> [T#159]\n",
      "  Op#15 SUB(T#151, T#126[512]) -> [T#160]\n",
      "  Op#16 FLOOR_DIV(T#160, T#127[280]) -> [T#161]\n",
      "  Op#17 ADD(T#161, T#117[1]) -> [T#162]\n",
      "  Op#18 MAXIMUM(T#162, T#120[0]) -> [T#163]\n",
      "  Op#19 PACK(T#163, T#117[1]) -> [T#164]\n",
      "  Op#20 PACK(T#163, T#126[512]) -> [T#165]\n",
      "  Op#21 CONCATENATION(T#148, T#165) -> [T#166]\n",
      "  Op#22 RANGE(T#120[0], T#163, T#117[1]) -> [T#167]\n",
      "  Op#23 MUL(T#167, T#114[35]) -> [T#168]\n",
      "  Op#24 RESHAPE(T#168, T#164) -> [T#169]\n",
      "  Op#25 ADD(T#169, T#115[0, 1, 2, 3, 4, ...]) -> [T#170]\n",
      "  Op#26 GATHER(T#159, T#170) -> [T#171]\n",
      "  Op#27 RESHAPE(T#171, T#166) -> [T#172]\n",
      "  Op#28 MUL(T#172, T#113) -> [T#173]\n",
      "  Op#29 EXPAND_DIMS(T#173, T#111[-2]) -> [T#174]\n",
      "  Op#30 RFFT2D(T#174, T#112[1, 512]) -> [T#175]\n",
      "  Op#31 SQUEEZE(T#175) -> [T#176]\n",
      "  Op#32 CAST(T#176) -> [T#177]\n",
      "  Op#33 STRIDED_SLICE(T#177, T#128[0, 0, 0], T#129[0, 0, 128], T#130[1, 1, 1]) -> [T#178]\n",
      "  Op#34 MUL(T#178, T#178) -> [T#179]\n",
      "  Op#35 POW(T#179, T#137) -> [T#180]\n",
      "  Op#36 TRANSPOSE(T#180, T#131[0, 2, 1]) -> [T#181]\n",
      "  Op#37 EXPAND_DIMS(T#181, T#119[-1]) -> [T#182]\n",
      "  Op#38 MUL(T#182, T#141) -> [T#183]\n",
      "  Op#39 ADD(T#183, T#140) -> [T#184]\n",
      "  Op#40 CONV_2D(T#184, T#110, T#53) -> [T#185]\n",
      "  Op#41 AVERAGE_POOL_2D(T#185) -> [T#186]\n",
      "  Op#42 MAX_POOL_2D(T#185) -> [T#187]\n",
      "  Op#43 CONCATENATION(T#187, T#186) -> [T#188]\n",
      "  Op#44 CONV_2D(T#188, T#109, T#52) -> [T#189]\n",
      "  Op#45 CONV_2D(T#189, T#108, T#51) -> [T#190]\n",
      "  Op#46 LOGISTIC(T#190) -> [T#191]\n",
      "  Op#47 MUL(T#190, T#191) -> [T#192]\n",
      "  Op#48 CONV_2D(T#192, T#107, T#50) -> [T#193]\n",
      "  Op#49 CONV_2D(T#193, T#106, T#49) -> [T#194]\n",
      "  Op#50 LOGISTIC(T#194) -> [T#195]\n",
      "  Op#51 MUL(T#194, T#195) -> [T#196]\n",
      "  Op#52 CONV_2D(T#196, T#105, T#48) -> [T#197]\n",
      "  Op#53 ADD(T#197, T#193) -> [T#198]\n",
      "  Op#54 CONV_2D(T#198, T#104, T#47) -> [T#199]\n",
      "  Op#55 LOGISTIC(T#199) -> [T#200]\n",
      "  Op#56 MUL(T#199, T#200) -> [T#201]\n",
      "  Op#57 CONV_2D(T#201, T#103, T#46) -> [T#202]\n",
      "  Op#58 ADD(T#202, T#198) -> [T#203]\n",
      "  Op#59 CONV_2D(T#203, T#102, T#45) -> [T#204]\n",
      "  Op#60 LOGISTIC(T#204) -> [T#205]\n",
      "  Op#61 MUL(T#204, T#205) -> [T#206]\n",
      "  Op#62 CONV_2D(T#206, T#101, T#44) -> [T#207]\n",
      "  Op#63 CONV_2D(T#207, T#100, T#43) -> [T#208]\n",
      "  Op#64 LOGISTIC(T#208) -> [T#209]\n",
      "  Op#65 MUL(T#208, T#209) -> [T#210]\n",
      "  Op#66 CONV_2D(T#210, T#99, T#42) -> [T#211]\n",
      "  Op#67 ADD(T#211, T#207) -> [T#212]\n",
      "  Op#68 CONV_2D(T#212, T#98, T#41) -> [T#213]\n",
      "  Op#69 LOGISTIC(T#213) -> [T#214]\n",
      "  Op#70 MUL(T#213, T#214) -> [T#215]\n",
      "  Op#71 CONV_2D(T#215, T#97, T#40) -> [T#216]\n",
      "  Op#72 ADD(T#216, T#212) -> [T#217]\n",
      "  Op#73 CONV_2D(T#217, T#96, T#39) -> [T#218]\n",
      "  Op#74 LOGISTIC(T#218) -> [T#219]\n",
      "  Op#75 MUL(T#218, T#219) -> [T#220]\n",
      "  Op#76 CONV_2D(T#220, T#95, T#38) -> [T#221]\n",
      "  Op#77 ADD(T#221, T#217) -> [T#222]\n",
      "  Op#78 CONV_2D(T#222, T#94, T#37) -> [T#223]\n",
      "  Op#79 LOGISTIC(T#223) -> [T#224]\n",
      "  Op#80 MUL(T#223, T#224) -> [T#225]\n",
      "  Op#81 DEPTHWISE_CONV_2D(T#225, T#36, T#35) -> [T#226]\n",
      "  Op#82 LOGISTIC(T#226) -> [T#227]\n",
      "  Op#83 MUL(T#226, T#227) -> [T#228]\n",
      "  Op#84 MEAN(T#228, T#132[1, 2]) -> [T#229]\n",
      "  Op#85 SHAPE(T#229) -> [T#230]\n",
      "  Op#86 STRIDED_SLICE(T#230, T#123[0], T#124[1], T#124[1]) -> [T#231]\n",
      "  Op#87 PACK(T#231, T#117[1], T#117[1], T#133[640]) -> [T#232]\n",
      "  Op#88 RESHAPE(T#229, T#232) -> [T#233]\n",
      "  Op#89 CONV_2D(T#233, T#92, T#91) -> [T#234]\n",
      "  Op#90 LOGISTIC(T#234) -> [T#235]\n",
      "  Op#91 MUL(T#234, T#235) -> [T#236]\n",
      "  Op#92 CONV_2D(T#236, T#90, T#93) -> [T#237]\n",
      "  Op#93 LOGISTIC(T#237) -> [T#238]\n",
      "  Op#94 MUL(T#228, T#238) -> [T#239]\n",
      "  Op#95 CONV_2D(T#239, T#89, T#34) -> [T#240]\n",
      "  Op#96 CONV_2D(T#240, T#88, T#33) -> [T#241]\n",
      "  Op#97 LOGISTIC(T#241) -> [T#242]\n",
      "  Op#98 MUL(T#241, T#242) -> [T#243]\n",
      "  Op#99 DEPTHWISE_CONV_2D(T#243, T#32, T#31) -> [T#244]\n",
      "  Op#100 LOGISTIC(T#244) -> [T#245]\n",
      "  Op#101 MUL(T#244, T#245) -> [T#246]\n",
      "  Op#102 MEAN(T#246, T#132[1, 2]) -> [T#247]\n",
      "  Op#103 SHAPE(T#247) -> [T#248]\n",
      "  Op#104 STRIDED_SLICE(T#248, T#123[0], T#124[1], T#124[1]) -> [T#249]\n",
      "  Op#105 PACK(T#249, T#117[1], T#117[1], T#133[640]) -> [T#250]\n",
      "  Op#106 RESHAPE(T#247, T#250) -> [T#251]\n",
      "  Op#107 CONV_2D(T#251, T#87, T#91) -> [T#252]\n",
      "  Op#108 LOGISTIC(T#252) -> [T#253]\n",
      "  Op#109 MUL(T#252, T#253) -> [T#254]\n",
      "  Op#110 CONV_2D(T#254, T#86, T#93) -> [T#255]\n",
      "  Op#111 LOGISTIC(T#255) -> [T#256]\n",
      "  Op#112 MUL(T#246, T#256) -> [T#257]\n",
      "  Op#113 CONV_2D(T#257, T#85, T#30) -> [T#258]\n",
      "  Op#114 ADD(T#258, T#240) -> [T#259]\n",
      "  Op#115 CONV_2D(T#259, T#84, T#29) -> [T#260]\n",
      "  Op#116 LOGISTIC(T#260) -> [T#261]\n",
      "  Op#117 MUL(T#260, T#261) -> [T#262]\n",
      "  Op#118 DEPTHWISE_CONV_2D(T#262, T#28, T#27) -> [T#263]\n",
      "  Op#119 LOGISTIC(T#263) -> [T#264]\n",
      "  Op#120 MUL(T#263, T#264) -> [T#265]\n",
      "  Op#121 MEAN(T#265, T#132[1, 2]) -> [T#266]\n",
      "  Op#122 SHAPE(T#266) -> [T#267]\n",
      "  Op#123 STRIDED_SLICE(T#267, T#123[0], T#124[1], T#124[1]) -> [T#268]\n",
      "  Op#124 PACK(T#268, T#117[1], T#117[1], T#133[640]) -> [T#269]\n",
      "  Op#125 RESHAPE(T#266, T#269) -> [T#270]\n",
      "  Op#126 CONV_2D(T#270, T#83, T#91) -> [T#271]\n",
      "  Op#127 LOGISTIC(T#271) -> [T#272]\n",
      "  Op#128 MUL(T#271, T#272) -> [T#273]\n",
      "  Op#129 CONV_2D(T#273, T#82, T#93) -> [T#274]\n",
      "  Op#130 LOGISTIC(T#274) -> [T#275]\n",
      "  Op#131 MUL(T#265, T#275) -> [T#276]\n",
      "  Op#132 CONV_2D(T#276, T#81, T#26) -> [T#277]\n",
      "  Op#133 ADD(T#277, T#259) -> [T#278]\n",
      "  Op#134 CONV_2D(T#278, T#80, T#25) -> [T#279]\n",
      "  Op#135 LOGISTIC(T#279) -> [T#280]\n",
      "  Op#136 MUL(T#279, T#280) -> [T#281]\n",
      "  Op#137 DEPTHWISE_CONV_2D(T#281, T#24, T#23) -> [T#282]\n",
      "  Op#138 LOGISTIC(T#282) -> [T#283]\n",
      "  Op#139 MUL(T#282, T#283) -> [T#284]\n",
      "  Op#140 MEAN(T#284, T#132[1, 2]) -> [T#285]\n",
      "  Op#141 SHAPE(T#285) -> [T#286]\n",
      "  Op#142 STRIDED_SLICE(T#286, T#123[0], T#124[1], T#124[1]) -> [T#287]\n",
      "  Op#143 PACK(T#287, T#117[1], T#117[1], T#133[640]) -> [T#288]\n",
      "  Op#144 RESHAPE(T#285, T#288) -> [T#289]\n",
      "  Op#145 CONV_2D(T#289, T#79, T#91) -> [T#290]\n",
      "  Op#146 LOGISTIC(T#290) -> [T#291]\n",
      "  Op#147 MUL(T#290, T#291) -> [T#292]\n",
      "  Op#148 CONV_2D(T#292, T#78, T#93) -> [T#293]\n",
      "  Op#149 LOGISTIC(T#293) -> [T#294]\n",
      "  Op#150 MUL(T#284, T#294) -> [T#295]\n",
      "  Op#151 CONV_2D(T#295, T#77, T#22) -> [T#296]\n",
      "  Op#152 ADD(T#296, T#278) -> [T#297]\n",
      "  Op#153 CONV_2D(T#297, T#76, T#21) -> [T#298]\n",
      "  Op#154 LOGISTIC(T#298) -> [T#299]\n",
      "  Op#155 MUL(T#298, T#299) -> [T#300]\n",
      "  Op#156 DEPTHWISE_CONV_2D(T#300, T#20, T#19) -> [T#301]\n",
      "  Op#157 LOGISTIC(T#301) -> [T#302]\n",
      "  Op#158 MUL(T#301, T#302) -> [T#303]\n",
      "  Op#159 MEAN(T#303, T#132[1, 2]) -> [T#304]\n",
      "  Op#160 SHAPE(T#304) -> [T#305]\n",
      "  Op#161 STRIDED_SLICE(T#305, T#123[0], T#124[1], T#124[1]) -> [T#306]\n",
      "  Op#162 PACK(T#306, T#117[1], T#117[1], T#133[640]) -> [T#307]\n",
      "  Op#163 RESHAPE(T#304, T#307) -> [T#308]\n",
      "  Op#164 CONV_2D(T#308, T#75, T#91) -> [T#309]\n",
      "  Op#165 LOGISTIC(T#309) -> [T#310]\n",
      "  Op#166 MUL(T#309, T#310) -> [T#311]\n",
      "  Op#167 CONV_2D(T#311, T#74, T#93) -> [T#312]\n",
      "  Op#168 LOGISTIC(T#312) -> [T#313]\n",
      "  Op#169 MUL(T#303, T#313) -> [T#314]\n",
      "  Op#170 CONV_2D(T#314, T#73, T#18) -> [T#315]\n",
      "  Op#171 ADD(T#315, T#297) -> [T#316]\n",
      "  Op#172 CONV_2D(T#316, T#72, T#17) -> [T#317]\n",
      "  Op#173 LOGISTIC(T#317) -> [T#318]\n",
      "  Op#174 MUL(T#317, T#318) -> [T#319]\n",
      "  Op#175 DEPTHWISE_CONV_2D(T#319, T#16, T#15) -> [T#320]\n",
      "  Op#176 LOGISTIC(T#320) -> [T#321]\n",
      "  Op#177 MUL(T#320, T#321) -> [T#322]\n",
      "  Op#178 MEAN(T#322, T#132[1, 2]) -> [T#323]\n",
      "  Op#179 SHAPE(T#323) -> [T#324]\n",
      "  Op#180 STRIDED_SLICE(T#324, T#123[0], T#124[1], T#124[1]) -> [T#325]\n",
      "  Op#181 PACK(T#325, T#117[1], T#117[1], T#134[1120]) -> [T#326]\n",
      "  Op#182 RESHAPE(T#323, T#326) -> [T#327]\n",
      "  Op#183 CONV_2D(T#327, T#70, T#69) -> [T#328]\n",
      "  Op#184 LOGISTIC(T#328) -> [T#329]\n",
      "  Op#185 MUL(T#328, T#329) -> [T#330]\n",
      "  Op#186 CONV_2D(T#330, T#68, T#71) -> [T#331]\n",
      "  Op#187 LOGISTIC(T#331) -> [T#332]\n",
      "  Op#188 MUL(T#322, T#332) -> [T#333]\n",
      "  Op#189 CONV_2D(T#333, T#67, T#14) -> [T#334]\n",
      "  Op#190 CONV_2D(T#334, T#66, T#13) -> [T#335]\n",
      "  Op#191 LOGISTIC(T#335) -> [T#336]\n",
      "  Op#192 MUL(T#335, T#336) -> [T#337]\n",
      "  Op#193 DEPTHWISE_CONV_2D(T#337, T#12, T#11) -> [T#338]\n",
      "  Op#194 LOGISTIC(T#338) -> [T#339]\n",
      "  Op#195 MUL(T#338, T#339) -> [T#340]\n",
      "  Op#196 MEAN(T#340, T#132[1, 2]) -> [T#341]\n",
      "  Op#197 SHAPE(T#341) -> [T#342]\n",
      "  Op#198 STRIDED_SLICE(T#342, T#123[0], T#124[1], T#124[1]) -> [T#343]\n",
      "  Op#199 PACK(T#343, T#117[1], T#117[1], T#134[1120]) -> [T#344]\n",
      "  Op#200 RESHAPE(T#341, T#344) -> [T#345]\n",
      "  Op#201 CONV_2D(T#345, T#65, T#69) -> [T#346]\n",
      "  Op#202 LOGISTIC(T#346) -> [T#347]\n",
      "  Op#203 MUL(T#346, T#347) -> [T#348]\n",
      "  Op#204 CONV_2D(T#348, T#64, T#71) -> [T#349]\n",
      "  Op#205 LOGISTIC(T#349) -> [T#350]\n",
      "  Op#206 MUL(T#340, T#350) -> [T#351]\n",
      "  Op#207 CONV_2D(T#351, T#63, T#10) -> [T#352]\n",
      "  Op#208 ADD(T#352, T#334) -> [T#353]\n",
      "  Op#209 CONV_2D(T#353, T#62, T#9) -> [T#354]\n",
      "  Op#210 LOGISTIC(T#354) -> [T#355]\n",
      "  Op#211 MUL(T#354, T#355) -> [T#356]\n",
      "  Op#212 DEPTHWISE_CONV_2D(T#356, T#8, T#7) -> [T#357]\n",
      "  Op#213 LOGISTIC(T#357) -> [T#358]\n",
      "  Op#214 MUL(T#357, T#358) -> [T#359]\n",
      "  Op#215 MEAN(T#359, T#132[1, 2]) -> [T#360]\n",
      "  Op#216 SHAPE(T#360) -> [T#361]\n",
      "  Op#217 STRIDED_SLICE(T#361, T#123[0], T#124[1], T#124[1]) -> [T#362]\n",
      "  Op#218 PACK(T#362, T#117[1], T#117[1], T#134[1120]) -> [T#363]\n",
      "  Op#219 RESHAPE(T#360, T#363) -> [T#364]\n",
      "  Op#220 CONV_2D(T#364, T#61, T#69) -> [T#365]\n",
      "  Op#221 LOGISTIC(T#365) -> [T#366]\n",
      "  Op#222 MUL(T#365, T#366) -> [T#367]\n",
      "  Op#223 CONV_2D(T#367, T#60, T#71) -> [T#368]\n",
      "  Op#224 LOGISTIC(T#368) -> [T#369]\n",
      "  Op#225 MUL(T#359, T#369) -> [T#370]\n",
      "  Op#226 CONV_2D(T#370, T#59, T#6) -> [T#371]\n",
      "  Op#227 ADD(T#371, T#353) -> [T#372]\n",
      "  Op#228 CONV_2D(T#372, T#58, T#5) -> [T#373]\n",
      "  Op#229 LOGISTIC(T#373) -> [T#374]\n",
      "  Op#230 MUL(T#373, T#374) -> [T#375]\n",
      "  Op#231 DEPTHWISE_CONV_2D(T#375, T#4, T#3) -> [T#376]\n",
      "  Op#232 LOGISTIC(T#376) -> [T#377]\n",
      "  Op#233 MUL(T#376, T#377) -> [T#378]\n",
      "  Op#234 MEAN(T#378, T#132[1, 2]) -> [T#379]\n",
      "  Op#235 SHAPE(T#379) -> [T#380]\n",
      "  Op#236 STRIDED_SLICE(T#380, T#123[0], T#124[1], T#124[1]) -> [T#381]\n",
      "  Op#237 PACK(T#381, T#117[1], T#117[1], T#134[1120]) -> [T#382]\n",
      "  Op#238 RESHAPE(T#379, T#382) -> [T#383]\n",
      "  Op#239 CONV_2D(T#383, T#57, T#69) -> [T#384]\n",
      "  Op#240 LOGISTIC(T#384) -> [T#385]\n",
      "  Op#241 MUL(T#384, T#385) -> [T#386]\n",
      "  Op#242 CONV_2D(T#386, T#56, T#71) -> [T#387]\n",
      "  Op#243 LOGISTIC(T#387) -> [T#388]\n",
      "  Op#244 MUL(T#378, T#388) -> [T#389]\n",
      "  Op#245 CONV_2D(T#389, T#55, T#2) -> [T#390]\n",
      "  Op#246 ADD(T#390, T#372) -> [T#391]\n",
      "  Op#247 MUL(T#391, T#139) -> [T#392]\n",
      "  Op#248 ADD(T#392, T#138) -> [T#393]\n",
      "  Op#249 CONV_2D(T#393, T#54, T#1) -> [T#394]\n",
      "  Op#250 REDUCE_MAX(T#394, T#132[1, 2]) -> [T#395]\n",
      "  Op#251 REDUCE_MAX(T#394, T#132[1, 2]) -> [T#396]\n",
      "  Op#252 SUB(T#394, T#395) -> [T#397]\n",
      "  Op#253 MUL(T#397, T#136) -> [T#398]\n",
      "  Op#254 EXP(T#398) -> [T#399]\n",
      "  Op#255 MEAN(T#399, T#132[1, 2]) -> [T#400]\n",
      "  Op#256 LOG(T#400) -> [T#401]\n",
      "  Op#257 DIV(T#401, T#136) -> [T#402]\n",
      "  Op#258 ADD(T#402, T#396) -> [T#403]\n",
      "  Op#259 FULLY_CONNECTED(T#403, T#142, T#135) -> [T#404]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(INPUT) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#1(model/POST_BN_1/FusedBatchNormV3;model/POST_CONV_1/Conv2D) shape:[420], type:FLOAT32 RO 1680 bytes, buffer: 2, data:[0.703291, 0.151619, 0.929611, 1.05721, -0.0952325, ...]\n",
      "  T#2(model/BLOCK_4-4_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D;model/BLOCK_4-4_CONV_3/Conv2D) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 3, data:[-0.303293, -0.566926, -0.164678, -0.409574, -0.311323, ...]\n",
      "  T#3(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-4_CONV_2/depthwise) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 4, data:[0.03562, -0.442556, 0.242526, -0.189173, -0.137097, ...]\n",
      "  T#4(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_CONV_2/depthwise;model/BLOCK_4-1_CONV_1/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 5, data:[-0.213518, -0.135148, -0.603809, -0.559516, -0.379189, ...]\n",
      "  T#5(model/BLOCK_4-4_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-4_CONV_1/Conv2D) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 6, data:[-1.24407, -0.0376666, -1.2601, -0.504979, -0.504578, ...]\n",
      "  T#6(model/BLOCK_4-3_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D;model/BLOCK_4-3_CONV_3/Conv2D) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 7, data:[0.0840644, -0.110269, -0.105898, -0.161293, -0.123441, ...]\n",
      "  T#7(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-3_CONV_2/depthwise) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 8, data:[0.0843629, -0.0535078, -0.136284, -0.35959, 0.137284, ...]\n",
      "  T#8(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-3_CONV_2/depthwise;model/BLOCK_4-1_CONV_1/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 9, data:[-0.734297, 0.403795, -5.34587, 0.876589, 0.309243, ...]\n",
      "  T#9(model/BLOCK_4-3_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-3_CONV_1/Conv2D) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 10, data:[-0.212481, -1.1889, -0.0504375, 0.146119, -0.779445, ...]\n",
      "  T#10(model/BLOCK_4-2_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D;model/BLOCK_4-2_CONV_3/Conv2D) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 11, data:[-0.0310575, -0.01638, -0.0170814, -0.0743111, -0.0226622, ...]\n",
      "  T#11(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-2_CONV_2/depthwise) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 12, data:[0.00732364, -0.15787, -0.631158, -0.106697, 0.0196075, ...]\n",
      "  T#12(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-2_CONV_2/depthwise;model/BLOCK_4-1_CONV_1/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 13, data:[-0.791778, -0.210047, -0.88355, -0.441906, -0.494887, ...]\n",
      "  T#13(model/BLOCK_4-2_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-2_CONV_1/Conv2D) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 14, data:[0.214278, 0.192685, 0.0268124, -0.538281, -0.227158, ...]\n",
      "  T#14(model/BLOCK_4-1_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 15, data:[0.00707362, -0.11092, -0.271591, -0.0480711, 0.1141, ...]\n",
      "  T#15(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-1_CONV_2/depthwise) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 16, data:[-0.213642, 0.0989731, 0.289327, 0.228966, -0.0641489, ...]\n",
      "  T#16(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_2/depthwise;model/BLOCK_4-1_CONV_1/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 17, data:[-0.313297, -0.692159, 1.42914, -0.135559, -0.402629, ...]\n",
      "  T#17(model/BLOCK_4-1_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 18, data:[-0.501423, -0.781778, -1.06513, -0.807659, -0.451615, ...]\n",
      "  T#18(model/BLOCK_3-5_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-5_CONV_3/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 19, data:[-0.0729527, -0.140453, -0.256495, 0.00789576, -0.0750102, ...]\n",
      "  T#19(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-5_CONV_2/depthwise) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 20, data:[0.199295, -0.693983, -0.0609956, -0.305395, -0.0527331, ...]\n",
      "  T#20(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_CONV_2/depthwise;model/BLOCK_3-1_CONV_1/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 21, data:[0.358909, -0.200586, 1.62531, 0.189931, 0.597165, ...]\n",
      "  T#21(model/BLOCK_3-5_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-5_CONV_1/Conv2D) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 22, data:[-1.13443, 0.0416078, -0.161235, -1.03465, -0.414547, ...]\n",
      "  T#22(model/BLOCK_3-4_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-4_CONV_3/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 23, data:[0.0162673, -0.223772, -0.0793594, 0.196439, 0.0911259, ...]\n",
      "  T#23(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-4_CONV_2/depthwise) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 24, data:[-0.167197, -0.627172, -0.118439, -0.0867302, -0.0966517, ...]\n",
      "  T#24(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-4_CONV_2/depthwise;model/BLOCK_3-1_CONV_1/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 25, data:[-0.10532, -0.530738, 0.000815318, 0.0100449, 0.0389737, ...]\n",
      "  T#25(model/BLOCK_3-4_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-4_CONV_1/Conv2D) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 26, data:[-0.280375, 0.916876, -0.271838, 0.260631, 0.065035, ...]\n",
      "  T#26(model/BLOCK_3-3_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-3_CONV_3/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 27, data:[0.00867989, -0.0112237, -0.166217, 0.266443, -0.436209, ...]\n",
      "  T#27(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-3_CONV_2/depthwise) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 28, data:[-0.052932, -0.15776, -0.162979, -1.74901, -0.0601944, ...]\n",
      "  T#28(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-3_CONV_2/depthwise;model/BLOCK_3-1_CONV_1/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 29, data:[0.123467, -0.0474579, 0.25923, -0.762767, -0.0930023, ...]\n",
      "  T#29(model/BLOCK_3-3_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-3_CONV_1/Conv2D) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 30, data:[1.04701, 0.565516, -0.577064, 0.252158, -0.205602, ...]\n",
      "  T#30(model/BLOCK_3-2_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-2_CONV_3/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 31, data:[-0.245983, -0.00641132, -0.0371882, 0.126828, -0.0948737, ...]\n",
      "  T#31(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-2_CONV_2/depthwise) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 32, data:[0.156241, 0.10379, -0.12009, 0.251382, -0.321336, ...]\n",
      "  T#32(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-2_CONV_2/depthwise;model/BLOCK_3-1_CONV_1/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 33, data:[1.23551, -0.0568431, 0.0760742, -0.370292, 0.0261757, ...]\n",
      "  T#33(model/BLOCK_3-2_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-2_CONV_1/Conv2D) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 34, data:[-0.530656, 0.133959, 0.382794, -0.28108, -0.106207, ...]\n",
      "  T#34(model/BLOCK_3-1_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 35, data:[0.028477, -0.247231, -0.271764, -0.436009, -0.0308246, ...]\n",
      "  T#35(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-1_CONV_2/depthwise) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 36, data:[0.507101, 0.170648, 0.0986953, 0.264744, 0.368448, ...]\n",
      "  T#36(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_2/depthwise;model/BLOCK_3-1_CONV_1/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 37, data:[-0.251236, 0.372286, -0.59223, -0.1335, 0.312628, ...]\n",
      "  T#37(model/BLOCK_3-1_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 38, data:[0.453774, -0.53238, 0.144864, 0.0808757, -0.600901, ...]\n",
      "  T#38(model/BLOCK_2-4_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D;model/BLOCK_2-4_CONV_3/Conv2D) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 39, data:[-1.07128, -0.719374, 0.521283, -0.52695, 0.637195, ...]\n",
      "  T#39(model/BLOCK_2-4_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D;model/BLOCK_2-4_CONV_1/Conv2D) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 40, data:[-0.0566794, -0.325451, -0.0834246, 0.0485905, -0.249119, ...]\n",
      "  T#40(model/BLOCK_2-3_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D;model/BLOCK_2-3_CONV_3/Conv2D) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 41, data:[-0.334773, 0.358166, 0.595261, 0.789514, 0.299735, ...]\n",
      "  T#41(model/BLOCK_2-3_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D;model/BLOCK_2-3_CONV_1/Conv2D) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 42, data:[-0.624671, -0.705771, -0.00291163, -0.566265, 0.401846, ...]\n",
      "  T#42(model/BLOCK_2-2_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D;model/BLOCK_2-2_CONV_3/Conv2D) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 43, data:[-0.26637, 0.121703, 0.097885, -0.248943, 0.0860163, ...]\n",
      "  T#43(model/BLOCK_2-2_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D;model/BLOCK_2-2_CONV_1/Conv2D) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 44, data:[-0.453432, 0.0377011, 0.029025, -1.10252, 1.40118, ...]\n",
      "  T#44(model/BLOCK_2-1_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 45, data:[0.517984, 1.20353, -0.631186, -0.242215, -0.117523, ...]\n",
      "  T#45(model/BLOCK_2-1_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 46, data:[1.08094, 1.82718, 1.35988, 2.0496, 1.56324, ...]\n",
      "  T#46(model/BLOCK_1-3_BN_3/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-3_CONV_3/Conv2D) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 47, data:[0.224621, -0.89843, -0.404808, 2.08627, 0.154646, ...]\n",
      "  T#47(model/BLOCK_1-3_BN_1/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-3_CONV_1/Conv2D) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 48, data:[1.23824, 1.12686, 1.3523, -0.914098, 1.96378, ...]\n",
      "  T#48(model/BLOCK_1-2_BN_3/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-2_CONV_3/Conv2D) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 49, data:[-0.463809, 0.940085, -1.53324, 1.37461, 0.36683, ...]\n",
      "  T#49(model/BLOCK_1-2_BN_1/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-2_CONV_1/Conv2D) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 50, data:[-2.62731, -0.868263, 0.266521, 0.0349529, 0.854639, ...]\n",
      "  T#50(model/BLOCK_1-1_BN_3/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-1_CONV_3/Conv2D) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 51, data:[-0.572335, -0.296768, -1.17371, -0.676895, 1.66753, ...]\n",
      "  T#51(model/BLOCK_1-1_BN_1/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 52, data:[0.994801, 1.30954, 1.39498, 2.66734, 0.875943, ...]\n",
      "  T#52(model/pool_0_CONV/BiasAdd;model/CONV_0/Conv2D;model/pool_0_CONV/Conv2D;model/pool_0_CONV/BiasAdd/ReadVariableOp/resource) shape:[30], type:FLOAT32 RO 120 bytes, buffer: 53, data:[0.177993, -0.00336044, 1.49043, 0.208713, -0.283743, ...]\n",
      "  T#53(model/BNORM_0/FusedBatchNormV3;model/CONV_0/Conv2D) shape:[30], type:FLOAT32 RO 120 bytes, buffer: 54, data:[-0.0201999, 0.021001, -0.00927022, 0.157607, 1.64969, ...]\n",
      "  T#54(model/POST_CONV_1/Conv2D) shape:[420, 3, 3, 280], type:FLOAT32 RO 4233600 bytes, buffer: 55, data:[-0.0291094, -0.0061691, 0.0503138, 0.0581343, 0.0575725, ...]\n",
      "  T#55(model/BLOCK_4-4_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 56, data:[0.0212589, 0.056527, 0.0380439, 0.0511093, -0.128075, ...]\n",
      "  T#56(model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 57, data:[-0.212755, -0.172498, -0.269743, -0.014416, -0.32258, ...]\n",
      "  T#57(model/BLOCK_4-4_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 58, data:[-0.0174236, -0.051295, -0.0601223, 0.0875765, 0.0552255, ...]\n",
      "  T#58(model/BLOCK_4-4_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:FLOAT32 RO 1254400 bytes, buffer: 59, data:[0.140507, 0.0259408, -0.00318167, 0.0121001, 0.0472033, ...]\n",
      "  T#59(model/BLOCK_4-3_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 60, data:[-0.103587, 0.0651307, 0.0905246, 0.0311029, 0.0932062, ...]\n",
      "  T#60(model/BLOCK_4-3_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 61, data:[0.76853, 0.272858, -0.0406274, 0.128225, -0.261265, ...]\n",
      "  T#61(model/BLOCK_4-3_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 62, data:[-0.480569, -0.185401, -0.246157, -0.254998, 0.0226147, ...]\n",
      "  T#62(model/BLOCK_4-3_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:FLOAT32 RO 1254400 bytes, buffer: 63, data:[0.084308, -0.104739, -0.11943, 0.137802, -0.100788, ...]\n",
      "  T#63(model/BLOCK_4-2_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 64, data:[-0.0254576, -0.0813834, 0.019934, -0.0212499, 0.0630072, ...]\n",
      "  T#64(model/BLOCK_4-2_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 65, data:[-0.0556371, 0.0161514, -0.236468, 0.562922, 0.757015, ...]\n",
      "  T#65(model/BLOCK_4-2_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 66, data:[-0.432114, -0.0357772, -0.146629, 0.377912, -0.445993, ...]\n",
      "  T#66(model/BLOCK_4-2_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:FLOAT32 RO 1254400 bytes, buffer: 67, data:[0.0775721, 0.0300743, 0.0787118, 0.033277, 0.0518173, ...]\n",
      "  T#67(model/BLOCK_4-1_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 68, data:[0.155144, 0.03334, -0.0436219, -0.0635754, -0.0201717, ...]\n",
      "  T#68(model/BLOCK_4-1_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 69, data:[0.0107329, -0.25262, 0.189735, 0.519728, 0.306989, ...]\n",
      "  T#69(model/BLOCK_4-1_SE_CONV_1/Conv2D) shape:[70], type:FLOAT32 RO 280 bytes, buffer: 70, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#70(model/BLOCK_4-1_SE_CONV_1/Conv2D1) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 71, data:[-0.114728, -0.486454, -0.0725451, -0.105543, 0.206242, ...]\n",
      "  T#71(model/BLOCK_4-1_CONV_1/Conv2D) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 72, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#72(model/BLOCK_4-1_CONV_1/Conv2D1) shape:[1120, 1, 1, 160], type:FLOAT32 RO 716800 bytes, buffer: 73, data:[-0.0420035, 0.0268913, 0.0743375, -0.00304259, 0.0097754, ...]\n",
      "  T#73(model/BLOCK_3-5_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 74, data:[0.0355608, 0.139506, -0.0253758, -0.116553, -0.247544, ...]\n",
      "  T#74(model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 75, data:[-0.297735, 0.290233, -0.57969, 0.101273, 0.230248, ...]\n",
      "  T#75(model/BLOCK_3-5_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 76, data:[0.43411, -0.114498, -0.0396519, 0.3074, 0.0421896, ...]\n",
      "  T#76(model/BLOCK_3-5_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 77, data:[-0.0592428, -0.0289971, -0.0524392, 0.0252963, -0.00123223, ...]\n",
      "  T#77(model/BLOCK_3-4_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 78, data:[0.008953, -0.178044, 0.10984, 0.027595, -0.019051, ...]\n",
      "  T#78(model/BLOCK_3-4_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 79, data:[-0.275259, 0.620791, -0.201793, -0.390887, 0.389617, ...]\n",
      "  T#79(model/BLOCK_3-4_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 80, data:[0.335489, -0.0140383, -0.2259, 0.299023, -0.151196, ...]\n",
      "  T#80(model/BLOCK_3-4_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 81, data:[-0.0530763, 0.030002, -0.00109313, 0.00830229, 0.0295681, ...]\n",
      "  T#81(model/BLOCK_3-3_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 82, data:[0.216798, 0.0985735, 0.122017, 0.0663547, -0.0423421, ...]\n",
      "  T#82(model/BLOCK_3-3_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 83, data:[0.00274766, 0.154431, -0.3122, -0.710318, -0.0499839, ...]\n",
      "  T#83(model/BLOCK_3-3_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 84, data:[0.0227193, -0.0669719, 1.52158, -0.018394, 0.124296, ...]\n",
      "  T#84(model/BLOCK_3-3_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 85, data:[0.0131174, 0.00535706, 0.0266619, -0.0648822, 2.78373e-05, ...]\n",
      "  T#85(model/BLOCK_3-2_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 86, data:[0.0697687, -0.206735, 0.109114, 0.121937, 0.0107974, ...]\n",
      "  T#86(model/BLOCK_3-2_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 87, data:[0.317052, -0.00767023, -0.111318, -0.0870155, -0.0846622, ...]\n",
      "  T#87(model/BLOCK_3-2_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 88, data:[0.324125, 0.138069, 0.466153, -0.375846, 0.431644, ...]\n",
      "  T#88(model/BLOCK_3-2_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 89, data:[0.0597176, -0.0259545, -0.000706167, -0.0420036, -0.0490324, ...]\n",
      "  T#89(model/BLOCK_3-1_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 90, data:[0.183485, -0.0989058, -0.0867138, -0.158595, 0.155576, ...]\n",
      "  T#90(model/BLOCK_3-1_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 91, data:[0.477402, 0.774508, 0.414591, 0.138802, -0.0958745, ...]\n",
      "  T#91(model/BLOCK_3-1_SE_CONV_1/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes, buffer: 92, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#92(model/BLOCK_3-1_SE_CONV_1/Conv2D1) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 93, data:[-0.109894, -0.250427, 0.248698, 0.197855, -0.148598, ...]\n",
      "  T#93(model/BLOCK_3-1_CONV_1/Conv2D) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 94, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#94(model/BLOCK_3-1_CONV_1/Conv2D1) shape:[640, 1, 1, 120], type:FLOAT32 RO 307200 bytes, buffer: 95, data:[0.027395, -0.00337426, 0.0371208, 0.0296344, 0.0550245, ...]\n",
      "  T#95(model/BLOCK_2-4_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 96, data:[0.514776, -0.170025, -0.492848, -0.127949, 0.0632972, ...]\n",
      "  T#96(model/BLOCK_2-4_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:FLOAT32 RO 1036800 bytes, buffer: 97, data:[-0.00882176, -0.00886716, 0.0172686, -0.0173403, -0.0128443, ...]\n",
      "  T#97(model/BLOCK_2-3_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 98, data:[0.151803, -0.211548, 0.656866, 0.313801, 0.534047, ...]\n",
      "  T#98(model/BLOCK_2-3_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:FLOAT32 RO 1036800 bytes, buffer: 99, data:[-0.00990321, 0.00305605, -0.022679, 0.00943848, 0.0178133, ...]\n",
      "  T#99(model/BLOCK_2-2_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 100, data:[-0.231138, -0.155019, 0.0335709, -0.048346, -0.0636056, ...]\n",
      "  T#100(model/BLOCK_2-2_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:FLOAT32 RO 1036800 bytes, buffer: 101, data:[0.00415435, -0.00527662, 0.0250746, 0.00708887, -0.00520974, ...]\n",
      "  T#101(model/BLOCK_2-1_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 102, data:[-0.135052, 0.0525188, 0.0256257, 0.037241, 0.0417646, ...]\n",
      "  T#102(model/BLOCK_2-1_CONV_1/Conv2D) shape:[240, 3, 3, 60], type:FLOAT32 RO 518400 bytes, buffer: 103, data:[0.00682351, -0.0175564, 0.0204914, 0.0128379, -0.0155376, ...]\n",
      "  T#103(model/BLOCK_1-3_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:FLOAT32 RO 14400 bytes, buffer: 104, data:[-1.06982, 0.00182795, -0.394202, 0.0216375, -0.540149, ...]\n",
      "  T#104(model/BLOCK_1-3_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:FLOAT32 RO 129600 bytes, buffer: 105, data:[0.0081317, 0.0289496, -0.000417384, -0.00211003, 0.0340565, ...]\n",
      "  T#105(model/BLOCK_1-2_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:FLOAT32 RO 14400 bytes, buffer: 106, data:[-0.0832476, -0.232616, 0.087849, -0.123365, -0.185093, ...]\n",
      "  T#106(model/BLOCK_1-2_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:FLOAT32 RO 129600 bytes, buffer: 107, data:[0.00565977, -0.0041388, 0.000459343, -0.0186408, 0.00484244, ...]\n",
      "  T#107(model/BLOCK_1-1_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:FLOAT32 RO 14400 bytes, buffer: 108, data:[0.0903042, -0.0224403, 0.279139, 0.140995, -0.201996, ...]\n",
      "  T#108(model/BLOCK_1-1_CONV_1/Conv2D) shape:[60, 3, 3, 30], type:FLOAT32 RO 64800 bytes, buffer: 109, data:[-0.024668, 0.0393796, -0.00368801, 0.0139366, 0.0272781, ...]\n",
      "  T#109(model/pool_0_CONV/Conv2D) shape:[30, 1, 1, 60], type:FLOAT32 RO 7200 bytes, buffer: 110, data:[0.449749, 0.183205, -0.323894, 0.0894036, 0.0372021, ...]\n",
      "  T#110(model/CONV_0/Conv2D) shape:[30, 4, 8, 1], type:FLOAT32 RO 3840 bytes, buffer: 111, data:[-0.114492, -0.237609, -0.215151, -0.182603, -0.0288566, ...]\n",
      "  T#111(model/ADVANCED_SPEC1/stft/rfft) shape:[], type:INT32 RO 4 bytes, buffer: 112, data:[-2]\n",
      "  T#112(model/ADVANCED_SPEC1/stft/rfft1) shape:[2], type:INT32 RO 8 bytes, buffer: 113, data:[1, 512]\n",
      "  T#113(model/ADVANCED_SPEC1/stft/hann_window/sub_2) shape:[512], type:FLOAT32 RO 2048 bytes, buffer: 114, data:[0, 3.76403e-05, 0.000150591, 0.000338793, 0.000602275, ...]\n",
      "  T#114(model/ADVANCED_SPEC1/stft/frame/floordiv_2) shape:[], type:INT32 RO 4 bytes, buffer: 115, data:[35]\n",
      "  T#115(model/ADVANCED_SPEC1/stft/frame/Reshape_3) shape:[1, 64], type:INT32 RO 256 bytes, buffer: 116, data:[0, 1, 2, 3, 4, ...]\n",
      "  T#116(model/ADVANCED_SPEC1/stft/frame/packed) shape:[3], type:INT32 RO 12 bytes, buffer: 117, data:[1, 1, 0]\n",
      "  T#117(model/ADVANCED_SPEC1/stft/frame/strided_slice) shape:[], type:INT32 RO 4 bytes, buffer: 118, data:[1]\n",
      "  T#118(model/ADVANCED_SPEC1/stft/frame/ones_like) shape:[2], type:INT32 RO 8 bytes, buffer: 119, data:[1, 1]\n",
      "  T#119(model/ADVANCED_SPEC1/ExpandDims/dim) shape:[], type:INT32 RO 4 bytes, buffer: 120, data:[-1]\n",
      "  T#120(model/ADVANCED_SPEC1/stft/frame/Maximum/x) shape:[], type:INT32 RO 4 bytes, buffer: 121, data:[0]\n",
      "  T#121(model/ADVANCED_SPEC1/stft/frame/Reshape/shape_1) shape:[0], type:INT32\n",
      "  T#122(model/ADVANCED_SPEC1/stft/frame/concat_1/values_1/1) shape:[], type:INT32 RO 4 bytes, buffer: 123, data:[8]\n",
      "  T#123(model/ADVANCED_SPEC1/stft/frame/strided_slice/stack_1) shape:[1], type:INT32 RO 4 bytes, buffer: 124, data:[0]\n",
      "  T#124(model/ADVANCED_SPEC1/stft/frame/strided_slice/stack_2) shape:[1], type:INT32 RO 4 bytes, buffer: 125, data:[1]\n",
      "  T#125(model/ADVANCED_SPEC1/stft/frame/zeros_like) shape:[2], type:INT32 RO 8 bytes, buffer: 126, data:[0, 0]\n",
      "  T#126(model/ADVANCED_SPEC1/stft/frame_length) shape:[], type:INT32 RO 4 bytes, buffer: 127, data:[512]\n",
      "  T#127(model/ADVANCED_SPEC1/stft/frame_step) shape:[], type:INT32 RO 4 bytes, buffer: 128, data:[280]\n",
      "  T#128(model/ADVANCED_SPEC1/strided_slice/stack) shape:[3], type:INT32 RO 12 bytes, buffer: 129, data:[0, 0, 0]\n",
      "  T#129(model/ADVANCED_SPEC1/strided_slice/stack_1) shape:[3], type:INT32 RO 12 bytes, buffer: 130, data:[0, 0, 128]\n",
      "  T#130(model/ADVANCED_SPEC1/strided_slice/stack_2) shape:[3], type:INT32 RO 12 bytes, buffer: 131, data:[1, 1, 1]\n",
      "  T#131(model/ADVANCED_SPEC1/transpose/perm) shape:[3], type:INT32 RO 12 bytes, buffer: 132, data:[0, 2, 1]\n",
      "  T#132(model/BLOCK_3-1_SE_AVG_POOL_1/Mean/reduction_indices) shape:[2], type:INT32 RO 8 bytes, buffer: 133, data:[1, 2]\n",
      "  T#133(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 134, data:[640]\n",
      "  T#134(model/BLOCK_4-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 135, data:[1120]\n",
      "  T#135(model/CLASS_DENSE_1/BiasAdd/ReadVariableOp/resource) shape:[2434], type:FLOAT32 RO 9736 bytes, buffer: 136, data:[-0.107069, -0.122795, -0.202518, -0.147702, -0.191683, ...]\n",
      "  T#136(model/GLOBAL_LME_POOL/ReadVariableOp/resource) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 137, data:[1.46607]\n",
      "  T#137(model/ADVANCED_SPEC1/truediv_1) shape:[], type:FLOAT32 RO 4 bytes, buffer: 138, data:[0.262867]\n",
      "  T#138(model/BNORM_POST_NOQUANT/FusedBatchNormV3) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 139, data:[0.374975, 0.296045, 0.377884, 0.231385, 0.356721, ...]\n",
      "  T#139(model/BNORM_POST_NOQUANT/FusedBatchNormV31) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 140, data:[0.346286, 0.419046, 0.374378, 0.392926, 0.321534, ...]\n",
      "  T#140(model/BNORM_SPEC_NOQUANT/FusedBatchNormV3) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 141, data:[-0.118066]\n",
      "  T#141(model/BNORM_SPEC_NOQUANT/FusedBatchNormV31) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 142, data:[1.24676]\n",
      "  T#142(model/CLASS_DENSE_1/MatMul) shape:[2434, 420], type:FLOAT32 RO 4089120 bytes, buffer: 143, data:[-0.226968, 0.00635715, -0.0237034, -0.110834, -0.217502, ...]\n",
      "  T#143(model/ADVANCED_SPEC1/Min) shape_signature:[-1, 1], type:FLOAT32\n",
      "  T#144(model/ADVANCED_SPEC1/Sub) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#145(model/ADVANCED_SPEC1/Max) shape_signature:[-1, 1], type:FLOAT32\n",
      "  T#146(model/ADVANCED_SPEC1/truediv) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#147(model/ADVANCED_SPEC1/stft/frame/Shape) shape:[2], type:INT32\n",
      "  T#148(model/ADVANCED_SPEC1/stft/frame/split) shape:[1], type:INT32\n",
      "  T#149(model/ADVANCED_SPEC1/stft/frame/split1) shape:[1], type:INT32\n",
      "  T#150(model/ADVANCED_SPEC1/stft/frame/split2) shape:[0], type:INT32\n",
      "  T#151(model/ADVANCED_SPEC1/stft/frame/Reshape) shape:[], type:INT32\n",
      "  T#152(model/ADVANCED_SPEC1/stft/frame/floordiv_3) shape:[], type:INT32\n",
      "  T#153(model/ADVANCED_SPEC1/stft/frame/concat_1/values_1) shape:[2], type:INT32\n",
      "  T#154(model/ADVANCED_SPEC1/stft/frame/mul) shape:[], type:INT32\n",
      "  T#155(model/ADVANCED_SPEC1/stft/frame/concat/values_1) shape:[1], type:INT32\n",
      "  T#156(model/ADVANCED_SPEC1/stft/frame/concat) shape:[2], type:INT32\n",
      "  T#157(model/ADVANCED_SPEC1/stft/frame/concat_1) shape:[3], type:INT32\n",
      "  T#158(model/ADVANCED_SPEC1/stft/frame/StridedSlice) shape_signature:[-1, -1], type:FLOAT32\n",
      "  T#159(model/ADVANCED_SPEC1/stft/frame/Reshape_1) shape_signature:[-1, -1, 8], type:FLOAT32\n",
      "  T#160(model/ADVANCED_SPEC1/stft/frame/sub_2) shape:[], type:INT32\n",
      "  T#161(model/ADVANCED_SPEC1/stft/frame/floordiv) shape:[], type:INT32\n",
      "  T#162(model/ADVANCED_SPEC1/stft/frame/add) shape:[], type:INT32\n",
      "  T#163(model/ADVANCED_SPEC1/stft/frame/Maximum) shape:[], type:INT32\n",
      "  T#164(model/ADVANCED_SPEC1/stft/frame/Reshape_2/shape) shape:[2], type:INT32\n",
      "  T#165(model/ADVANCED_SPEC1/stft/frame/concat_2/values_1) shape:[2], type:INT32\n",
      "  T#166(model/ADVANCED_SPEC1/stft/frame/concat_2) shape:[3], type:INT32\n",
      "  T#167(model/ADVANCED_SPEC1/stft/frame/range_1) shape_signature:[-1], type:INT32\n",
      "  T#168(model/ADVANCED_SPEC1/stft/frame/mul_1) shape_signature:[-1], type:INT32\n",
      "  T#169(model/ADVANCED_SPEC1/stft/frame/Reshape_2) shape_signature:[-1, 1], type:INT32\n",
      "  T#170(model/ADVANCED_SPEC1/stft/frame/add_1) shape_signature:[-1, 64], type:INT32\n",
      "  T#171(model/ADVANCED_SPEC1/stft/frame/GatherV2;model/ADVANCED_SPEC1/stft/frame/strided_slice) shape_signature:[-1, -1, 64, 8], type:FLOAT32\n",
      "  T#172(model/ADVANCED_SPEC1/stft/frame/Reshape_4) shape_signature:[-1, -1, 512], type:FLOAT32\n",
      "  T#173(model/ADVANCED_SPEC1/stft/mul) shape_signature:[-1, -1, 512], type:FLOAT32\n",
      "  T#174(model/ADVANCED_SPEC1/stft/rfft2) shape_signature:[-1, -1, 1, 512], type:FLOAT32\n",
      "  T#175(model/ADVANCED_SPEC1/stft/rfft3) shape_signature:[-1, -1, 1, 257], type:COMPLEX64\n",
      "  T#176(model/ADVANCED_SPEC1/stft/rfft4) shape_signature:[-1, -1, 257], type:COMPLEX64\n",
      "  T#177(model/ADVANCED_SPEC1/Cast) shape_signature:[-1, -1, 257], type:FLOAT32\n",
      "  T#178(model/ADVANCED_SPEC1/strided_slice) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#179(model/ADVANCED_SPEC1/Pow;model/ADVANCED_SPEC1/Pow/y) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#180(model/ADVANCED_SPEC1/Pow_1) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#181(model/ADVANCED_SPEC1/transpose) shape_signature:[-1, 128, -1], type:FLOAT32\n",
      "  T#182(model/ADVANCED_SPEC1/ExpandDims) shape_signature:[-1, 128, -1, 1], type:FLOAT32\n",
      "  T#183(model/BNORM_SPEC_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 128, -1, 1], type:FLOAT32\n",
      "  T#184(model/BNORM_SPEC_NOQUANT/FusedBatchNormV33) shape_signature:[-1, 128, -1, 1], type:FLOAT32\n",
      "  T#185(model/ACT_0/Relu;model/BNORM_0/FusedBatchNormV3;model/CONV_0/Conv2D) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#186(model/pool_0_AVG/AvgPool) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#187(model/pool_0_MAX/MaxPool) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#188(model/pool_0_CONCAT/concat) shape_signature:[-1, 64, -1, 60], type:FLOAT32\n",
      "  T#189(model/pool_0_CONV/BiasAdd;model/CONV_0/Conv2D;model/pool_0_CONV/Conv2D;model/pool_0_CONV/BiasAdd/ReadVariableOp/resource1) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#190(model/BLOCK_1-1_BN_1/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#191(model/BLOCK_1-1_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#192(model/BLOCK_1-1_ACT_1/mul) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#193(model/BLOCK_1-1_BN_3/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-1_CONV_3/Conv2D1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#194(model/BLOCK_1-2_BN_1/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-2_CONV_1/Conv2D1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#195(model/BLOCK_1-2_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#196(model/BLOCK_1-2_ACT_1/mul) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#197(model/BLOCK_1-2_BN_3/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-2_CONV_3/Conv2D1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#198(model/BLOCK_1-2_ADD/add) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#199(model/BLOCK_1-3_BN_1/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-3_CONV_1/Conv2D1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#200(model/BLOCK_1-3_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#201(model/BLOCK_1-3_ACT_1/mul) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#202(model/BLOCK_1-3_BN_3/FusedBatchNormV3;model/BLOCK_1-1_CONV_1/Conv2D;model/BLOCK_1-3_CONV_3/Conv2D1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#203(model/BLOCK_1-3_ADD/add) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#204(model/BLOCK_2-1_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#205(model/BLOCK_2-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#206(model/BLOCK_2-1_ACT_1/mul) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#207(model/BLOCK_2-1_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D1) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#208(model/BLOCK_2-2_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D;model/BLOCK_2-2_CONV_1/Conv2D1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#209(model/BLOCK_2-2_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#210(model/BLOCK_2-2_ACT_1/mul) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#211(model/BLOCK_2-2_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D;model/BLOCK_2-2_CONV_3/Conv2D1) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#212(model/BLOCK_2-2_ADD/add) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#213(model/BLOCK_2-3_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D;model/BLOCK_2-3_CONV_1/Conv2D1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#214(model/BLOCK_2-3_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#215(model/BLOCK_2-3_ACT_1/mul) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#216(model/BLOCK_2-3_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D;model/BLOCK_2-3_CONV_3/Conv2D1) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#217(model/BLOCK_2-3_ADD/add) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#218(model/BLOCK_2-4_BN_1/FusedBatchNormV3;model/BLOCK_2-1_CONV_1/Conv2D;model/BLOCK_2-4_CONV_1/Conv2D1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#219(model/BLOCK_2-4_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#220(model/BLOCK_2-4_ACT_1/mul) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#221(model/BLOCK_2-4_BN_3/FusedBatchNormV3;model/BLOCK_2-1_CONV_3/Conv2D;model/BLOCK_2-4_CONV_3/Conv2D1) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#222(model/BLOCK_2-4_ADD/add) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#223(model/BLOCK_3-1_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D1) shape_signature:[-1, 16, -1, 640], type:FLOAT32\n",
      "  T#224(model/BLOCK_3-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 640], type:FLOAT32\n",
      "  T#225(model/BLOCK_3-1_ACT_1/mul) shape_signature:[-1, 16, -1, 640], type:FLOAT32\n",
      "  T#226(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-1_CONV_2/depthwise1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#227(model/BLOCK_3-1_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#228(model/BLOCK_3-1_ACT_2/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#229(model/BLOCK_3-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#230(model/BLOCK_3-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#231(model/BLOCK_3-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#232(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#233(model/BLOCK_3-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#234(model/BLOCK_3-1_SE_CONV_1/Conv2D2) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#235(model/BLOCK_3-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#236(model/BLOCK_3-1_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#237(model/BLOCK_3-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#238(model/BLOCK_3-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#239(model/BLOCK_3-1_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#240(model/BLOCK_3-1_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D1) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#241(model/BLOCK_3-2_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-2_CONV_1/Conv2D1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#242(model/BLOCK_3-2_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#243(model/BLOCK_3-2_ACT_1/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#244(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-2_CONV_2/depthwise1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#245(model/BLOCK_3-2_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#246(model/BLOCK_3-2_ACT_2/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#247(model/BLOCK_3-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#248(model/BLOCK_3-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#249(model/BLOCK_3-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#250(model/BLOCK_3-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#251(model/BLOCK_3-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#252(model/BLOCK_3-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#253(model/BLOCK_3-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#254(model/BLOCK_3-2_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#255(model/BLOCK_3-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#256(model/BLOCK_3-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#257(model/BLOCK_3-2_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#258(model/BLOCK_3-2_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-2_CONV_3/Conv2D1) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#259(model/BLOCK_3-2_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#260(model/BLOCK_3-3_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-3_CONV_1/Conv2D1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#261(model/BLOCK_3-3_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#262(model/BLOCK_3-3_ACT_1/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#263(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-3_CONV_2/depthwise1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#264(model/BLOCK_3-3_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#265(model/BLOCK_3-3_ACT_2/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#266(model/BLOCK_3-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#267(model/BLOCK_3-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#268(model/BLOCK_3-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#269(model/BLOCK_3-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#270(model/BLOCK_3-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#271(model/BLOCK_3-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#272(model/BLOCK_3-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#273(model/BLOCK_3-3_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#274(model/BLOCK_3-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#275(model/BLOCK_3-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#276(model/BLOCK_3-3_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#277(model/BLOCK_3-3_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-3_CONV_3/Conv2D1) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#278(model/BLOCK_3-3_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#279(model/BLOCK_3-4_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-4_CONV_1/Conv2D1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#280(model/BLOCK_3-4_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#281(model/BLOCK_3-4_ACT_1/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#282(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-4_CONV_2/depthwise1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#283(model/BLOCK_3-4_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#284(model/BLOCK_3-4_ACT_2/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#285(model/BLOCK_3-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#286(model/BLOCK_3-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#287(model/BLOCK_3-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#288(model/BLOCK_3-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#289(model/BLOCK_3-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#290(model/BLOCK_3-4_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#291(model/BLOCK_3-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#292(model/BLOCK_3-4_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#293(model/BLOCK_3-4_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#294(model/BLOCK_3-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#295(model/BLOCK_3-4_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#296(model/BLOCK_3-4_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-4_CONV_3/Conv2D1) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#297(model/BLOCK_3-4_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#298(model/BLOCK_3-5_BN_1/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-5_CONV_1/Conv2D1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#299(model/BLOCK_3-5_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#300(model/BLOCK_3-5_ACT_1/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#301(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_1/Conv2D;model/BLOCK_3-5_CONV_2/depthwise1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#302(model/BLOCK_3-5_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#303(model/BLOCK_3-5_ACT_2/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#304(model/BLOCK_3-5_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#305(model/BLOCK_3-5_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#306(model/BLOCK_3-5_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#307(model/BLOCK_3-5_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#308(model/BLOCK_3-5_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#309(model/BLOCK_3-5_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#310(model/BLOCK_3-5_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#311(model/BLOCK_3-5_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#312(model/BLOCK_3-5_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#313(model/BLOCK_3-5_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#314(model/BLOCK_3-5_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#315(model/BLOCK_3-5_BN_3/FusedBatchNormV3;model/BLOCK_3-1_CONV_3/Conv2D;model/BLOCK_3-5_CONV_3/Conv2D1) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#316(model/BLOCK_3-5_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#317(model/BLOCK_4-1_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D1) shape_signature:[-1, 8, -1, 1120], type:FLOAT32\n",
      "  T#318(model/BLOCK_4-1_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 1120], type:FLOAT32\n",
      "  T#319(model/BLOCK_4-1_ACT_1/mul) shape_signature:[-1, 8, -1, 1120], type:FLOAT32\n",
      "  T#320(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-1_CONV_2/depthwise1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#321(model/BLOCK_4-1_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#322(model/BLOCK_4-1_ACT_2/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#323(model/BLOCK_4-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#324(model/BLOCK_4-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#325(model/BLOCK_4-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#326(model/BLOCK_4-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#327(model/BLOCK_4-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#328(model/BLOCK_4-1_SE_CONV_1/Conv2D2) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#329(model/BLOCK_4-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#330(model/BLOCK_4-1_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#331(model/BLOCK_4-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#332(model/BLOCK_4-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#333(model/BLOCK_4-1_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#334(model/BLOCK_4-1_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D1) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#335(model/BLOCK_4-2_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-2_CONV_1/Conv2D1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#336(model/BLOCK_4-2_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#337(model/BLOCK_4-2_ACT_1/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#338(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-2_CONV_2/depthwise1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#339(model/BLOCK_4-2_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#340(model/BLOCK_4-2_ACT_2/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#341(model/BLOCK_4-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#342(model/BLOCK_4-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#343(model/BLOCK_4-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#344(model/BLOCK_4-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#345(model/BLOCK_4-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#346(model/BLOCK_4-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#347(model/BLOCK_4-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#348(model/BLOCK_4-2_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#349(model/BLOCK_4-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#350(model/BLOCK_4-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#351(model/BLOCK_4-2_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#352(model/BLOCK_4-2_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D;model/BLOCK_4-2_CONV_3/Conv2D1) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#353(model/BLOCK_4-2_ADD/add) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#354(model/BLOCK_4-3_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-3_CONV_1/Conv2D1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#355(model/BLOCK_4-3_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#356(model/BLOCK_4-3_ACT_1/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#357(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-3_CONV_2/depthwise1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#358(model/BLOCK_4-3_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#359(model/BLOCK_4-3_ACT_2/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#360(model/BLOCK_4-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#361(model/BLOCK_4-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#362(model/BLOCK_4-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#363(model/BLOCK_4-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#364(model/BLOCK_4-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#365(model/BLOCK_4-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#366(model/BLOCK_4-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#367(model/BLOCK_4-3_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#368(model/BLOCK_4-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#369(model/BLOCK_4-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#370(model/BLOCK_4-3_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#371(model/BLOCK_4-3_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D;model/BLOCK_4-3_CONV_3/Conv2D1) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#372(model/BLOCK_4-3_ADD/add) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#373(model/BLOCK_4-4_BN_1/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-4_CONV_1/Conv2D1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#374(model/BLOCK_4-4_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#375(model/BLOCK_4-4_ACT_1/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#376(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_1/Conv2D;model/BLOCK_4-4_CONV_2/depthwise1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#377(model/BLOCK_4-4_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#378(model/BLOCK_4-4_ACT_2/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#379(model/BLOCK_4-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#380(model/BLOCK_4-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#381(model/BLOCK_4-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#382(model/BLOCK_4-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#383(model/BLOCK_4-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#384(model/BLOCK_4-4_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#385(model/BLOCK_4-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#386(model/BLOCK_4-4_SE_CONV_1/mul) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#387(model/BLOCK_4-4_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#388(model/BLOCK_4-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#389(model/BLOCK_4-4_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#390(model/BLOCK_4-4_BN_3/FusedBatchNormV3;model/BLOCK_4-1_CONV_3/Conv2D;model/BLOCK_4-4_CONV_3/Conv2D1) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#391(model/BLOCK_4-4_ADD/add) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#392(model/BNORM_POST_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#393(model/ACT_POST/Relu;model/BNORM_POST_NOQUANT/FusedBatchNormV3) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#394(model/POST_ACT_1/Relu;model/POST_BN_1/FusedBatchNormV3;model/POST_CONV_1/Conv2D) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#395(model/GLOBAL_LME_POOL/Max) shape_signature:[-1, 1, 1, 420], type:FLOAT32\n",
      "  T#396(model/GLOBAL_LME_POOL/Max_1) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#397(model/GLOBAL_LME_POOL/sub) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#398(model/GLOBAL_LME_POOL/mul) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#399(model/GLOBAL_LME_POOL/Exp) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#400(model/GLOBAL_LME_POOL/Mean) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#401(model/GLOBAL_LME_POOL/Log) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#402(model/GLOBAL_LME_POOL/truediv) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#403(model/GLOBAL_LME_POOL/add) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#404(Identity) shape_signature:[-1, 2434], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:   30254244 bytes\n",
      "    Non-data buffer size:      63032 bytes (00.21 %)\n",
      "  Total data buffer size:   30191212 bytes (99.79 %)\n",
      "    (Zero value buffers):       7508 bytes (00.02 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_original_V_2_1 = \"/home/jovyan/models/origin/BirdNET-Analyzer/checkpoints/V2.1/BirdNET_GLOBAL_2K_V2.1_Model_FP32.tflite\"\n",
    "tf.lite.experimental.Analyzer.analyze(model_path=path_to_original_V_2_1,\n",
    "                                      model_content=None,\n",
    "                                      gpu_compatibility=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4af2f5a-a81a-4dfb-afc2-a87e7f6c2e1d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== /home/jovyan/20230717_test_layer_remove.tflite ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the REDUCE_MIN op takes\n",
      "tensor #0 and tensor #116 as input and produces tensor #142 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#402]\n",
      "  Op#0 REDUCE_MIN(T#0, T#116[1]) -> [T#142]\n",
      "  Op#1 SUB(T#0, T#142) -> [T#143]\n",
      "  Op#2 REDUCE_MAX(T#143, T#116[1]) -> [T#144]\n",
      "  Op#3 DIV(T#143, T#144) -> [T#145]\n",
      "  Op#4 SHAPE(T#145) -> [T#146]\n",
      "  Op#5 SPLIT_V(T#146, T#124[1, 1, 0], T#136[0]) -> [T#147, T#148, T#149]\n",
      "  Op#6 RESHAPE(T#148, T#135[]) -> [T#150]\n",
      "  Op#7 FLOOR_DIV(T#150, T#134[8]) -> [T#151]\n",
      "  Op#8 PACK(T#151, T#134[8]) -> [T#152]\n",
      "  Op#9 MUL(T#151, T#134[8]) -> [T#153]\n",
      "  Op#10 RESHAPE(T#153, T#119[1]) -> [T#154]\n",
      "  Op#11 CONCATENATION(T#147, T#154) -> [T#155]\n",
      "  Op#12 CONCATENATION(T#147, T#152) -> [T#156]\n",
      "  Op#13 STRIDED_SLICE(T#145, T#133[0, 0], T#155, T#125[1, 1]) -> [T#157]\n",
      "  Op#14 RESHAPE(T#157, T#156) -> [T#158]\n",
      "  Op#15 SUB(T#150, T#132[512]) -> [T#159]\n",
      "  Op#16 FLOOR_DIV(T#159, T#131[280]) -> [T#160]\n",
      "  Op#17 ADD(T#160, T#116[1]) -> [T#161]\n",
      "  Op#18 MAXIMUM(T#161, T#136[0]) -> [T#162]\n",
      "  Op#19 PACK(T#162, T#116[1]) -> [T#163]\n",
      "  Op#20 PACK(T#162, T#132[512]) -> [T#164]\n",
      "  Op#21 CONCATENATION(T#147, T#164) -> [T#165]\n",
      "  Op#22 RANGE(T#136[0], T#162, T#116[1]) -> [T#166]\n",
      "  Op#23 MUL(T#166, T#126[35]) -> [T#167]\n",
      "  Op#24 RESHAPE(T#167, T#163) -> [T#168]\n",
      "  Op#25 ADD(T#168, T#123[0, 1, 2, 3, 4, ...]) -> [T#169]\n",
      "  Op#26 GATHER(T#158, T#169) -> [T#170]\n",
      "  Op#27 RESHAPE(T#170, T#165) -> [T#171]\n",
      "  Op#28 MUL(T#171, T#122) -> [T#172]\n",
      "  Op#29 EXPAND_DIMS(T#172, T#56[-2]) -> [T#173]\n",
      "  Op#30 RFFT2D(T#173, T#57[1, 512]) -> [T#174]\n",
      "  Op#31 SQUEEZE(T#174) -> [T#175]\n",
      "  Op#32 CAST(T#175) -> [T#176]\n",
      "  Op#33 STRIDED_SLICE(T#176, T#130[0, 0, 0], T#129[0, 0, 128], T#128[1, 1, 1]) -> [T#177]\n",
      "  Op#34 MUL(T#177, T#177) -> [T#178]\n",
      "  Op#35 POW(T#178, T#121) -> [T#179]\n",
      "  Op#36 TRANSPOSE(T#179, T#127[0, 2, 1]) -> [T#180]\n",
      "  Op#37 EXPAND_DIMS(T#180, T#137[-1]) -> [T#181]\n",
      "  Op#38 MUL(T#181, T#138) -> [T#182]\n",
      "  Op#39 ADD(T#182, T#139) -> [T#183]\n",
      "  Op#40 CONV_2D(T#183, T#58, T#1) -> [T#184]\n",
      "  Op#41 AVERAGE_POOL_2D(T#184) -> [T#185]\n",
      "  Op#42 MAX_POOL_2D(T#184) -> [T#186]\n",
      "  Op#43 CONCATENATION(T#186, T#185) -> [T#187]\n",
      "  Op#44 CONV_2D(T#187, T#59, T#12) -> [T#188]\n",
      "  Op#45 CONV_2D(T#188, T#60, T#13) -> [T#189]\n",
      "  Op#46 LOGISTIC(T#189) -> [T#190]\n",
      "  Op#47 MUL(T#189, T#190) -> [T#191]\n",
      "  Op#48 CONV_2D(T#191, T#61, T#14) -> [T#192]\n",
      "  Op#49 CONV_2D(T#192, T#62, T#15) -> [T#193]\n",
      "  Op#50 LOGISTIC(T#193) -> [T#194]\n",
      "  Op#51 MUL(T#193, T#194) -> [T#195]\n",
      "  Op#52 CONV_2D(T#195, T#63, T#16) -> [T#196]\n",
      "  Op#53 ADD(T#196, T#192) -> [T#197]\n",
      "  Op#54 CONV_2D(T#197, T#64, T#17) -> [T#198]\n",
      "  Op#55 LOGISTIC(T#198) -> [T#199]\n",
      "  Op#56 MUL(T#198, T#199) -> [T#200]\n",
      "  Op#57 CONV_2D(T#200, T#65, T#18) -> [T#201]\n",
      "  Op#58 ADD(T#201, T#197) -> [T#202]\n",
      "  Op#59 CONV_2D(T#202, T#66, T#19) -> [T#203]\n",
      "  Op#60 LOGISTIC(T#203) -> [T#204]\n",
      "  Op#61 MUL(T#203, T#204) -> [T#205]\n",
      "  Op#62 CONV_2D(T#205, T#67, T#20) -> [T#206]\n",
      "  Op#63 CONV_2D(T#206, T#68, T#21) -> [T#207]\n",
      "  Op#64 LOGISTIC(T#207) -> [T#208]\n",
      "  Op#65 MUL(T#207, T#208) -> [T#209]\n",
      "  Op#66 CONV_2D(T#209, T#69, T#22) -> [T#210]\n",
      "  Op#67 ADD(T#210, T#206) -> [T#211]\n",
      "  Op#68 CONV_2D(T#211, T#70, T#23) -> [T#212]\n",
      "  Op#69 LOGISTIC(T#212) -> [T#213]\n",
      "  Op#70 MUL(T#212, T#213) -> [T#214]\n",
      "  Op#71 CONV_2D(T#214, T#71, T#24) -> [T#215]\n",
      "  Op#72 ADD(T#215, T#211) -> [T#216]\n",
      "  Op#73 CONV_2D(T#216, T#72, T#25) -> [T#217]\n",
      "  Op#74 LOGISTIC(T#217) -> [T#218]\n",
      "  Op#75 MUL(T#217, T#218) -> [T#219]\n",
      "  Op#76 CONV_2D(T#219, T#73, T#26) -> [T#220]\n",
      "  Op#77 ADD(T#220, T#216) -> [T#221]\n",
      "  Op#78 CONV_2D(T#221, T#74, T#27) -> [T#222]\n",
      "  Op#79 LOGISTIC(T#222) -> [T#223]\n",
      "  Op#80 MUL(T#222, T#223) -> [T#224]\n",
      "  Op#81 DEPTHWISE_CONV_2D(T#224, T#28, T#2) -> [T#225]\n",
      "  Op#82 LOGISTIC(T#225) -> [T#226]\n",
      "  Op#83 MUL(T#225, T#226) -> [T#227]\n",
      "  Op#84 MEAN(T#227, T#115[1, 2]) -> [T#228]\n",
      "  Op#85 SHAPE(T#228) -> [T#229]\n",
      "  Op#86 STRIDED_SLICE(T#229, T#118[0], T#119[1], T#119[1]) -> [T#230]\n",
      "  Op#87 PACK(T#230, T#116[1], T#116[1], T#117[640]) -> [T#231]\n",
      "  Op#88 RESHAPE(T#228, T#231) -> [T#232]\n",
      "  Op#89 CONV_2D(T#232, T#76, T#75) -> [T#233]\n",
      "  Op#90 LOGISTIC(T#233) -> [T#234]\n",
      "  Op#91 MUL(T#233, T#234) -> [T#235]\n",
      "  Op#92 CONV_2D(T#235, T#77, T#29) -> [T#236]\n",
      "  Op#93 LOGISTIC(T#236) -> [T#237]\n",
      "  Op#94 MUL(T#227, T#237) -> [T#238]\n",
      "  Op#95 CONV_2D(T#238, T#78, T#30) -> [T#239]\n",
      "  Op#96 CONV_2D(T#239, T#79, T#31) -> [T#240]\n",
      "  Op#97 LOGISTIC(T#240) -> [T#241]\n",
      "  Op#98 MUL(T#240, T#241) -> [T#242]\n",
      "  Op#99 DEPTHWISE_CONV_2D(T#242, T#32, T#3) -> [T#243]\n",
      "  Op#100 LOGISTIC(T#243) -> [T#244]\n",
      "  Op#101 MUL(T#243, T#244) -> [T#245]\n",
      "  Op#102 MEAN(T#245, T#115[1, 2]) -> [T#246]\n",
      "  Op#103 SHAPE(T#246) -> [T#247]\n",
      "  Op#104 STRIDED_SLICE(T#247, T#118[0], T#119[1], T#119[1]) -> [T#248]\n",
      "  Op#105 PACK(T#248, T#116[1], T#116[1], T#117[640]) -> [T#249]\n",
      "  Op#106 RESHAPE(T#246, T#249) -> [T#250]\n",
      "  Op#107 CONV_2D(T#250, T#80, T#75) -> [T#251]\n",
      "  Op#108 LOGISTIC(T#251) -> [T#252]\n",
      "  Op#109 MUL(T#251, T#252) -> [T#253]\n",
      "  Op#110 CONV_2D(T#253, T#81, T#29) -> [T#254]\n",
      "  Op#111 LOGISTIC(T#254) -> [T#255]\n",
      "  Op#112 MUL(T#245, T#255) -> [T#256]\n",
      "  Op#113 CONV_2D(T#256, T#82, T#33) -> [T#257]\n",
      "  Op#114 ADD(T#257, T#239) -> [T#258]\n",
      "  Op#115 CONV_2D(T#258, T#83, T#34) -> [T#259]\n",
      "  Op#116 LOGISTIC(T#259) -> [T#260]\n",
      "  Op#117 MUL(T#259, T#260) -> [T#261]\n",
      "  Op#118 DEPTHWISE_CONV_2D(T#261, T#35, T#4) -> [T#262]\n",
      "  Op#119 LOGISTIC(T#262) -> [T#263]\n",
      "  Op#120 MUL(T#262, T#263) -> [T#264]\n",
      "  Op#121 MEAN(T#264, T#115[1, 2]) -> [T#265]\n",
      "  Op#122 SHAPE(T#265) -> [T#266]\n",
      "  Op#123 STRIDED_SLICE(T#266, T#118[0], T#119[1], T#119[1]) -> [T#267]\n",
      "  Op#124 PACK(T#267, T#116[1], T#116[1], T#117[640]) -> [T#268]\n",
      "  Op#125 RESHAPE(T#265, T#268) -> [T#269]\n",
      "  Op#126 CONV_2D(T#269, T#84, T#75) -> [T#270]\n",
      "  Op#127 LOGISTIC(T#270) -> [T#271]\n",
      "  Op#128 MUL(T#270, T#271) -> [T#272]\n",
      "  Op#129 CONV_2D(T#272, T#85, T#29) -> [T#273]\n",
      "  Op#130 LOGISTIC(T#273) -> [T#274]\n",
      "  Op#131 MUL(T#264, T#274) -> [T#275]\n",
      "  Op#132 CONV_2D(T#275, T#86, T#36) -> [T#276]\n",
      "  Op#133 ADD(T#276, T#258) -> [T#277]\n",
      "  Op#134 CONV_2D(T#277, T#87, T#37) -> [T#278]\n",
      "  Op#135 LOGISTIC(T#278) -> [T#279]\n",
      "  Op#136 MUL(T#278, T#279) -> [T#280]\n",
      "  Op#137 DEPTHWISE_CONV_2D(T#280, T#38, T#5) -> [T#281]\n",
      "  Op#138 LOGISTIC(T#281) -> [T#282]\n",
      "  Op#139 MUL(T#281, T#282) -> [T#283]\n",
      "  Op#140 MEAN(T#283, T#115[1, 2]) -> [T#284]\n",
      "  Op#141 SHAPE(T#284) -> [T#285]\n",
      "  Op#142 STRIDED_SLICE(T#285, T#118[0], T#119[1], T#119[1]) -> [T#286]\n",
      "  Op#143 PACK(T#286, T#116[1], T#116[1], T#117[640]) -> [T#287]\n",
      "  Op#144 RESHAPE(T#284, T#287) -> [T#288]\n",
      "  Op#145 CONV_2D(T#288, T#88, T#75) -> [T#289]\n",
      "  Op#146 LOGISTIC(T#289) -> [T#290]\n",
      "  Op#147 MUL(T#289, T#290) -> [T#291]\n",
      "  Op#148 CONV_2D(T#291, T#89, T#29) -> [T#292]\n",
      "  Op#149 LOGISTIC(T#292) -> [T#293]\n",
      "  Op#150 MUL(T#283, T#293) -> [T#294]\n",
      "  Op#151 CONV_2D(T#294, T#90, T#39) -> [T#295]\n",
      "  Op#152 ADD(T#295, T#277) -> [T#296]\n",
      "  Op#153 CONV_2D(T#296, T#91, T#40) -> [T#297]\n",
      "  Op#154 LOGISTIC(T#297) -> [T#298]\n",
      "  Op#155 MUL(T#297, T#298) -> [T#299]\n",
      "  Op#156 DEPTHWISE_CONV_2D(T#299, T#41, T#6) -> [T#300]\n",
      "  Op#157 LOGISTIC(T#300) -> [T#301]\n",
      "  Op#158 MUL(T#300, T#301) -> [T#302]\n",
      "  Op#159 MEAN(T#302, T#115[1, 2]) -> [T#303]\n",
      "  Op#160 SHAPE(T#303) -> [T#304]\n",
      "  Op#161 STRIDED_SLICE(T#304, T#118[0], T#119[1], T#119[1]) -> [T#305]\n",
      "  Op#162 PACK(T#305, T#116[1], T#116[1], T#117[640]) -> [T#306]\n",
      "  Op#163 RESHAPE(T#303, T#306) -> [T#307]\n",
      "  Op#164 CONV_2D(T#307, T#92, T#75) -> [T#308]\n",
      "  Op#165 LOGISTIC(T#308) -> [T#309]\n",
      "  Op#166 MUL(T#308, T#309) -> [T#310]\n",
      "  Op#167 CONV_2D(T#310, T#93, T#29) -> [T#311]\n",
      "  Op#168 LOGISTIC(T#311) -> [T#312]\n",
      "  Op#169 MUL(T#302, T#312) -> [T#313]\n",
      "  Op#170 CONV_2D(T#313, T#94, T#42) -> [T#314]\n",
      "  Op#171 ADD(T#314, T#296) -> [T#315]\n",
      "  Op#172 CONV_2D(T#315, T#95, T#43) -> [T#316]\n",
      "  Op#173 LOGISTIC(T#316) -> [T#317]\n",
      "  Op#174 MUL(T#316, T#317) -> [T#318]\n",
      "  Op#175 DEPTHWISE_CONV_2D(T#318, T#44, T#7) -> [T#319]\n",
      "  Op#176 LOGISTIC(T#319) -> [T#320]\n",
      "  Op#177 MUL(T#319, T#320) -> [T#321]\n",
      "  Op#178 MEAN(T#321, T#115[1, 2]) -> [T#322]\n",
      "  Op#179 SHAPE(T#322) -> [T#323]\n",
      "  Op#180 STRIDED_SLICE(T#323, T#118[0], T#119[1], T#119[1]) -> [T#324]\n",
      "  Op#181 PACK(T#324, T#116[1], T#116[1], T#120[1120]) -> [T#325]\n",
      "  Op#182 RESHAPE(T#322, T#325) -> [T#326]\n",
      "  Op#183 CONV_2D(T#326, T#97, T#96) -> [T#327]\n",
      "  Op#184 LOGISTIC(T#327) -> [T#328]\n",
      "  Op#185 MUL(T#327, T#328) -> [T#329]\n",
      "  Op#186 CONV_2D(T#329, T#98, T#45) -> [T#330]\n",
      "  Op#187 LOGISTIC(T#330) -> [T#331]\n",
      "  Op#188 MUL(T#321, T#331) -> [T#332]\n",
      "  Op#189 CONV_2D(T#332, T#99, T#46) -> [T#333]\n",
      "  Op#190 CONV_2D(T#333, T#100, T#47) -> [T#334]\n",
      "  Op#191 LOGISTIC(T#334) -> [T#335]\n",
      "  Op#192 MUL(T#334, T#335) -> [T#336]\n",
      "  Op#193 DEPTHWISE_CONV_2D(T#336, T#48, T#8) -> [T#337]\n",
      "  Op#194 LOGISTIC(T#337) -> [T#338]\n",
      "  Op#195 MUL(T#337, T#338) -> [T#339]\n",
      "  Op#196 MEAN(T#339, T#115[1, 2]) -> [T#340]\n",
      "  Op#197 SHAPE(T#340) -> [T#341]\n",
      "  Op#198 STRIDED_SLICE(T#341, T#118[0], T#119[1], T#119[1]) -> [T#342]\n",
      "  Op#199 PACK(T#342, T#116[1], T#116[1], T#120[1120]) -> [T#343]\n",
      "  Op#200 RESHAPE(T#340, T#343) -> [T#344]\n",
      "  Op#201 CONV_2D(T#344, T#101, T#96) -> [T#345]\n",
      "  Op#202 LOGISTIC(T#345) -> [T#346]\n",
      "  Op#203 MUL(T#345, T#346) -> [T#347]\n",
      "  Op#204 CONV_2D(T#347, T#102, T#45) -> [T#348]\n",
      "  Op#205 LOGISTIC(T#348) -> [T#349]\n",
      "  Op#206 MUL(T#339, T#349) -> [T#350]\n",
      "  Op#207 CONV_2D(T#350, T#103, T#49) -> [T#351]\n",
      "  Op#208 ADD(T#351, T#333) -> [T#352]\n",
      "  Op#209 CONV_2D(T#352, T#104, T#50) -> [T#353]\n",
      "  Op#210 LOGISTIC(T#353) -> [T#354]\n",
      "  Op#211 MUL(T#353, T#354) -> [T#355]\n",
      "  Op#212 DEPTHWISE_CONV_2D(T#355, T#51, T#9) -> [T#356]\n",
      "  Op#213 LOGISTIC(T#356) -> [T#357]\n",
      "  Op#214 MUL(T#356, T#357) -> [T#358]\n",
      "  Op#215 MEAN(T#358, T#115[1, 2]) -> [T#359]\n",
      "  Op#216 SHAPE(T#359) -> [T#360]\n",
      "  Op#217 STRIDED_SLICE(T#360, T#118[0], T#119[1], T#119[1]) -> [T#361]\n",
      "  Op#218 PACK(T#361, T#116[1], T#116[1], T#120[1120]) -> [T#362]\n",
      "  Op#219 RESHAPE(T#359, T#362) -> [T#363]\n",
      "  Op#220 CONV_2D(T#363, T#105, T#96) -> [T#364]\n",
      "  Op#221 LOGISTIC(T#364) -> [T#365]\n",
      "  Op#222 MUL(T#364, T#365) -> [T#366]\n",
      "  Op#223 CONV_2D(T#366, T#106, T#45) -> [T#367]\n",
      "  Op#224 LOGISTIC(T#367) -> [T#368]\n",
      "  Op#225 MUL(T#358, T#368) -> [T#369]\n",
      "  Op#226 CONV_2D(T#369, T#107, T#52) -> [T#370]\n",
      "  Op#227 ADD(T#370, T#352) -> [T#371]\n",
      "  Op#228 CONV_2D(T#371, T#108, T#53) -> [T#372]\n",
      "  Op#229 LOGISTIC(T#372) -> [T#373]\n",
      "  Op#230 MUL(T#372, T#373) -> [T#374]\n",
      "  Op#231 DEPTHWISE_CONV_2D(T#374, T#54, T#10) -> [T#375]\n",
      "  Op#232 LOGISTIC(T#375) -> [T#376]\n",
      "  Op#233 MUL(T#375, T#376) -> [T#377]\n",
      "  Op#234 MEAN(T#377, T#115[1, 2]) -> [T#378]\n",
      "  Op#235 SHAPE(T#378) -> [T#379]\n",
      "  Op#236 STRIDED_SLICE(T#379, T#118[0], T#119[1], T#119[1]) -> [T#380]\n",
      "  Op#237 PACK(T#380, T#116[1], T#116[1], T#120[1120]) -> [T#381]\n",
      "  Op#238 RESHAPE(T#378, T#381) -> [T#382]\n",
      "  Op#239 CONV_2D(T#382, T#109, T#96) -> [T#383]\n",
      "  Op#240 LOGISTIC(T#383) -> [T#384]\n",
      "  Op#241 MUL(T#383, T#384) -> [T#385]\n",
      "  Op#242 CONV_2D(T#385, T#110, T#45) -> [T#386]\n",
      "  Op#243 LOGISTIC(T#386) -> [T#387]\n",
      "  Op#244 MUL(T#377, T#387) -> [T#388]\n",
      "  Op#245 CONV_2D(T#388, T#111, T#55) -> [T#389]\n",
      "  Op#246 ADD(T#389, T#371) -> [T#390]\n",
      "  Op#247 MUL(T#390, T#140) -> [T#391]\n",
      "  Op#248 ADD(T#391, T#141) -> [T#392]\n",
      "  Op#249 CONV_2D(T#392, T#112, T#11) -> [T#393]\n",
      "  Op#250 REDUCE_MAX(T#393, T#115[1, 2]) -> [T#394]\n",
      "  Op#251 REDUCE_MAX(T#393, T#115[1, 2]) -> [T#395]\n",
      "  Op#252 SUB(T#393, T#394) -> [T#396]\n",
      "  Op#253 MUL(T#396, T#113) -> [T#397]\n",
      "  Op#254 EXP(T#397) -> [T#398]\n",
      "  Op#255 MEAN(T#398, T#115[1, 2]) -> [T#399]\n",
      "  Op#256 LOG(T#399) -> [T#400]\n",
      "  Op#257 MUL(T#400, T#114) -> [T#401]\n",
      "  Op#258 ADD(T#401, T#395) -> [T#402]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_INPUT:0) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#1(model/BNORM_0/FusedBatchNormV3) shape:[30], type:FLOAT32 RO 120 bytes, buffer: 2, data:[-0.0201999, 0.021001, -0.00927022, 0.157607, 1.64969, ...]\n",
      "  T#2(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 3, data:[0.507101, 0.170648, 0.0986953, 0.264744, 0.368448, ...]\n",
      "  T#3(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 4, data:[0.156241, 0.10379, -0.12009, 0.251382, -0.321336, ...]\n",
      "  T#4(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 5, data:[-0.052932, -0.15776, -0.162979, -1.74901, -0.0601944, ...]\n",
      "  T#5(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 6, data:[-0.167197, -0.627172, -0.118439, -0.0867302, -0.0966517, ...]\n",
      "  T#6(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 7, data:[0.199295, -0.693983, -0.0609956, -0.305395, -0.0527331, ...]\n",
      "  T#7(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 8, data:[-0.213642, 0.0989731, 0.289327, 0.228966, -0.0641489, ...]\n",
      "  T#8(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 9, data:[0.00732364, -0.15787, -0.631158, -0.106697, 0.0196075, ...]\n",
      "  T#9(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 10, data:[0.0843629, -0.0535078, -0.136284, -0.35959, 0.137284, ...]\n",
      "  T#10(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 11, data:[0.03562, -0.442556, 0.242526, -0.189173, -0.137097, ...]\n",
      "  T#11(model/POST_BN_1/FusedBatchNormV3) shape:[420], type:FLOAT32 RO 1680 bytes, buffer: 12, data:[0.703291, 0.151619, 0.929611, 1.05721, -0.0952325, ...]\n",
      "  T#12(model/pool_0_CONV/BiasAdd/ReadVariableOp) shape:[30], type:FLOAT32 RO 120 bytes, buffer: 13, data:[0.177993, -0.00336044, 1.49043, 0.208713, -0.283743, ...]\n",
      "  T#13(model/BLOCK_1-1_BN_1/FusedBatchNormV3) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 14, data:[0.994801, 1.30954, 1.39498, 2.66734, 0.875943, ...]\n",
      "  T#14(model/BLOCK_1-1_BN_3/FusedBatchNormV3) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 15, data:[-0.572335, -0.296768, -1.17371, -0.676895, 1.66753, ...]\n",
      "  T#15(model/BLOCK_1-2_BN_1/FusedBatchNormV3) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 16, data:[-2.62731, -0.868263, 0.266521, 0.0349529, 0.854639, ...]\n",
      "  T#16(model/BLOCK_1-2_BN_3/FusedBatchNormV3) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 17, data:[-0.463809, 0.940085, -1.53324, 1.37461, 0.36683, ...]\n",
      "  T#17(model/BLOCK_1-3_BN_1/FusedBatchNormV3) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 18, data:[1.23824, 1.12686, 1.3523, -0.914098, 1.96378, ...]\n",
      "  T#18(model/BLOCK_1-3_BN_3/FusedBatchNormV3) shape:[60], type:FLOAT32 RO 240 bytes, buffer: 19, data:[0.224621, -0.89843, -0.404808, 2.08627, 0.154646, ...]\n",
      "  T#19(model/BLOCK_2-1_BN_1/FusedBatchNormV3) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 20, data:[1.08094, 1.82718, 1.35988, 2.0496, 1.56324, ...]\n",
      "  T#20(model/BLOCK_2-1_BN_3/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 21, data:[0.517984, 1.20353, -0.631186, -0.242215, -0.117523, ...]\n",
      "  T#21(model/BLOCK_2-2_BN_1/FusedBatchNormV3) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 22, data:[-0.453432, 0.0377011, 0.029025, -1.10252, 1.40118, ...]\n",
      "  T#22(model/BLOCK_2-2_BN_3/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 23, data:[-0.26637, 0.121703, 0.097885, -0.248943, 0.0860163, ...]\n",
      "  T#23(model/BLOCK_2-3_BN_1/FusedBatchNormV3) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 24, data:[-0.624671, -0.705771, -0.00291157, -0.566265, 0.401846, ...]\n",
      "  T#24(model/BLOCK_2-3_BN_3/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 25, data:[-0.334773, 0.358166, 0.595261, 0.789514, 0.299735, ...]\n",
      "  T#25(model/BLOCK_2-4_BN_1/FusedBatchNormV3) shape:[240], type:FLOAT32 RO 960 bytes, buffer: 26, data:[-0.0566794, -0.325451, -0.0834246, 0.0485905, -0.249119, ...]\n",
      "  T#26(model/BLOCK_2-4_BN_3/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes, buffer: 27, data:[-1.07128, -0.719374, 0.521283, -0.52695, 0.637195, ...]\n",
      "  T#27(model/BLOCK_3-1_BN_1/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 28, data:[0.453774, -0.53238, 0.144864, 0.0808757, -0.600901, ...]\n",
      "  T#28(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 29, data:[-0.251236, 0.372286, -0.59223, -0.1335, 0.312628, ...]\n",
      "  T#29(model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 30, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#30(model/BLOCK_3-1_BN_3/FusedBatchNormV3) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 31, data:[0.028477, -0.247231, -0.271764, -0.436009, -0.0308246, ...]\n",
      "  T#31(model/BLOCK_3-2_BN_1/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 32, data:[-0.530656, 0.133959, 0.382794, -0.28108, -0.106207, ...]\n",
      "  T#32(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-2_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 33, data:[1.23551, -0.0568431, 0.0760742, -0.370292, 0.0261757, ...]\n",
      "  T#33(model/BLOCK_3-2_BN_3/FusedBatchNormV3) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 34, data:[-0.245983, -0.00641132, -0.0371882, 0.126828, -0.0948737, ...]\n",
      "  T#34(model/BLOCK_3-3_BN_1/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 35, data:[1.04701, 0.565516, -0.577064, 0.252158, -0.205602, ...]\n",
      "  T#35(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-3_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 36, data:[0.123467, -0.0474579, 0.25923, -0.762767, -0.0930023, ...]\n",
      "  T#36(model/BLOCK_3-3_BN_3/FusedBatchNormV3) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 37, data:[0.00867989, -0.0112237, -0.166217, 0.266443, -0.436209, ...]\n",
      "  T#37(model/BLOCK_3-4_BN_1/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 38, data:[-0.280375, 0.916876, -0.271838, 0.260631, 0.065035, ...]\n",
      "  T#38(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-4_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 39, data:[-0.10532, -0.530738, 0.000815318, 0.0100449, 0.0389737, ...]\n",
      "  T#39(model/BLOCK_3-4_BN_3/FusedBatchNormV3) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 40, data:[0.0162673, -0.223772, -0.0793594, 0.196439, 0.0911259, ...]\n",
      "  T#40(model/BLOCK_3-5_BN_1/FusedBatchNormV3) shape:[640], type:FLOAT32 RO 2560 bytes, buffer: 41, data:[-1.13443, 0.0416078, -0.161235, -1.03465, -0.414547, ...]\n",
      "  T#41(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:FLOAT32 RO 23040 bytes, buffer: 42, data:[0.358909, -0.200586, 1.62531, 0.189931, 0.597165, ...]\n",
      "  T#42(model/BLOCK_3-5_BN_3/FusedBatchNormV3) shape:[160], type:FLOAT32 RO 640 bytes, buffer: 43, data:[-0.0729527, -0.140453, -0.256495, 0.00789576, -0.0750102, ...]\n",
      "  T#43(model/BLOCK_4-1_BN_1/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 44, data:[-0.501423, -0.781778, -1.06513, -0.807659, -0.451615, ...]\n",
      "  T#44(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 45, data:[-0.313297, -0.692159, 1.42914, -0.135559, -0.402629, ...]\n",
      "  T#45(model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 46, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#46(model/BLOCK_4-1_BN_3/FusedBatchNormV3) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 47, data:[0.00707362, -0.11092, -0.271591, -0.0480711, 0.1141, ...]\n",
      "  T#47(model/BLOCK_4-2_BN_1/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 48, data:[0.214278, 0.192685, 0.0268124, -0.538281, -0.227158, ...]\n",
      "  T#48(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-2_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 49, data:[-0.791778, -0.210047, -0.88355, -0.441906, -0.494887, ...]\n",
      "  T#49(model/BLOCK_4-2_BN_3/FusedBatchNormV3) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 50, data:[-0.0310575, -0.01638, -0.0170814, -0.0743111, -0.0226622, ...]\n",
      "  T#50(model/BLOCK_4-3_BN_1/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 51, data:[-0.212481, -1.1889, -0.0504375, 0.146119, -0.779445, ...]\n",
      "  T#51(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-3_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 52, data:[-0.734297, 0.403795, -5.34587, 0.876589, 0.309243, ...]\n",
      "  T#52(model/BLOCK_4-3_BN_3/FusedBatchNormV3) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 53, data:[0.0840644, -0.110269, -0.105898, -0.161293, -0.123441, ...]\n",
      "  T#53(model/BLOCK_4-4_BN_1/FusedBatchNormV3) shape:[1120], type:FLOAT32 RO 4480 bytes, buffer: 54, data:[-1.24407, -0.0376666, -1.2601, -0.504979, -0.504578, ...]\n",
      "  T#54(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:FLOAT32 RO 40320 bytes, buffer: 55, data:[-0.213518, -0.135148, -0.603809, -0.559516, -0.379189, ...]\n",
      "  T#55(model/BLOCK_4-4_BN_3/FusedBatchNormV3) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 56, data:[-0.303293, -0.566926, -0.164678, -0.409574, -0.311323, ...]\n",
      "  T#56(stft/rfft;stft/rfft) shape:[], type:INT32 RO 4 bytes, buffer: 57, data:[-2]\n",
      "  T#57(stft/rfft;stft/rfft1) shape:[2], type:INT32 RO 8 bytes, buffer: 58, data:[1, 512]\n",
      "  T#58(model/CONV_0/Conv2D) shape:[30, 4, 8, 1], type:FLOAT32 RO 3840 bytes, buffer: 59, data:[-0.114492, -0.237609, -0.215151, -0.182603, -0.0288566, ...]\n",
      "  T#59(model/pool_0_CONV/Conv2D) shape:[30, 1, 1, 60], type:FLOAT32 RO 7200 bytes, buffer: 60, data:[0.449749, 0.183205, -0.323894, 0.0894036, 0.0372021, ...]\n",
      "  T#60(model/BLOCK_1-1_CONV_1/Conv2D) shape:[60, 3, 3, 30], type:FLOAT32 RO 64800 bytes, buffer: 61, data:[-0.024668, 0.0393796, -0.00368801, 0.0139366, 0.0272781, ...]\n",
      "  T#61(model/BLOCK_1-1_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:FLOAT32 RO 14400 bytes, buffer: 62, data:[0.0903042, -0.0224403, 0.279139, 0.140995, -0.201996, ...]\n",
      "  T#62(model/BLOCK_1-2_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:FLOAT32 RO 129600 bytes, buffer: 63, data:[0.00565977, -0.0041388, 0.000459343, -0.0186408, 0.00484244, ...]\n",
      "  T#63(model/BLOCK_1-2_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:FLOAT32 RO 14400 bytes, buffer: 64, data:[-0.0832476, -0.232616, 0.087849, -0.123365, -0.185093, ...]\n",
      "  T#64(model/BLOCK_1-3_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:FLOAT32 RO 129600 bytes, buffer: 65, data:[0.0081317, 0.0289496, -0.000417384, -0.00211003, 0.0340565, ...]\n",
      "  T#65(model/BLOCK_1-3_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:FLOAT32 RO 14400 bytes, buffer: 66, data:[-1.06982, 0.00182795, -0.394202, 0.0216375, -0.540149, ...]\n",
      "  T#66(model/BLOCK_2-1_CONV_1/Conv2D) shape:[240, 3, 3, 60], type:FLOAT32 RO 518400 bytes, buffer: 67, data:[0.00682351, -0.0175564, 0.0204914, 0.0128379, -0.0155376, ...]\n",
      "  T#67(model/BLOCK_2-1_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 68, data:[-0.135052, 0.0525188, 0.0256257, 0.037241, 0.0417646, ...]\n",
      "  T#68(model/BLOCK_2-2_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:FLOAT32 RO 1036800 bytes, buffer: 69, data:[0.00415435, -0.00527662, 0.0250746, 0.00708887, -0.00520974, ...]\n",
      "  T#69(model/BLOCK_2-2_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 70, data:[-0.231138, -0.155019, 0.0335709, -0.048346, -0.0636056, ...]\n",
      "  T#70(model/BLOCK_2-3_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:FLOAT32 RO 1036800 bytes, buffer: 71, data:[-0.00990321, 0.00305605, -0.022679, 0.00943848, 0.0178133, ...]\n",
      "  T#71(model/BLOCK_2-3_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 72, data:[0.151803, -0.211548, 0.656866, 0.313801, 0.534047, ...]\n",
      "  T#72(model/BLOCK_2-4_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:FLOAT32 RO 1036800 bytes, buffer: 73, data:[-0.00882176, -0.00886716, 0.0172686, -0.0173403, -0.0128443, ...]\n",
      "  T#73(model/BLOCK_2-4_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:FLOAT32 RO 115200 bytes, buffer: 74, data:[0.514776, -0.170025, -0.492848, -0.127949, 0.0632972, ...]\n",
      "  T#74(model/BLOCK_3-1_CONV_1/Conv2D) shape:[640, 1, 1, 120], type:FLOAT32 RO 307200 bytes, buffer: 75, data:[0.027395, -0.00337426, 0.0371208, 0.0296344, 0.0550245, ...]\n",
      "  T#75(model/BLOCK_3-5_SE_CONV_1/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes, buffer: 76, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#76(model/BLOCK_3-1_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 77, data:[-0.109894, -0.250427, 0.248698, 0.197855, -0.148598, ...]\n",
      "  T#77(model/BLOCK_3-1_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 78, data:[0.477402, 0.774508, 0.414591, 0.138802, -0.0958745, ...]\n",
      "  T#78(model/BLOCK_3-1_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 79, data:[0.183485, -0.0989058, -0.0867138, -0.158595, 0.155576, ...]\n",
      "  T#79(model/BLOCK_3-2_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 80, data:[0.0597176, -0.0259545, -0.000706167, -0.0420036, -0.0490324, ...]\n",
      "  T#80(model/BLOCK_3-2_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 81, data:[0.324125, 0.138069, 0.466153, -0.375846, 0.431644, ...]\n",
      "  T#81(model/BLOCK_3-2_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 82, data:[0.317052, -0.00767023, -0.111318, -0.0870155, -0.0846622, ...]\n",
      "  T#82(model/BLOCK_3-2_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 83, data:[0.0697687, -0.206735, 0.109114, 0.121937, 0.0107974, ...]\n",
      "  T#83(model/BLOCK_3-3_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 84, data:[0.0131174, 0.00535706, 0.0266619, -0.0648822, 2.78373e-05, ...]\n",
      "  T#84(model/BLOCK_3-3_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 85, data:[0.0227193, -0.0669719, 1.52158, -0.018394, 0.124296, ...]\n",
      "  T#85(model/BLOCK_3-3_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 86, data:[0.00274766, 0.154431, -0.3122, -0.710318, -0.0499839, ...]\n",
      "  T#86(model/BLOCK_3-3_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 87, data:[0.216798, 0.0985736, 0.122017, 0.0663547, -0.0423421, ...]\n",
      "  T#87(model/BLOCK_3-4_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 88, data:[-0.0530763, 0.030002, -0.00109313, 0.00830229, 0.0295681, ...]\n",
      "  T#88(model/BLOCK_3-4_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 89, data:[0.335489, -0.0140383, -0.2259, 0.299023, -0.151196, ...]\n",
      "  T#89(model/BLOCK_3-4_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 90, data:[-0.275259, 0.620791, -0.201793, -0.390887, 0.389617, ...]\n",
      "  T#90(model/BLOCK_3-4_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 91, data:[0.008953, -0.178044, 0.10984, 0.027595, -0.019051, ...]\n",
      "  T#91(model/BLOCK_3-5_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:FLOAT32 RO 409600 bytes, buffer: 92, data:[-0.0592428, -0.0289971, -0.0524392, 0.0252963, -0.00123223, ...]\n",
      "  T#92(model/BLOCK_3-5_SE_CONV_1/Conv2D1) shape:[40, 1, 1, 640], type:FLOAT32 RO 102400 bytes, buffer: 93, data:[0.43411, -0.114498, -0.0396519, 0.3074, 0.0421896, ...]\n",
      "  T#93(model/BLOCK_3-5_SE_CONV_2/Conv2D1) shape:[640, 1, 1, 40], type:FLOAT32 RO 102400 bytes, buffer: 94, data:[-0.297735, 0.290233, -0.57969, 0.101273, 0.230248, ...]\n",
      "  T#94(model/BLOCK_3-5_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:FLOAT32 RO 409600 bytes, buffer: 95, data:[0.0355608, 0.139506, -0.0253758, -0.116553, -0.247544, ...]\n",
      "  T#95(model/BLOCK_4-1_CONV_1/Conv2D) shape:[1120, 1, 1, 160], type:FLOAT32 RO 716800 bytes, buffer: 96, data:[-0.0420035, 0.0268913, 0.0743375, -0.00304259, 0.0097754, ...]\n",
      "  T#96(model/BLOCK_4-4_SE_CONV_1/Conv2D) shape:[70], type:FLOAT32 RO 280 bytes, buffer: 97, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#97(model/BLOCK_4-1_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 98, data:[-0.114728, -0.486454, -0.0725451, -0.105543, 0.206242, ...]\n",
      "  T#98(model/BLOCK_4-1_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 99, data:[0.0107329, -0.25262, 0.189735, 0.519728, 0.306989, ...]\n",
      "  T#99(model/BLOCK_4-1_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 100, data:[0.155144, 0.03334, -0.0436219, -0.0635754, -0.0201717, ...]\n",
      "  T#100(model/BLOCK_4-2_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:FLOAT32 RO 1254400 bytes, buffer: 101, data:[0.0775721, 0.0300743, 0.0787118, 0.033277, 0.0518173, ...]\n",
      "  T#101(model/BLOCK_4-2_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 102, data:[-0.432114, -0.0357772, -0.146629, 0.377912, -0.445993, ...]\n",
      "  T#102(model/BLOCK_4-2_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 103, data:[-0.0556371, 0.0161514, -0.236468, 0.562922, 0.757015, ...]\n",
      "  T#103(model/BLOCK_4-2_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 104, data:[-0.0254576, -0.0813834, 0.019934, -0.0212499, 0.0630072, ...]\n",
      "  T#104(model/BLOCK_4-3_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:FLOAT32 RO 1254400 bytes, buffer: 105, data:[0.084308, -0.104739, -0.11943, 0.137802, -0.100788, ...]\n",
      "  T#105(model/BLOCK_4-3_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 106, data:[-0.480569, -0.185401, -0.246157, -0.254998, 0.0226147, ...]\n",
      "  T#106(model/BLOCK_4-3_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 107, data:[0.76853, 0.272858, -0.0406274, 0.128225, -0.261265, ...]\n",
      "  T#107(model/BLOCK_4-3_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 108, data:[-0.103587, 0.0651307, 0.0905246, 0.0311029, 0.0932062, ...]\n",
      "  T#108(model/BLOCK_4-4_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:FLOAT32 RO 1254400 bytes, buffer: 109, data:[0.140507, 0.0259408, -0.00318167, 0.0121001, 0.0472033, ...]\n",
      "  T#109(model/BLOCK_4-4_SE_CONV_1/Conv2D1) shape:[70, 1, 1, 1120], type:FLOAT32 RO 313600 bytes, buffer: 110, data:[-0.0174236, -0.051295, -0.0601223, 0.0875765, 0.0552255, ...]\n",
      "  T#110(model/BLOCK_4-4_SE_CONV_2/Conv2D1) shape:[1120, 1, 1, 70], type:FLOAT32 RO 313600 bytes, buffer: 111, data:[-0.212755, -0.172498, -0.269743, -0.014416, -0.32258, ...]\n",
      "  T#111(model/BLOCK_4-4_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:FLOAT32 RO 1254400 bytes, buffer: 112, data:[0.0212589, 0.056527, 0.0380439, 0.0511093, -0.128075, ...]\n",
      "  T#112(model/POST_CONV_1/Conv2D) shape:[420, 3, 3, 280], type:FLOAT32 RO 4233600 bytes, buffer: 113, data:[-0.0291094, -0.0061691, 0.0503138, 0.0581343, 0.0575725, ...]\n",
      "  T#113(ReadVariableOp;ReadVariableOp) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 114, data:[1.46607]\n",
      "  T#114(truediv;truediv;ReadVariableOp;ReadVariableOp) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 115, data:[0.682098]\n",
      "  T#115(model/BLOCK_3-1_SE_AVG_POOL_1/Mean/reduction_indices) shape:[2], type:INT32 RO 8 bytes, buffer: 116, data:[1, 2]\n",
      "  T#116(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape/1) shape:[], type:INT32 RO 4 bytes, buffer: 117, data:[1]\n",
      "  T#117(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 118, data:[640]\n",
      "  T#118(model/BLOCK_3-1_SE_RESHAPE/strided_slice/stack) shape:[1], type:INT32 RO 4 bytes, buffer: 119, data:[0]\n",
      "  T#119(model/BLOCK_3-1_SE_RESHAPE/strided_slice/stack_1) shape:[1], type:INT32 RO 4 bytes, buffer: 117, data:[1]\n",
      "  T#120(model/BLOCK_4-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 121, data:[1120]\n",
      "  T#121(truediv_1;truediv_1) shape:[], type:FLOAT32 RO 4 bytes, buffer: 122, data:[0.262867]\n",
      "  T#122(stft/hann_window/sub_2;stft/hann_window/sub_2) shape:[512], type:FLOAT32 RO 2048 bytes, buffer: 123, data:[0, 3.76403e-05, 0.000150591, 0.000338793, 0.000602275, ...]\n",
      "  T#123(stft/frame/Reshape_3;stft/frame/Reshape_3) shape:[1, 64], type:INT32 RO 256 bytes, buffer: 124, data:[0, 1, 2, 3, 4, ...]\n",
      "  T#124(stft/frame/packed;stft/frame/packed) shape:[3], type:INT32 RO 12 bytes, buffer: 125, data:[1, 1, 0]\n",
      "  T#125(stft/frame/ones_like;stft/frame/ones_like) shape:[2], type:INT32 RO 8 bytes, buffer: 126, data:[1, 1]\n",
      "  T#126(stft/frame/floordiv_2;stft/frame/floordiv_2) shape:[], type:INT32 RO 4 bytes, buffer: 127, data:[35]\n",
      "  T#127(transpose/perm;transpose/perm) shape:[3], type:INT32 RO 12 bytes, buffer: 128, data:[0, 2, 1]\n",
      "  T#128(strided_slice/stack_2;strided_slice/stack_2) shape:[3], type:INT32 RO 12 bytes, buffer: 129, data:[1, 1, 1]\n",
      "  T#129(strided_slice/stack_1;strided_slice/stack_1) shape:[3], type:INT32 RO 12 bytes, buffer: 130, data:[0, 0, 128]\n",
      "  T#130(strided_slice/stack;strided_slice/stack) shape:[3], type:INT32 RO 12 bytes, buffer: 131, data:[0, 0, 0]\n",
      "  T#131(stft/frame_step;stft/frame_step) shape:[], type:INT32 RO 4 bytes, buffer: 132, data:[280]\n",
      "  T#132(stft/frame_length;stft/frame_length) shape:[], type:INT32 RO 4 bytes, buffer: 133, data:[512]\n",
      "  T#133(stft/frame/zeros_like;stft/frame/zeros_like) shape:[2], type:INT32 RO 8 bytes, buffer: 134, data:[0, 0]\n",
      "  T#134(stft/frame/concat_1/values_1/1;stft/frame/concat_1/values_1/1) shape:[], type:INT32 RO 4 bytes, buffer: 135, data:[8]\n",
      "  T#135(stft/frame/Reshape/shape_1;stft/frame/Reshape/shape_1) shape:[0], type:INT32\n",
      "  T#136(stft/frame/Maximum/x;stft/frame/Maximum/x) shape:[], type:INT32 RO 4 bytes, buffer: 119, data:[0]\n",
      "  T#137(ExpandDims/dim;ExpandDims/dim) shape:[], type:INT32 RO 4 bytes, buffer: 138, data:[-1]\n",
      "  T#138(model/BNORM_SPEC_NOQUANT/FusedBatchNormV3) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 139, data:[1.24676]\n",
      "  T#139(model/BNORM_SPEC_NOQUANT/FusedBatchNormV31) shape:[1], type:FLOAT32 RO 4 bytes, buffer: 140, data:[-0.118066]\n",
      "  T#140(model/BNORM_POST_NOQUANT/FusedBatchNormV3) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 141, data:[0.346286, 0.419046, 0.374378, 0.392926, 0.321534, ...]\n",
      "  T#141(model/BNORM_POST_NOQUANT/FusedBatchNormV31) shape:[280], type:FLOAT32 RO 1120 bytes, buffer: 142, data:[0.374975, 0.296045, 0.377884, 0.231385, 0.356721, ...]\n",
      "  T#142(Min;Min) shape_signature:[-1, 1], type:FLOAT32\n",
      "  T#143(Sub;Sub) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#144(Max;Max) shape_signature:[-1, 1], type:FLOAT32\n",
      "  T#145(truediv;truediv) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#146(stft/frame/Shape;stft/frame/Shape) shape:[2], type:INT32\n",
      "  T#147(stft/frame/split;stft/frame/split) shape:[1], type:INT32\n",
      "  T#148(stft/frame/split;stft/frame/split1) shape:[1], type:INT32\n",
      "  T#149(stft/frame/split;stft/frame/split2) shape:[0], type:INT32\n",
      "  T#150(stft/frame/Reshape;stft/frame/Reshape) shape:[], type:INT32\n",
      "  T#151(stft/frame/floordiv_3;stft/frame/floordiv_3) shape:[], type:INT32\n",
      "  T#152(stft/frame/concat_1/values_1;stft/frame/concat_1/values_1) shape:[2], type:INT32\n",
      "  T#153(stft/frame/mul;stft/frame/mul) shape:[], type:INT32\n",
      "  T#154(stft/frame/concat/values_1;stft/frame/concat/values_1) shape:[1], type:INT32\n",
      "  T#155(stft/frame/concat;stft/frame/concat) shape:[2], type:INT32\n",
      "  T#156(stft/frame/concat_1;stft/frame/concat_1) shape:[3], type:INT32\n",
      "  T#157(stft/frame/StridedSlice;stft/frame/StridedSlice) shape_signature:[-1, -1], type:FLOAT32\n",
      "  T#158(stft/frame/Reshape_1;stft/frame/Reshape_1) shape_signature:[-1, -1, 8], type:FLOAT32\n",
      "  T#159(stft/frame/sub_2;stft/frame/sub_2) shape:[], type:INT32\n",
      "  T#160(stft/frame/floordiv;stft/frame/floordiv) shape:[], type:INT32\n",
      "  T#161(stft/frame/add;stft/frame/add) shape:[], type:INT32\n",
      "  T#162(stft/frame/Maximum;stft/frame/Maximum) shape:[], type:INT32\n",
      "  T#163(stft/frame/Reshape_2/shape;stft/frame/Reshape_2/shape) shape:[2], type:INT32\n",
      "  T#164(stft/frame/concat_2/values_1;stft/frame/concat_2/values_1) shape:[2], type:INT32\n",
      "  T#165(stft/frame/concat_2;stft/frame/concat_2) shape:[3], type:INT32\n",
      "  T#166(stft/frame/range_1;stft/frame/range_1) shape_signature:[-1], type:INT32\n",
      "  T#167(stft/frame/mul_1;stft/frame/mul_1) shape_signature:[-1], type:INT32\n",
      "  T#168(stft/frame/Reshape_2;stft/frame/Reshape_2) shape_signature:[-1, 1], type:INT32\n",
      "  T#169(stft/frame/add_1;stft/frame/add_1) shape_signature:[-1, 64], type:INT32\n",
      "  T#170(stft/frame/GatherV2;stft/frame/GatherV2;model/BLOCK_3-1_SE_RESHAPE/Reshape/shape/1) shape_signature:[-1, -1, 64, 8], type:FLOAT32\n",
      "  T#171(stft/frame/Reshape_4;stft/frame/Reshape_4) shape_signature:[-1, -1, 512], type:FLOAT32\n",
      "  T#172(stft/mul;stft/mul) shape_signature:[-1, -1, 512], type:FLOAT32\n",
      "  T#173(stft/rfft;stft/rfft2) shape_signature:[-1, -1, 1, 512], type:FLOAT32\n",
      "  T#174(stft/rfft;stft/rfft3) shape_signature:[-1, -1, 1, 257], type:COMPLEX64\n",
      "  T#175(stft/rfft;stft/rfft4) shape_signature:[-1, -1, 257], type:COMPLEX64\n",
      "  T#176(Cast;Cast) shape_signature:[-1, -1, 257], type:FLOAT32\n",
      "  T#177(strided_slice;strided_slice) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#178(Pow;Pow;Pow/y;Pow/y) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#179(Pow_1;Pow_1) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#180(transpose;transpose) shape_signature:[-1, 128, -1], type:FLOAT32\n",
      "  T#181(ExpandDims;ExpandDims) shape_signature:[-1, 128, -1, 1], type:FLOAT32\n",
      "  T#182(model/BNORM_SPEC_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 128, -1, 1], type:FLOAT32\n",
      "  T#183(model/BNORM_SPEC_NOQUANT/FusedBatchNormV33) shape_signature:[-1, 128, -1, 1], type:FLOAT32\n",
      "  T#184(model/ACT_0/Relu;model/BNORM_0/FusedBatchNormV3;model/pool_0_CONV/Conv2D;model/CONV_0/Conv2D) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#185(model/pool_0_AVG/AvgPool) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#186(model/pool_0_MAX/MaxPool) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#187(model/pool_0_CONCAT/concat) shape_signature:[-1, 64, -1, 60], type:FLOAT32\n",
      "  T#188(model/pool_0_CONV/BiasAdd;model/pool_0_CONV/Conv2D;model/pool_0_CONV/BiasAdd/ReadVariableOp) shape_signature:[-1, 64, -1, 30], type:FLOAT32\n",
      "  T#189(model/BLOCK_1-1_BN_1/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-1_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#190(model/BLOCK_1-1_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#191(model/BLOCK_1-1_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#192(model/BLOCK_1-1_BN_3/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-1_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#193(model/BLOCK_1-2_BN_1/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-2_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#194(model/BLOCK_1-2_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#195(model/BLOCK_1-2_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#196(model/BLOCK_1-2_BN_3/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-2_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#197(model/BLOCK_1-2_ADD/add) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#198(model/BLOCK_1-3_BN_1/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-3_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#199(model/BLOCK_1-3_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#200(model/BLOCK_1-3_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#201(model/BLOCK_1-3_BN_3/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#202(model/BLOCK_1-3_ADD/add) shape_signature:[-1, 32, -1, 60], type:FLOAT32\n",
      "  T#203(model/BLOCK_2-1_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D;model/BLOCK_2-1_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#204(model/BLOCK_2-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#205(model/BLOCK_2-1_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#206(model/BLOCK_2-1_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D;model/BLOCK_2-1_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#207(model/BLOCK_2-2_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D;model/BLOCK_2-2_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#208(model/BLOCK_2-2_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#209(model/BLOCK_2-2_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#210(model/BLOCK_2-2_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D;model/BLOCK_2-2_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#211(model/BLOCK_2-2_ADD/add) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#212(model/BLOCK_2-3_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D;model/BLOCK_2-3_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#213(model/BLOCK_2-3_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#214(model/BLOCK_2-3_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#215(model/BLOCK_2-3_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D;model/BLOCK_2-3_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#216(model/BLOCK_2-3_ADD/add) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#217(model/BLOCK_2-4_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#218(model/BLOCK_2-4_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#219(model/BLOCK_2-4_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:FLOAT32\n",
      "  T#220(model/BLOCK_2-4_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#221(model/BLOCK_2-4_ADD/add) shape_signature:[-1, 16, -1, 120], type:FLOAT32\n",
      "  T#222(model/BLOCK_3-1_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-1_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 640], type:FLOAT32\n",
      "  T#223(model/BLOCK_3-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 640], type:FLOAT32\n",
      "  T#224(model/BLOCK_3-1_ACT_1/mul_1) shape_signature:[-1, 16, -1, 640], type:FLOAT32\n",
      "  T#225(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-1_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#226(model/BLOCK_3-1_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#227(model/BLOCK_3-1_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#228(model/BLOCK_3-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#229(model/BLOCK_3-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#230(model/BLOCK_3-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#231(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#232(model/BLOCK_3-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#233(model/BLOCK_3-1_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#234(model/BLOCK_3-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#235(model/BLOCK_3-1_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#236(model/BLOCK_3-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#237(model/BLOCK_3-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#238(model/BLOCK_3-1_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#239(model/BLOCK_3-1_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-1_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#240(model/BLOCK_3-2_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-2_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#241(model/BLOCK_3-2_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#242(model/BLOCK_3-2_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#243(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-2_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#244(model/BLOCK_3-2_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#245(model/BLOCK_3-2_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#246(model/BLOCK_3-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#247(model/BLOCK_3-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#248(model/BLOCK_3-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#249(model/BLOCK_3-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#250(model/BLOCK_3-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#251(model/BLOCK_3-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#252(model/BLOCK_3-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#253(model/BLOCK_3-2_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#254(model/BLOCK_3-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#255(model/BLOCK_3-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#256(model/BLOCK_3-2_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#257(model/BLOCK_3-2_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-2_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#258(model/BLOCK_3-2_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#259(model/BLOCK_3-3_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-3_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#260(model/BLOCK_3-3_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#261(model/BLOCK_3-3_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#262(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-3_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#263(model/BLOCK_3-3_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#264(model/BLOCK_3-3_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#265(model/BLOCK_3-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#266(model/BLOCK_3-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#267(model/BLOCK_3-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#268(model/BLOCK_3-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#269(model/BLOCK_3-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#270(model/BLOCK_3-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#271(model/BLOCK_3-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#272(model/BLOCK_3-3_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#273(model/BLOCK_3-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#274(model/BLOCK_3-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#275(model/BLOCK_3-3_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#276(model/BLOCK_3-3_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-3_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#277(model/BLOCK_3-3_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#278(model/BLOCK_3-4_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-4_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#279(model/BLOCK_3-4_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#280(model/BLOCK_3-4_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#281(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-4_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#282(model/BLOCK_3-4_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#283(model/BLOCK_3-4_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#284(model/BLOCK_3-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#285(model/BLOCK_3-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#286(model/BLOCK_3-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#287(model/BLOCK_3-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#288(model/BLOCK_3-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#289(model/BLOCK_3-4_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#290(model/BLOCK_3-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#291(model/BLOCK_3-4_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#292(model/BLOCK_3-4_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#293(model/BLOCK_3-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#294(model/BLOCK_3-4_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#295(model/BLOCK_3-4_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-4_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#296(model/BLOCK_3-4_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#297(model/BLOCK_3-5_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-5_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#298(model/BLOCK_3-5_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#299(model/BLOCK_3-5_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#300(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-5_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#301(model/BLOCK_3-5_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#302(model/BLOCK_3-5_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#303(model/BLOCK_3-5_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:FLOAT32\n",
      "  T#304(model/BLOCK_3-5_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#305(model/BLOCK_3-5_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#306(model/BLOCK_3-5_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#307(model/BLOCK_3-5_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#308(model/BLOCK_3-5_SE_CONV_1/Conv2D2) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#309(model/BLOCK_3-5_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#310(model/BLOCK_3-5_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:FLOAT32\n",
      "  T#311(model/BLOCK_3-5_SE_CONV_2/Conv2D2) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#312(model/BLOCK_3-5_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:FLOAT32\n",
      "  T#313(model/BLOCK_3-5_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:FLOAT32\n",
      "  T#314(model/BLOCK_3-5_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#315(model/BLOCK_3-5_ADD/add) shape_signature:[-1, 8, -1, 160], type:FLOAT32\n",
      "  T#316(model/BLOCK_4-1_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-1_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 1120], type:FLOAT32\n",
      "  T#317(model/BLOCK_4-1_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 1120], type:FLOAT32\n",
      "  T#318(model/BLOCK_4-1_ACT_1/mul_1) shape_signature:[-1, 8, -1, 1120], type:FLOAT32\n",
      "  T#319(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-1_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#320(model/BLOCK_4-1_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#321(model/BLOCK_4-1_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#322(model/BLOCK_4-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#323(model/BLOCK_4-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#324(model/BLOCK_4-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#325(model/BLOCK_4-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#326(model/BLOCK_4-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#327(model/BLOCK_4-1_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#328(model/BLOCK_4-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#329(model/BLOCK_4-1_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#330(model/BLOCK_4-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#331(model/BLOCK_4-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#332(model/BLOCK_4-1_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#333(model/BLOCK_4-1_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D;model/BLOCK_4-1_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#334(model/BLOCK_4-2_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-2_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#335(model/BLOCK_4-2_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#336(model/BLOCK_4-2_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#337(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-2_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#338(model/BLOCK_4-2_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#339(model/BLOCK_4-2_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#340(model/BLOCK_4-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#341(model/BLOCK_4-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#342(model/BLOCK_4-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#343(model/BLOCK_4-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#344(model/BLOCK_4-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#345(model/BLOCK_4-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#346(model/BLOCK_4-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#347(model/BLOCK_4-2_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#348(model/BLOCK_4-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#349(model/BLOCK_4-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#350(model/BLOCK_4-2_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#351(model/BLOCK_4-2_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D;model/BLOCK_4-2_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#352(model/BLOCK_4-2_ADD/add) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#353(model/BLOCK_4-3_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-3_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#354(model/BLOCK_4-3_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#355(model/BLOCK_4-3_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#356(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-3_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#357(model/BLOCK_4-3_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#358(model/BLOCK_4-3_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#359(model/BLOCK_4-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#360(model/BLOCK_4-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#361(model/BLOCK_4-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#362(model/BLOCK_4-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#363(model/BLOCK_4-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#364(model/BLOCK_4-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#365(model/BLOCK_4-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#366(model/BLOCK_4-3_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#367(model/BLOCK_4-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#368(model/BLOCK_4-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#369(model/BLOCK_4-3_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#370(model/BLOCK_4-3_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D;model/BLOCK_4-3_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#371(model/BLOCK_4-3_ADD/add) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#372(model/BLOCK_4-4_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-4_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#373(model/BLOCK_4-4_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#374(model/BLOCK_4-4_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#375(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-4_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#376(model/BLOCK_4-4_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#377(model/BLOCK_4-4_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#378(model/BLOCK_4-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:FLOAT32\n",
      "  T#379(model/BLOCK_4-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#380(model/BLOCK_4-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#381(model/BLOCK_4-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#382(model/BLOCK_4-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#383(model/BLOCK_4-4_SE_CONV_1/Conv2D2) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#384(model/BLOCK_4-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#385(model/BLOCK_4-4_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:FLOAT32\n",
      "  T#386(model/BLOCK_4-4_SE_CONV_2/Conv2D2) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#387(model/BLOCK_4-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:FLOAT32\n",
      "  T#388(model/BLOCK_4-4_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:FLOAT32\n",
      "  T#389(model/BLOCK_4-4_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#390(model/BLOCK_4-4_ADD/add) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#391(model/BNORM_POST_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#392(model/ACT_POST/Relu;model/BNORM_POST_NOQUANT/FusedBatchNormV3) shape_signature:[-1, 4, -1, 280], type:FLOAT32\n",
      "  T#393(model/POST_ACT_1/Relu;model/POST_BN_1/FusedBatchNormV3;model/POST_CONV_1/Conv2D) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#394(Max;Max1) shape_signature:[-1, 1, 1, 420], type:FLOAT32\n",
      "  T#395(Max_1;Max_1) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#396(sub;sub) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#397(mul;mul) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#398(Exp;Exp) shape_signature:[-1, 2, -1, 420], type:FLOAT32\n",
      "  T#399(Mean;Mean) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#400(Log;Log) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#401(truediv;truediv;ReadVariableOp;ReadVariableOp1) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#402(StatefulPartitionedCall:0) shape_signature:[-1, 420], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has '1' signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'INPUT' : T#0\n",
      "- Outputs: \n",
      "    'GLOBAL_LME_POOL' : T#402\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:   26155172 bytes\n",
      "    Non-data buffer size:      62736 bytes (00.24 %)\n",
      "  Total data buffer size:   26092436 bytes (99.76 %)\n",
      "    (Zero value buffers):       7504 bytes (00.03 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_testexport = \"/home/jovyan/20230717_test_layer_remove.tflite\"\n",
    "tf.lite.experimental.Analyzer.analyze(model_path=path_to_testexport,\n",
    "                                      model_content=None,\n",
    "                                      gpu_compatibility=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb79cf-d46d-47b8-bb5a-35434883e587",
   "metadata": {},
   "source": [
    "---\n",
    "## -> also removed Tensors from Dense Layer (T#142 and T#135)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

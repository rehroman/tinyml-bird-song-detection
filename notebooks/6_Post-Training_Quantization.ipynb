{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424f1f80-d145-48f5-b3f2-162591538540",
   "metadata": {},
   "source": [
    "### Full integer post-training quantization of weights and activations into 8-bit integer, except for input output\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594e23c-5ff3-4f30-8d00-afdd74de1f8c",
   "metadata": {},
   "source": [
    "#### Load validation data and convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "914f973f-d82a-413d-9e9b-15f8a9eaad4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 15:54:30.845349: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-07 15:54:30.889253: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-07 15:54:30.890194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-07 15:54:31.514154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.920_0001_270097.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.930_0002_182583971.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.940_0004_534761.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.950_0018_226391901.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/0.970_0017_647758.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0001_0H2uMhzSitY_520.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0002_--ivFZu-hlc_30.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0002_2RpOd9MJjyQ_10.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0003_-w4HLksto_k_30.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/validation/non_target/1.000_0003_6m5hv5BX7KU_40.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.480_0001_200614_1467_1.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.920_0103_669234.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.940_0015_139518451.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.950_0064_558294.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/validation/target/0.970_0001_155008.wav\n",
      "...Done. Loaded 1381 validation samples and 2 labels.\n"
     ]
    }
   ],
   "source": [
    "import data as datapy\n",
    "\n",
    "val_data_path = \"/home/jovyan/cut-data/validation/\"\n",
    "\n",
    "# load validation as representative data for quantization\n",
    "print('Loading validation data...', flush=True)\n",
    "x_val, y_val, labels, file_paths_val = datapy.loadData(val_data_path)\n",
    "print('...Done. Loaded {} validation samples and {} labels.'.format(x_val.shape[0], y_val.shape[1]), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2832e-eef0-4abb-b7be-ede92734a361",
   "metadata": {},
   "source": [
    "### Load dataset generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3f7d8-d3ad-479e-9155-90b7c5dafa49",
   "metadata": {},
   "source": [
    "#### Balance the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10ae4736-da5c-436a-94a2-bda04c348e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance the validation data...\n",
      "Balanced validation data:\n",
      "balanced_x_val shape: (944,)\n",
      "balanced_y_val shape: (944, 2)\n",
      "balanced_file_paths_val shape: (944,)\n",
      "...Done. Loaded 944 validation samples and 944 labels.\n"
     ]
    }
   ],
   "source": [
    "# balance the validation data:\n",
    "print('Balance the validation data...')\n",
    "\n",
    "y_val_indices = np.argmax(y_val, axis=1)\n",
    "\n",
    "# minimum of one class\n",
    "min_samples = min(np.bincount(y_val_indices))\n",
    "\n",
    "# reduce entries until minimum after shuffle \n",
    "balanced_x_val = []\n",
    "balanced_y_val = []\n",
    "balanced_file_paths_val = []\n",
    "for label in np.unique(y_val_indices):\n",
    "    indices = np.where(y_val_indices == label)[0]\n",
    "    np.random.shuffle(indices)  # Random order for random removal of samples\n",
    "    indices = indices[:min_samples]\n",
    "    balanced_x_val.append(x_val[indices])\n",
    "    balanced_y_val.append(y_val[indices])\n",
    "    balanced_file_paths_val.extend(file_paths_val[indices])\n",
    "\n",
    "# Combine the balanced data for all classes\n",
    "balanced_x_val = np.concatenate(balanced_x_val, axis=0)\n",
    "balanced_y_val = np.concatenate(balanced_y_val, axis=0)\n",
    "balanced_file_paths_val = np.array(balanced_file_paths_val)\n",
    "\n",
    "print('Balanced validation data:')\n",
    "print('balanced_x_val shape:', balanced_x_val.shape)\n",
    "print('balanced_y_val shape:', balanced_y_val.shape)\n",
    "print('balanced_file_paths_val shape:', balanced_file_paths_val.shape)\n",
    "\n",
    "print('...Done. Loaded {} validation samples and {} labels.'.format(balanced_x_val.shape[0], balanced_y_val.shape[0]), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e4786b14-b3f4-4a0d-bd98-bff47810619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "x_val = np.array(balanced_x_val, dtype='float32')\n",
    "y_val = np.array(balanced_y_val, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "819b4b75-8a70-4c53-ac3f-3ad2c799bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as modelpy\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "\n",
    "\n",
    "val_gen = modelpy.AudioDataGenerator(balanced_file_paths_val, balanced_y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c68221-60b0-4c9e-8492-35449de50a78",
   "metadata": {},
   "source": [
    "##### Load Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aaba55cc-6a9c-413c-9d06-9a6331de521e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading keras model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " INPUT (InputLayer)          [(None, 144000)]             0         []                            \n",
      "                                                                                                  \n",
      " ADVANCED_SPEC1 (LinearSpec  (None, 128, 513, 1)          1         ['INPUT[0][0]']               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " BNORM_SPEC_NOQUANT (BatchN  (None, 128, 513, 1)          4         ['ADVANCED_SPEC1[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " CONV_0 (Conv2D)             (None, 64, 257, 30)          960       ['BNORM_SPEC_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " BNORM_0 (BatchNormalizatio  (None, 64, 257, 30)          120       ['CONV_0[0][0]']              \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " ACT_0 (Activation)          (None, 64, 257, 30)          0         ['BNORM_0[0][0]']             \n",
      "                                                                                                  \n",
      " pool_0_MAX (MaxPooling2D)   (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      "                                                                                                  \n",
      " pool_0_AVG (AveragePooling  (None, 64, 128, 30)          0         ['ACT_0[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONCAT (Concatenate  (None, 64, 128, 60)          0         ['pool_0_MAX[0][0]',          \n",
      " )                                                                   'pool_0_AVG[0][0]']          \n",
      "                                                                                                  \n",
      " pool_0_ACT_QUANT (Activati  (None, 64, 128, 60)          0         ['pool_0_CONCAT[0][0]']       \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " pool_0_CONV (Conv2D)        (None, 64, 128, 30)          1830      ['pool_0_ACT_QUANT[0][0]']    \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_1 (Conv2D)   (None, 32, 64, 60)           16200     ['pool_0_CONV[0][0]']         \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-1_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-1_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-1_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-2_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-2_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-2_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_1 (Conv2D)   (None, 32, 64, 60)           32400     ['BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_1 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_1 (Activatio  (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ACT_QUANT (Activ  (None, 32, 64, 60)           0         ['BLOCK_1-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_1-3_CONV_3 (Conv2D)   (None, 32, 64, 60)           3600      ['BLOCK_1-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_1-3_BN_3 (BatchNorma  (None, 32, 64, 60)           240       ['BLOCK_1-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_1-3_ADD (Add)         (None, 32, 64, 60)           0         ['BLOCK_1-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_1-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_1 (Conv2D)   (None, 16, 32, 240)          129600    ['BLOCK_1-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-1_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-1_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-1_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-1_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-2_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-2_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-2_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-2_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-3_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-3_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-3_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-3_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_1 (Conv2D)   (None, 16, 32, 240)          259200    ['BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_1 (BatchNorma  (None, 16, 32, 240)          960       ['BLOCK_2-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_1 (Activatio  (None, 16, 32, 240)          0         ['BLOCK_2-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ACT_QUANT (Activ  (None, 16, 32, 240)          0         ['BLOCK_2-4_ACT_1[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_2-4_CONV_3 (Conv2D)   (None, 16, 32, 120)          28800     ['BLOCK_2-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_2-4_BN_3 (BatchNorma  (None, 16, 32, 120)          480       ['BLOCK_2-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_2-4_ADD (Add)         (None, 16, 32, 120)          0         ['BLOCK_2-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_2-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_1 (Conv2D)   (None, 16, 32, 640)          76800     ['BLOCK_2-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_1 (BatchNorma  (None, 16, 32, 640)          2560      ['BLOCK_3-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_1 (Activatio  (None, 16, 32, 640)          0         ['BLOCK_3-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-1_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-1_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-1_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-2_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-2_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-2_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-2_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-3_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-3_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-3_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-3_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-4_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-4_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-4_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-4_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_1 (Conv2D)   (None, 8, 16, 640)           102400    ['BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_1 (BatchNorma  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_1 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_2 (Depthwis  (None, 8, 16, 640)           5760      ['BLOCK_3-5_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_2_NOQUANT (Ba  (None, 8, 16, 640)           2560      ['BLOCK_3-5_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_2 (Activatio  (None, 8, 16, 640)           0         ['BLOCK_3-5_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_AVG_POOL_1 (G  (None, 640)                  0         ['BLOCK_3-5_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_RESHAPE (Resh  (None, 1, 1, 640)            0         ['BLOCK_3-5_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_1 (Conv2  (None, 1, 1, 40)             25600     ['BLOCK_3-5_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_SE_CONV_2 (Conv2  (None, 1, 1, 640)            25600     ['BLOCK_3-5_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_3-5_MULTIPLY (Multip  (None, 8, 16, 640)           0         ['BLOCK_3-5_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_3-5_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ACT_QUANT (Activ  (None, 8, 16, 640)           0         ['BLOCK_3-5_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_3-5_CONV_3 (Conv2D)   (None, 8, 16, 160)           102400    ['BLOCK_3-5_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_3-5_BN_3 (BatchNorma  (None, 8, 16, 160)           640       ['BLOCK_3-5_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_3-5_ADD (Add)         (None, 8, 16, 160)           0         ['BLOCK_3-5_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_3-4_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_1 (Conv2D)   (None, 8, 16, 1120)          179200    ['BLOCK_3-5_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_1 (BatchNorma  (None, 8, 16, 1120)          4480      ['BLOCK_4-1_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_1 (Activatio  (None, 8, 16, 1120)          0         ['BLOCK_4-1_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-1_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-1_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-1_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-1_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-1_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-1_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-1_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-1_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-1_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-1_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-1_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-1_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-1_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-1_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-1_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-2_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-2_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-2_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-2_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-2_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-2_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-2_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-2_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-2_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-2_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-2_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-2_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-2_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-2_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-2_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-2_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-2_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-1_BN_3[0][0]']      \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-3_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-3_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-3_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-3_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-3_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-3_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-3_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-3_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-3_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-3_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-3_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-3_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-3_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-3_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-3_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-3_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-3_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-2_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_1 (Conv2D)   (None, 4, 8, 1120)           313600    ['BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_1 (BatchNorma  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_1[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_1 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_2 (Depthwis  (None, 4, 8, 1120)           10080     ['BLOCK_4-4_ACT_1[0][0]']     \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_2_NOQUANT (Ba  (None, 4, 8, 1120)           4480      ['BLOCK_4-4_CONV_2[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_2 (Activatio  (None, 4, 8, 1120)           0         ['BLOCK_4-4_BN_2_NOQUANT[0][0]\n",
      " n)                                                                 ']                            \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_AVG_POOL_1 (G  (None, 1120)                 0         ['BLOCK_4-4_ACT_2[0][0]']     \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_RESHAPE (Resh  (None, 1, 1, 1120)           0         ['BLOCK_4-4_SE_AVG_POOL_1[0][0\n",
      " ape)                                                               ]']                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_1 (Conv2  (None, 1, 1, 70)             78400     ['BLOCK_4-4_SE_RESHAPE[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_SE_CONV_2 (Conv2  (None, 1, 1, 1120)           78400     ['BLOCK_4-4_SE_CONV_1[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " BLOCK_4-4_MULTIPLY (Multip  (None, 4, 8, 1120)           0         ['BLOCK_4-4_ACT_2[0][0]',     \n",
      " ly)                                                                 'BLOCK_4-4_SE_CONV_2[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ACT_QUANT (Activ  (None, 4, 8, 1120)           0         ['BLOCK_4-4_MULTIPLY[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " BLOCK_4-4_CONV_3 (Conv2D)   (None, 4, 8, 280)            313600    ['BLOCK_4-4_ACT_QUANT[0][0]'] \n",
      "                                                                                                  \n",
      " BLOCK_4-4_BN_3 (BatchNorma  (None, 4, 8, 280)            1120      ['BLOCK_4-4_CONV_3[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " BLOCK_4-4_ADD (Add)         (None, 4, 8, 280)            0         ['BLOCK_4-4_BN_3[0][0]',      \n",
      "                                                                     'BLOCK_4-3_ADD[0][0]']       \n",
      "                                                                                                  \n",
      " BNORM_POST_NOQUANT (BatchN  (None, 4, 8, 280)            1120      ['BLOCK_4-4_ADD[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " ACT_POST (Activation)       (None, 4, 8, 280)            0         ['BNORM_POST_NOQUANT[0][0]']  \n",
      "                                                                                                  \n",
      " POST_CONV_1 (Conv2D)        (None, 2, 6, 420)            1058400   ['ACT_POST[0][0]']            \n",
      "                                                                                                  \n",
      " POST_BN_1 (BatchNormalizat  (None, 2, 6, 420)            1680      ['POST_CONV_1[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " POST_ACT_1 (Activation)     (None, 2, 6, 420)            0         ['POST_BN_1[0][0]']           \n",
      "                                                                                                  \n",
      " GLOBAL_LME_POOL (GlobalLog  (None, 420)                  1         ['POST_ACT_1[0][0]']          \n",
      " ExpPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 3)                    1263      ['GLOBAL_LME_POOL[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2)                    8         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 2)                    0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6581027 (25.10 MB)\n",
      "Trainable params: 1271 (4.96 KB)\n",
      "Non-trainable params: 6579756 (25.10 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# baseline keras file which still has the activation layer in the end\n",
    "keras_baselineModel_activation_path = \"/home/jovyan/models/checkpoints_/baseline_two_class_model_activation/\"\n",
    "keras_baselineModel_activation = keras.models.load_model(keras_baselineModel_activation_path)\n",
    "\n",
    "print(\"Finished loading keras model\")\n",
    "\n",
    "keras_baselineModel_activation.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca1fb3-7ad0-43f0-989d-1736f538c590",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae4e23a7-4a21-491a-b19d-62e720e5bcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversion using Quantization...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpo4ycjq7j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo4ycjq7j/assets\n",
      "/opt/conda/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-08-07 18:05:24.366643: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-07 18:05:24.366706: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-07 18:05:24.367000: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpo4ycjq7j\n",
      "2023-08-07 18:05:24.392009: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-07 18:05:24.392064: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpo4ycjq7j\n",
      "2023-08-07 18:05:24.473649: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-07 18:05:24.860765: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpo4ycjq7j\n",
      "2023-08-07 18:05:25.014431: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 647431 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of val_gen: 79\n",
      "########NEW BATCH#######\n",
      "Shape of batch: 2\n",
      "########NEW ENTRY######\n",
      "Shape of input_value: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    print(\"Shape of val_gen:\", len(val_gen))\n",
    "    for batch in val_gen:\n",
    "        print(\"########NEW BATCH#######\")\n",
    "        print(\"Shape of batch:\", len(batch))\n",
    "        for input_value in batch:\n",
    "            print(\"########NEW ENTRY######\")\n",
    "            print(\"Shape of input_value:\", len(input_value))\n",
    "            yield [input_value]\n",
    "            break\n",
    "        break\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_baselineModel_activation)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "print('Starting conversion using Quantization...', flush=True)\n",
    "baseline_activation_INT8_tflite = converter.convert()\n",
    "print('...Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f5ef73-1121-4598-95af-2f6d09009cd2",
   "metadata": {},
   "source": [
    "#### Evaluate Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ed352fe-7f46-44e5-b8fe-b6a816f512d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the TFLite model: 6.99 MB\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=baseline_activation_INT8_tflite)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "tflite_size = len(baseline_activation_INT8_tflite) / (1024 * 1024)\n",
    "print(f\"Size of the TFLite model: {tflite_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c2344-08e6-4611-921c-a8b5ae7e252d",
   "metadata": {},
   "source": [
    "#### Save 8 intmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c72f756-be8d-412b-a04b-671a81e4a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the quantized model:\n",
    "tflite_model_INT8_path = \"/home/jovyan/models/checkpoints_/baseline_activation_INT8.tflite\"\n",
    "with open(tflite_model_INT8_path, \"wb\") as f:\n",
    "    f.write(baseline_activation_INT8_tflite)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914c9eb-a209-45bb-9dc3-72da7826825a",
   "metadata": {},
   "source": [
    "### Evaluate 8 int model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0a30d48-03a0-403a-bbe1-6480472372c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== /home/jovyan/models/checkpoints_/baseline_activation_INT8.tflite ===\n",
      "\n",
      "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
      "T# represents the Tensor numbers. For example, in Subgraph#0, the QUANTIZE op takes\n",
      "tensor #0 as input and produces tensor #160 as output.\n",
      "\n",
      "Subgraph#0 main(T#0) -> [T#434]\n",
      "  Op#0 QUANTIZE(T#0) -> [T#160]\n",
      "  Op#1 REDUCE_MIN(T#160, T#2[1]) -> [T#161]\n",
      "  Op#2 SUB(T#160, T#161) -> [T#162]\n",
      "  Op#3 DEQUANTIZE(T#162) -> [T#163]\n",
      "  Op#4 REDUCE_MAX(T#162, T#2[1]) -> [T#164]\n",
      "  Op#5 DEQUANTIZE(T#164) -> [T#165]\n",
      "  Op#6 DIV(T#163, T#165) -> [T#166]\n",
      "  Op#7 QUANTIZE(T#166) -> [T#167]\n",
      "  Op#8 SHAPE(T#167) -> [T#168]\n",
      "  Op#9 SPLIT_V(T#168, T#3[1, 1, 0], T#4[0]) -> [T#169, T#170, T#171]\n",
      "  Op#10 RESHAPE(T#170, T#5[]) -> [T#172]\n",
      "  Op#11 FLOOR_DIV(T#172, T#6[8]) -> [T#173]\n",
      "  Op#12 PACK(T#173, T#6[8]) -> [T#174]\n",
      "  Op#13 MUL(T#173, T#6[8]) -> [T#175]\n",
      "  Op#14 RESHAPE(T#175, T#7[1]) -> [T#176]\n",
      "  Op#15 CONCATENATION(T#169, T#176) -> [T#177]\n",
      "  Op#16 CONCATENATION(T#169, T#174) -> [T#178]\n",
      "  Op#17 STRIDED_SLICE(T#167, T#8[0, 0], T#177, T#9[1, 1]) -> [T#179]\n",
      "  Op#18 RESHAPE(T#179, T#178) -> [T#180]\n",
      "  Op#19 SUB(T#172, T#10[512]) -> [T#181]\n",
      "  Op#20 FLOOR_DIV(T#181, T#11[280]) -> [T#182]\n",
      "  Op#21 ADD(T#182, T#2[1]) -> [T#183]\n",
      "  Op#22 MAXIMUM(T#183, T#4[0]) -> [T#184]\n",
      "  Op#23 PACK(T#184, T#2[1]) -> [T#185]\n",
      "  Op#24 PACK(T#184, T#10[512]) -> [T#186]\n",
      "  Op#25 CONCATENATION(T#169, T#186) -> [T#187]\n",
      "  Op#26 RANGE(T#4[0], T#184, T#2[1]) -> [T#188]\n",
      "  Op#27 MUL(T#188, T#12[35]) -> [T#189]\n",
      "  Op#28 RESHAPE(T#189, T#185) -> [T#190]\n",
      "  Op#29 ADD(T#190, T#13[0, 1, 2, 3, 4, ...]) -> [T#191]\n",
      "  Op#30 GATHER(T#180, T#191) -> [T#192]\n",
      "  Op#31 RESHAPE(T#192, T#187) -> [T#193]\n",
      "  Op#32 MUL(T#193, T#159) -> [T#194]\n",
      "  Op#33 EXPAND_DIMS(T#194, T#14[-2]) -> [T#195]\n",
      "  Op#34 DEQUANTIZE(T#195) -> [T#196]\n",
      "  Op#35 RFFT2D(T#196, T#15[1, 512]) -> [T#197]\n",
      "  Op#36 SQUEEZE(T#197) -> [T#198]\n",
      "  Op#37 CAST(T#198) -> [T#199]\n",
      "  Op#38 QUANTIZE(T#199) -> [T#200]\n",
      "  Op#39 STRIDED_SLICE(T#200, T#16[0, 0, 0], T#17[0, 0, 128], T#18[1, 1, 1]) -> [T#201]\n",
      "  Op#40 MUL(T#201, T#201) -> [T#202]\n",
      "  Op#41 DEQUANTIZE(T#202) -> [T#203]\n",
      "  Op#42 POW(T#203, T#1) -> [T#204]\n",
      "  Op#43 QUANTIZE(T#204) -> [T#205]\n",
      "  Op#44 TRANSPOSE(T#205, T#19[0, 2, 1]) -> [T#206]\n",
      "  Op#45 EXPAND_DIMS(T#206, T#20[-1]) -> [T#207]\n",
      "  Op#46 MUL(T#207, T#158) -> [T#208]\n",
      "  Op#47 ADD(T#208, T#157) -> [T#209]\n",
      "  Op#48 CONV_2D(T#209, T#156, T#155[-55, 75, -18, 891, 8082, ...]) -> [T#210]\n",
      "  Op#49 AVERAGE_POOL_2D(T#210) -> [T#211]\n",
      "  Op#50 MAX_POOL_2D(T#210) -> [T#212]\n",
      "  Op#51 CONCATENATION(T#212, T#211) -> [T#213]\n",
      "  Op#52 CONV_2D(T#213, T#154, T#153[275, -4, 2965, 181, -427, ...]) -> [T#214]\n",
      "  Op#53 CONV_2D(T#214, T#152, T#151[2453, 3517, 1547, 6589, 3246, ...]) -> [T#215]\n",
      "  Op#54 LOGISTIC(T#215) -> [T#216]\n",
      "  Op#55 MUL(T#215, T#216) -> [T#217]\n",
      "  Op#56 CONV_2D(T#217, T#150, T#149[-781, -295, -1045, -847, 1161, ...]) -> [T#218]\n",
      "  Op#57 CONV_2D(T#218, T#148, T#147[-10989, -6367, 1151, 97, 4097, ...]) -> [T#219]\n",
      "  Op#58 LOGISTIC(T#219) -> [T#220]\n",
      "  Op#59 MUL(T#219, T#220) -> [T#221]\n",
      "  Op#60 CONV_2D(T#221, T#146, T#145[-1369, 2495, -4062, 4174, 1082, ...]) -> [T#222]\n",
      "  Op#61 ADD(T#222, T#218) -> [T#223]\n",
      "  Op#62 CONV_2D(T#223, T#144, T#143[8772, 6210, 8018, -5468, 13215, ...]) -> [T#224]\n",
      "  Op#63 LOGISTIC(T#224) -> [T#225]\n",
      "  Op#64 MUL(T#224, T#225) -> [T#226]\n",
      "  Op#65 CONV_2D(T#226, T#142, T#141[199, -649, -309, 1474, 159, ...]) -> [T#227]\n",
      "  Op#66 ADD(T#227, T#223) -> [T#228]\n",
      "  Op#67 CONV_2D(T#228, T#140, T#139[8282, 10877, 12668, 9228, 12346, ...]) -> [T#229]\n",
      "  Op#68 LOGISTIC(T#229) -> [T#230]\n",
      "  Op#69 MUL(T#229, T#230) -> [T#231]\n",
      "  Op#70 CONV_2D(T#231, T#138, T#137[1883, 3889, -2416, -1082, -428, ...]) -> [T#232]\n",
      "  Op#71 CONV_2D(T#232, T#136, T#135[-5752, 369, 561, -15249, 15195, ...]) -> [T#233]\n",
      "  Op#72 LOGISTIC(T#233) -> [T#234]\n",
      "  Op#73 MUL(T#233, T#234) -> [T#235]\n",
      "  Op#74 CONV_2D(T#235, T#134, T#133[-1505, 818, 581, -1272, 498, ...]) -> [T#236]\n",
      "  Op#75 ADD(T#236, T#232) -> [T#237]\n",
      "  Op#76 CONV_2D(T#237, T#132, T#131[-4326, -11401, -41, -4785, 5131, ...]) -> [T#238]\n",
      "  Op#77 LOGISTIC(T#238) -> [T#239]\n",
      "  Op#78 MUL(T#238, T#239) -> [T#240]\n",
      "  Op#79 CONV_2D(T#240, T#130, T#129[-1001, 1296, 1778, 2259, 1189, ...]) -> [T#241]\n",
      "  Op#80 ADD(T#241, T#237) -> [T#242]\n",
      "  Op#81 CONV_2D(T#242, T#128, T#127[-513, -5281, -1122, 618, -3274, ...]) -> [T#243]\n",
      "  Op#82 LOGISTIC(T#243) -> [T#244]\n",
      "  Op#83 MUL(T#243, T#244) -> [T#245]\n",
      "  Op#84 CONV_2D(T#245, T#126, T#125[-3746, -3267, 1806, -1352, 1685, ...]) -> [T#246]\n",
      "  Op#85 ADD(T#246, T#242) -> [T#247]\n",
      "  Op#86 CONV_2D(T#247, T#124, T#123[2545, -3452, 853, 458, -2576, ...]) -> [T#248]\n",
      "  Op#87 LOGISTIC(T#248) -> [T#249]\n",
      "  Op#88 MUL(T#248, T#249) -> [T#250]\n",
      "  Op#89 DEPTHWISE_CONV_2D(T#250, T#122, T#121[1008, 356, 152, 337, 680, ...]) -> [T#251]\n",
      "  Op#90 LOGISTIC(T#251) -> [T#252]\n",
      "  Op#91 MUL(T#251, T#252) -> [T#253]\n",
      "  Op#92 MEAN(T#253, T#21[1, 2]) -> [T#254]\n",
      "  Op#93 SHAPE(T#254) -> [T#255]\n",
      "  Op#94 STRIDED_SLICE(T#255, T#22[0], T#7[1], T#7[1]) -> [T#256]\n",
      "  Op#95 PACK(T#256, T#2[1], T#2[1], T#23[640]) -> [T#257]\n",
      "  Op#96 RESHAPE(T#254, T#257) -> [T#258]\n",
      "  Op#97 CONV_2D(T#258, T#120, T#115[0, 0, 0, 0, 0, ...]) -> [T#259]\n",
      "  Op#98 LOGISTIC(T#259) -> [T#260]\n",
      "  Op#99 MUL(T#259, T#260) -> [T#261]\n",
      "  Op#100 CONV_2D(T#261, T#114, T#109[0, 0, 0, 0, 0, ...]) -> [T#262]\n",
      "  Op#101 LOGISTIC(T#262) -> [T#263]\n",
      "  Op#102 MUL(T#253, T#263) -> [T#264]\n",
      "  Op#103 CONV_2D(T#264, T#108, T#107[143, -1218, -1383, -2425, -137, ...]) -> [T#265]\n",
      "  Op#104 CONV_2D(T#265, T#106, T#105[-3734, 567, 2314, -1060, -395, ...]) -> [T#266]\n",
      "  Op#105 LOGISTIC(T#266) -> [T#267]\n",
      "  Op#106 MUL(T#266, T#267) -> [T#268]\n",
      "  Op#107 DEPTHWISE_CONV_2D(T#268, T#104, T#103[42, 115, -223, 753, -878, ...]) -> [T#269]\n",
      "  Op#108 LOGISTIC(T#269) -> [T#270]\n",
      "  Op#109 MUL(T#269, T#270) -> [T#271]\n",
      "  Op#110 MEAN(T#271, T#21[1, 2]) -> [T#272]\n",
      "  Op#111 SHAPE(T#272) -> [T#273]\n",
      "  Op#112 STRIDED_SLICE(T#273, T#22[0], T#7[1], T#7[1]) -> [T#274]\n",
      "  Op#113 PACK(T#274, T#2[1], T#2[1], T#23[640]) -> [T#275]\n",
      "  Op#114 RESHAPE(T#272, T#275) -> [T#276]\n",
      "  Op#115 CONV_2D(T#276, T#102, T#116[0, 0, 0, 0, 0, ...]) -> [T#277]\n",
      "  Op#116 LOGISTIC(T#277) -> [T#278]\n",
      "  Op#117 MUL(T#277, T#278) -> [T#279]\n",
      "  Op#118 CONV_2D(T#279, T#101, T#110[0, 0, 0, 0, 0, ...]) -> [T#280]\n",
      "  Op#119 LOGISTIC(T#280) -> [T#281]\n",
      "  Op#120 MUL(T#271, T#281) -> [T#282]\n",
      "  Op#121 CONV_2D(T#282, T#100, T#99[-1062, -33, -187, 607, -355, ...]) -> [T#283]\n",
      "  Op#122 ADD(T#283, T#265) -> [T#284]\n",
      "  Op#123 CONV_2D(T#284, T#98, T#97[4655, 2423, -3284, 1506, -524, ...]) -> [T#285]\n",
      "  Op#124 LOGISTIC(T#285) -> [T#286]\n",
      "  Op#125 MUL(T#285, T#286) -> [T#287]\n",
      "  Op#126 DEPTHWISE_CONV_2D(T#287, T#96, T#95[-91, -344, -158, -793, -165, ...]) -> [T#288]\n",
      "  Op#127 LOGISTIC(T#288) -> [T#289]\n",
      "  Op#128 MUL(T#288, T#289) -> [T#290]\n",
      "  Op#129 MEAN(T#290, T#21[1, 2]) -> [T#291]\n",
      "  Op#130 SHAPE(T#291) -> [T#292]\n",
      "  Op#131 STRIDED_SLICE(T#292, T#22[0], T#7[1], T#7[1]) -> [T#293]\n",
      "  Op#132 PACK(T#293, T#2[1], T#2[1], T#23[640]) -> [T#294]\n",
      "  Op#133 RESHAPE(T#291, T#294) -> [T#295]\n",
      "  Op#134 CONV_2D(T#295, T#94, T#117[0, 0, 0, 0, 0, ...]) -> [T#296]\n",
      "  Op#135 LOGISTIC(T#296) -> [T#297]\n",
      "  Op#136 MUL(T#296, T#297) -> [T#298]\n",
      "  Op#137 CONV_2D(T#298, T#93, T#111[0, 0, 0, 0, 0, ...]) -> [T#299]\n",
      "  Op#138 LOGISTIC(T#299) -> [T#300]\n",
      "  Op#139 MUL(T#290, T#300) -> [T#301]\n",
      "  Op#140 CONV_2D(T#301, T#92, T#91[34, -55, -908, 1036, -2091, ...]) -> [T#302]\n",
      "  Op#141 ADD(T#302, T#284) -> [T#303]\n",
      "  Op#142 CONV_2D(T#303, T#90, T#89[-1114, 6749, -720, 913, 404, ...]) -> [T#304]\n",
      "  Op#143 LOGISTIC(T#304) -> [T#305]\n",
      "  Op#144 MUL(T#304, T#305) -> [T#306]\n",
      "  Op#145 DEPTHWISE_CONV_2D(T#306, T#88, T#87[-270, -918, -151, -169, -128, ...]) -> [T#307]\n",
      "  Op#146 LOGISTIC(T#307) -> [T#308]\n",
      "  Op#147 MUL(T#307, T#308) -> [T#309]\n",
      "  Op#148 MEAN(T#309, T#21[1, 2]) -> [T#310]\n",
      "  Op#149 SHAPE(T#310) -> [T#311]\n",
      "  Op#150 STRIDED_SLICE(T#311, T#22[0], T#7[1], T#7[1]) -> [T#312]\n",
      "  Op#151 PACK(T#312, T#2[1], T#2[1], T#23[640]) -> [T#313]\n",
      "  Op#152 RESHAPE(T#310, T#313) -> [T#314]\n",
      "  Op#153 CONV_2D(T#314, T#86, T#118[0, 0, 0, 0, 0, ...]) -> [T#315]\n",
      "  Op#154 LOGISTIC(T#315) -> [T#316]\n",
      "  Op#155 MUL(T#315, T#316) -> [T#317]\n",
      "  Op#156 CONV_2D(T#317, T#85, T#112[0, 0, 0, 0, 0, ...]) -> [T#318]\n",
      "  Op#157 LOGISTIC(T#318) -> [T#319]\n",
      "  Op#158 MUL(T#309, T#319) -> [T#320]\n",
      "  Op#159 CONV_2D(T#320, T#84, T#83[69, -1130, -439, 763, 277, ...]) -> [T#321]\n",
      "  Op#160 ADD(T#321, T#303) -> [T#322]\n",
      "  Op#161 CONV_2D(T#322, T#82, T#81[-5406, 197, -2336, -5583, -2612, ...]) -> [T#323]\n",
      "  Op#162 LOGISTIC(T#323) -> [T#324]\n",
      "  Op#163 MUL(T#323, T#324) -> [T#325]\n",
      "  Op#164 DEPTHWISE_CONV_2D(T#325, T#80, T#79[311, -805, -9, -90, -70, ...]) -> [T#326]\n",
      "  Op#165 LOGISTIC(T#326) -> [T#327]\n",
      "  Op#166 MUL(T#326, T#327) -> [T#328]\n",
      "  Op#167 MEAN(T#328, T#21[1, 2]) -> [T#329]\n",
      "  Op#168 SHAPE(T#329) -> [T#330]\n",
      "  Op#169 STRIDED_SLICE(T#330, T#22[0], T#7[1], T#7[1]) -> [T#331]\n",
      "  Op#170 PACK(T#331, T#2[1], T#2[1], T#23[640]) -> [T#332]\n",
      "  Op#171 RESHAPE(T#329, T#332) -> [T#333]\n",
      "  Op#172 CONV_2D(T#333, T#78, T#119[0, 0, 0, 0, 0, ...]) -> [T#334]\n",
      "  Op#173 LOGISTIC(T#334) -> [T#335]\n",
      "  Op#174 MUL(T#334, T#335) -> [T#336]\n",
      "  Op#175 CONV_2D(T#336, T#77, T#113[0, 0, 0, 0, 0, ...]) -> [T#337]\n",
      "  Op#176 LOGISTIC(T#337) -> [T#338]\n",
      "  Op#177 MUL(T#328, T#338) -> [T#339]\n",
      "  Op#178 CONV_2D(T#339, T#76, T#75[-98, -241, -311, 12, -71, ...]) -> [T#340]\n",
      "  Op#179 ADD(T#340, T#322) -> [T#341]\n",
      "  Op#180 CONV_2D(T#341, T#74, T#73[-1839, -5524, -6139, -4054, -1489, ...]) -> [T#342]\n",
      "  Op#181 LOGISTIC(T#342) -> [T#343]\n",
      "  Op#182 MUL(T#342, T#343) -> [T#344]\n",
      "  Op#183 DEPTHWISE_CONV_2D(T#344, T#72, T#71[-165, 89, 177, 205, -114, ...]) -> [T#345]\n",
      "  Op#184 LOGISTIC(T#345) -> [T#346]\n",
      "  Op#185 MUL(T#345, T#346) -> [T#347]\n",
      "  Op#186 MEAN(T#347, T#21[1, 2]) -> [T#348]\n",
      "  Op#187 SHAPE(T#348) -> [T#349]\n",
      "  Op#188 STRIDED_SLICE(T#349, T#22[0], T#7[1], T#7[1]) -> [T#350]\n",
      "  Op#189 PACK(T#350, T#2[1], T#2[1], T#24[1120]) -> [T#351]\n",
      "  Op#190 RESHAPE(T#348, T#351) -> [T#352]\n",
      "  Op#191 CONV_2D(T#352, T#70, T#66[0, 0, 0, 0, 0, ...]) -> [T#353]\n",
      "  Op#192 LOGISTIC(T#353) -> [T#354]\n",
      "  Op#193 MUL(T#353, T#354) -> [T#355]\n",
      "  Op#194 CONV_2D(T#355, T#65, T#61[0, 0, 0, 0, 0, ...]) -> [T#356]\n",
      "  Op#195 LOGISTIC(T#356) -> [T#357]\n",
      "  Op#196 MUL(T#347, T#357) -> [T#358]\n",
      "  Op#197 CONV_2D(T#358, T#60, T#59[39, -702, -1646, -308, 672, ...]) -> [T#359]\n",
      "  Op#198 CONV_2D(T#359, T#58, T#57[1644, 720, 1586, -2405, -4185, ...]) -> [T#360]\n",
      "  Op#199 LOGISTIC(T#360) -> [T#361]\n",
      "  Op#200 MUL(T#360, T#361) -> [T#362]\n",
      "  Op#201 DEPTHWISE_CONV_2D(T#362, T#56, T#55[5, -253, -33, -153, 3, ...]) -> [T#363]\n",
      "  Op#202 LOGISTIC(T#363) -> [T#364]\n",
      "  Op#203 MUL(T#363, T#364) -> [T#365]\n",
      "  Op#204 MEAN(T#365, T#21[1, 2]) -> [T#366]\n",
      "  Op#205 SHAPE(T#366) -> [T#367]\n",
      "  Op#206 STRIDED_SLICE(T#367, T#22[0], T#7[1], T#7[1]) -> [T#368]\n",
      "  Op#207 PACK(T#368, T#2[1], T#2[1], T#24[1120]) -> [T#369]\n",
      "  Op#208 RESHAPE(T#366, T#369) -> [T#370]\n",
      "  Op#209 CONV_2D(T#370, T#54, T#67[0, 0, 0, 0, 0, ...]) -> [T#371]\n",
      "  Op#210 LOGISTIC(T#371) -> [T#372]\n",
      "  Op#211 MUL(T#371, T#372) -> [T#373]\n",
      "  Op#212 CONV_2D(T#373, T#53, T#62[0, 0, 0, 0, 0, ...]) -> [T#374]\n",
      "  Op#213 LOGISTIC(T#374) -> [T#375]\n",
      "  Op#214 MUL(T#365, T#375) -> [T#376]\n",
      "  Op#215 CONV_2D(T#376, T#52, T#51[-324, -191, -190, -888, -258, ...]) -> [T#377]\n",
      "  Op#216 ADD(T#377, T#359) -> [T#378]\n",
      "  Op#217 CONV_2D(T#378, T#50, T#49[-1565, -10740, -3357, 1761, -4880, ...]) -> [T#379]\n",
      "  Op#218 LOGISTIC(T#379) -> [T#380]\n",
      "  Op#219 MUL(T#379, T#380) -> [T#381]\n",
      "  Op#220 DEPTHWISE_CONV_2D(T#381, T#48, T#47[178, -70, -12, -347, 288, ...]) -> [T#382]\n",
      "  Op#221 LOGISTIC(T#382) -> [T#383]\n",
      "  Op#222 MUL(T#382, T#383) -> [T#384]\n",
      "  Op#223 MEAN(T#384, T#21[1, 2]) -> [T#385]\n",
      "  Op#224 SHAPE(T#385) -> [T#386]\n",
      "  Op#225 STRIDED_SLICE(T#386, T#22[0], T#7[1], T#7[1]) -> [T#387]\n",
      "  Op#226 PACK(T#387, T#2[1], T#2[1], T#24[1120]) -> [T#388]\n",
      "  Op#227 RESHAPE(T#385, T#388) -> [T#389]\n",
      "  Op#228 CONV_2D(T#389, T#46, T#68[0, 0, 0, 0, 0, ...]) -> [T#390]\n",
      "  Op#229 LOGISTIC(T#390) -> [T#391]\n",
      "  Op#230 MUL(T#390, T#391) -> [T#392]\n",
      "  Op#231 CONV_2D(T#392, T#45, T#63[0, 0, 0, 0, 0, ...]) -> [T#393]\n",
      "  Op#232 LOGISTIC(T#393) -> [T#394]\n",
      "  Op#233 MUL(T#384, T#394) -> [T#395]\n",
      "  Op#234 CONV_2D(T#395, T#44, T#43[588, -1013, -951, -1262, -950, ...]) -> [T#396]\n",
      "  Op#235 ADD(T#396, T#378) -> [T#397]\n",
      "  Op#236 CONV_2D(T#397, T#42, T#41[-12374, -473, -11934, -3582, -7241, ...]) -> [T#398]\n",
      "  Op#237 LOGISTIC(T#398) -> [T#399]\n",
      "  Op#238 MUL(T#398, T#399) -> [T#400]\n",
      "  Op#239 DEPTHWISE_CONV_2D(T#400, T#40, T#39[124, -828, 310, -577, -310, ...]) -> [T#401]\n",
      "  Op#240 LOGISTIC(T#401) -> [T#402]\n",
      "  Op#241 MUL(T#401, T#402) -> [T#403]\n",
      "  Op#242 MEAN(T#403, T#21[1, 2]) -> [T#404]\n",
      "  Op#243 SHAPE(T#404) -> [T#405]\n",
      "  Op#244 STRIDED_SLICE(T#405, T#22[0], T#7[1], T#7[1]) -> [T#406]\n",
      "  Op#245 PACK(T#406, T#2[1], T#2[1], T#24[1120]) -> [T#407]\n",
      "  Op#246 RESHAPE(T#404, T#407) -> [T#408]\n",
      "  Op#247 CONV_2D(T#408, T#38, T#69[0, 0, 0, 0, 0, ...]) -> [T#409]\n",
      "  Op#248 LOGISTIC(T#409) -> [T#410]\n",
      "  Op#249 MUL(T#409, T#410) -> [T#411]\n",
      "  Op#250 CONV_2D(T#411, T#37, T#64[0, 0, 0, 0, 0, ...]) -> [T#412]\n",
      "  Op#251 LOGISTIC(T#412) -> [T#413]\n",
      "  Op#252 MUL(T#403, T#413) -> [T#414]\n",
      "  Op#253 CONV_2D(T#414, T#36, T#35[-3370, -8876, -1541, -3646, -3722, ...]) -> [T#415]\n",
      "  Op#254 ADD(T#415, T#397) -> [T#416]\n",
      "  Op#255 MUL(T#416, T#34) -> [T#417]\n",
      "  Op#256 ADD(T#417, T#33) -> [T#418]\n",
      "  Op#257 CONV_2D(T#418, T#32, T#31[37795, 6349, 44074, 53959, -4670, ...]) -> [T#419]\n",
      "  Op#258 REDUCE_MAX(T#419, T#21[1, 2]) -> [T#420]\n",
      "  Op#259 REDUCE_MAX(T#419, T#21[1, 2]) -> [T#421]\n",
      "  Op#260 SUB(T#419, T#420) -> [T#422]\n",
      "  Op#261 MUL(T#422, T#30) -> [T#423]\n",
      "  Op#262 EXP(T#423) -> [T#424]\n",
      "  Op#263 MEAN(T#424, T#21[1, 2]) -> [T#425]\n",
      "  Op#264 DEQUANTIZE(T#425) -> [T#426]\n",
      "  Op#265 LOG(T#426) -> [T#427]\n",
      "  Op#266 QUANTIZE(T#427) -> [T#428]\n",
      "  Op#267 MUL(T#428, T#29) -> [T#429]\n",
      "  Op#268 ADD(T#429, T#421) -> [T#430]\n",
      "  Op#269 FULLY_CONNECTED(T#430, T#28, T#27[1169, -74, -370]) -> [T#431]\n",
      "  Op#270 FULLY_CONNECTED(T#431, T#26, T#25[-102, -286]) -> [T#432]\n",
      "  Op#271 LOGISTIC(T#432) -> [T#433]\n",
      "  Op#272 DEQUANTIZE(T#433) -> [T#434]\n",
      "\n",
      "Tensors of Subgraph#0\n",
      "  T#0(serving_default_INPUT:0) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#1(truediv_1;truediv_1) shape:[], type:FLOAT32 RO 4 bytes, buffer: 2, data:[0.262867]\n",
      "  T#2(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape/1) shape:[], type:INT32 RO 4 bytes, buffer: 3, data:[1]\n",
      "  T#3(stft/frame/packed;stft/frame/packed) shape:[3], type:INT32 RO 12 bytes, buffer: 4, data:[1, 1, 0]\n",
      "  T#4(stft/frame/Maximum/x;stft/frame/Maximum/x) shape:[], type:INT32 RO 4 bytes, buffer: 5, data:[0]\n",
      "  T#5(stft/frame/Reshape/shape_1;stft/frame/Reshape/shape_1) shape:[0], type:INT32\n",
      "  T#6(stft/frame/concat_1/values_1/1;stft/frame/concat_1/values_1/1) shape:[], type:INT32 RO 4 bytes, buffer: 7, data:[8]\n",
      "  T#7(model/BLOCK_3-1_SE_RESHAPE/strided_slice/stack_1) shape:[1], type:INT32 RO 4 bytes, buffer: 3, data:[1]\n",
      "  T#8(stft/frame/zeros_like;stft/frame/zeros_like) shape:[2], type:INT32 RO 8 bytes, buffer: 9, data:[0, 0]\n",
      "  T#9(stft/frame/ones_like;stft/frame/ones_like) shape:[2], type:INT32 RO 8 bytes, buffer: 10, data:[1, 1]\n",
      "  T#10(stft/frame_length;stft/frame_length) shape:[], type:INT32 RO 4 bytes, buffer: 11, data:[512]\n",
      "  T#11(stft/frame_step;stft/frame_step) shape:[], type:INT32 RO 4 bytes, buffer: 12, data:[280]\n",
      "  T#12(stft/frame/floordiv_2;stft/frame/floordiv_2) shape:[], type:INT32 RO 4 bytes, buffer: 13, data:[35]\n",
      "  T#13(stft/frame/Reshape_3;stft/frame/Reshape_3) shape:[1, 64], type:INT32 RO 256 bytes, buffer: 14, data:[0, 1, 2, 3, 4, ...]\n",
      "  T#14(stft/rfft;stft/rfft) shape:[], type:INT32 RO 4 bytes, buffer: 15, data:[-2]\n",
      "  T#15(stft/rfft;stft/rfft1) shape:[2], type:INT32 RO 8 bytes, buffer: 16, data:[1, 512]\n",
      "  T#16(strided_slice/stack;strided_slice/stack) shape:[3], type:INT32 RO 12 bytes, buffer: 17, data:[0, 0, 0]\n",
      "  T#17(strided_slice/stack_1;strided_slice/stack_1) shape:[3], type:INT32 RO 12 bytes, buffer: 18, data:[0, 0, 128]\n",
      "  T#18(strided_slice/stack_2;strided_slice/stack_2) shape:[3], type:INT32 RO 12 bytes, buffer: 19, data:[1, 1, 1]\n",
      "  T#19(transpose/perm;transpose/perm) shape:[3], type:INT32 RO 12 bytes, buffer: 20, data:[0, 2, 1]\n",
      "  T#20(ExpandDims/dim;ExpandDims/dim) shape:[], type:INT32 RO 4 bytes, buffer: 21, data:[-1]\n",
      "  T#21(model/BLOCK_3-1_SE_AVG_POOL_1/Mean/reduction_indices) shape:[2], type:INT32 RO 8 bytes, buffer: 22, data:[1, 2]\n",
      "  T#22(model/BLOCK_3-1_SE_RESHAPE/strided_slice/stack) shape:[1], type:INT32 RO 4 bytes, buffer: 5, data:[0]\n",
      "  T#23(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 24, data:[640]\n",
      "  T#24(model/BLOCK_4-1_SE_RESHAPE/Reshape/shape/3) shape:[], type:INT32 RO 4 bytes, buffer: 25, data:[1120]\n",
      "  T#25(model/dense_1/BiasAdd/ReadVariableOp) shape:[2], type:INT32 RO 8 bytes, buffer: 26, data:[-102, -286]\n",
      "  T#26(model/dense_1/MatMul) shape:[2, 3], type:INT8 RO 6 bytes, buffer: 27, data:[G, ., ., ., l, ...]\n",
      "  T#27(model/dense/BiasAdd/ReadVariableOp) shape:[3], type:INT32 RO 12 bytes, buffer: 28, data:[1169, -74, -370]\n",
      "  T#28(model/dense/MatMul) shape:[3, 420], type:INT8 RO 1260 bytes, buffer: 29, data:[., ., H, 6, ., ...]\n",
      "  T#29(truediv;truediv;ReadVariableOp;ReadVariableOp) shape:[1], type:INT8 RO 1 bytes, buffer: 30, data:[.]\n",
      "  T#30(ReadVariableOp;ReadVariableOp) shape:[1], type:INT8 RO 1 bytes, buffer: 30, data:[.]\n",
      "  T#31(model/POST_BN_1/FusedBatchNormV3) shape:[420], type:INT32 RO 1680 bytes, buffer: 32, data:[37795, 6349, 44074, 53959, -4670, ...]\n",
      "  T#32(model/POST_CONV_1/Conv2D) shape:[420, 3, 3, 280], type:INT8 RO 1058400 bytes, buffer: 33, data:[., ., 0, 8, 7, ...]\n",
      "  T#33(model/BNORM_POST_NOQUANT/FusedBatchNormV31) shape:[280], type:INT8 RO 280 bytes, buffer: 34, data:[., ., ., ., ., ...]\n",
      "  T#34(model/BNORM_POST_NOQUANT/FusedBatchNormV3) shape:[280], type:INT8 RO 280 bytes, buffer: 35, data:[., ., ., ., ., ...]\n",
      "  T#35(model/BLOCK_4-4_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 36, data:[-3370, -8876, -1541, -3646, -3722, ...]\n",
      "  T#36(model/BLOCK_4-4_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 37, data:[., ., \n",
      ", ., ., ...]\n",
      "  T#37(model/BLOCK_4-4_SE_CONV_2/Conv2D1) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 38, data:[., ., ., ., ., ...]\n",
      "  T#38(model/BLOCK_4-4_SE_CONV_1/Conv2D1) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 39, data:[., ., ., ., ., ...]\n",
      "  T#39(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 40, data:[124, -828, 310, -577, -310, ...]\n",
      "  T#40(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 41, data:[., ., ., ., ., ...]\n",
      "  T#41(model/BLOCK_4-4_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 42, data:[-12374, -473, -11934, -3582, -7241, ...]\n",
      "  T#42(model/BLOCK_4-4_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:INT8 RO 313600 bytes, buffer: 43, data:[X, ., ., ., ., ...]\n",
      "  T#43(model/BLOCK_4-3_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 44, data:[588, -1013, -951, -1262, -950, ...]\n",
      "  T#44(model/BLOCK_4-3_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 45, data:[., ., ., \n",
      ", ., ...]\n",
      "  T#45(model/BLOCK_4-3_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 46, data:[F, ., ., ., ., ...]\n",
      "  T#46(model/BLOCK_4-3_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 47, data:[., ., ., ., ., ...]\n",
      "  T#47(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 48, data:[178, -70, -12, -347, 288, ...]\n",
      "  T#48(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-3_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 49, data:[., +, ., E, 5, ...]\n",
      "  T#49(model/BLOCK_4-3_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 50, data:[-1565, -10740, -3357, 1761, -4880, ...]\n",
      "  T#50(model/BLOCK_4-3_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:INT8 RO 313600 bytes, buffer: 51, data:[(, ., ., B, ., ...]\n",
      "  T#51(model/BLOCK_4-2_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 52, data:[-324, -191, -190, -888, -258, ...]\n",
      "  T#52(model/BLOCK_4-2_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 53, data:[., ., \n",
      ", ., !, ...]\n",
      "  T#53(model/BLOCK_4-2_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 54, data:[., ., ., <, Q, ...]\n",
      "  T#54(model/BLOCK_4-2_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 55, data:[., ., ., ,, ., ...]\n",
      "  T#55(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 56, data:[5, -253, -33, -153, 3, ...]\n",
      "  T#56(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-2_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 57, data:[., ., ., ., ., ...]\n",
      "  T#57(model/BLOCK_4-2_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 58, data:[1644, 720, 1586, -2405, -4185, ...]\n",
      "  T#58(model/BLOCK_4-2_CONV_1/Conv2D) shape:[1120, 1, 1, 280], type:INT8 RO 313600 bytes, buffer: 59, data:[/, ., /, ., ., ...]\n",
      "  T#59(model/BLOCK_4-1_BN_3/FusedBatchNormV3) shape:[280], type:INT32 RO 1120 bytes, buffer: 60, data:[39, -702, -1646, -308, 672, ...]\n",
      "  T#60(model/BLOCK_4-1_CONV_3/Conv2D) shape:[280, 1, 1, 1120], type:INT8 RO 313600 bytes, buffer: 61, data:[;, ., ., ., ., ...]\n",
      "  T#61(model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1120], type:INT32 RO 4480 bytes, buffer: 62, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#62(model/BLOCK_4-4_SE_CONV_2/Conv2D2) shape:[1120], type:INT32 RO 4480 bytes, buffer: 62, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#63(model/BLOCK_4-4_SE_CONV_2/Conv2D3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 62, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#64(model/BLOCK_4-4_SE_CONV_2/Conv2D4) shape:[1120], type:INT32 RO 4480 bytes, buffer: 62, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#65(model/BLOCK_4-1_SE_CONV_2/Conv2D) shape:[1120, 1, 1, 70], type:INT8 RO 78400 bytes, buffer: 66, data:[., ., ., ., ., ...]\n",
      "  T#66(model/BLOCK_4-4_SE_CONV_1/Conv2D) shape:[70], type:INT32 RO 280 bytes, buffer: 67, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#67(model/BLOCK_4-4_SE_CONV_1/Conv2D2) shape:[70], type:INT32 RO 280 bytes, buffer: 67, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#68(model/BLOCK_4-4_SE_CONV_1/Conv2D3) shape:[70], type:INT32 RO 280 bytes, buffer: 67, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#69(model/BLOCK_4-4_SE_CONV_1/Conv2D4) shape:[70], type:INT32 RO 280 bytes, buffer: 67, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#70(model/BLOCK_4-1_SE_CONV_1/Conv2D) shape:[70, 1, 1, 1120], type:INT8 RO 78400 bytes, buffer: 71, data:[., ., ., ., ., ...]\n",
      "  T#71(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 72, data:[-165, 89, 177, 205, -114, ...]\n",
      "  T#72(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-1_CONV_2/depthwise;model/BLOCK_4-4_SE_CONV_2/Conv2D) shape:[1, 3, 3, 1120], type:INT8 RO 10080 bytes, buffer: 73, data:[., ., i, ., ., ...]\n",
      "  T#73(model/BLOCK_4-1_BN_1/FusedBatchNormV3) shape:[1120], type:INT32 RO 4480 bytes, buffer: 74, data:[-1839, -5524, -6139, -4054, -1489, ...]\n",
      "  T#74(model/BLOCK_4-1_CONV_1/Conv2D) shape:[1120, 1, 1, 160], type:INT8 RO 179200 bytes, buffer: 75, data:[., #, a, ., ., ...]\n",
      "  T#75(model/BLOCK_3-5_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 76, data:[-98, -241, -311, 12, -71, ...]\n",
      "  T#76(model/BLOCK_3-5_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 77, data:[., ., ., ., ., ...]\n",
      "  T#77(model/BLOCK_3-5_SE_CONV_2/Conv2D1) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 78, data:[., !, ., ., ., ...]\n",
      "  T#78(model/BLOCK_3-5_SE_CONV_1/Conv2D1) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 79, data:[', ., ., ., ., ...]\n",
      "  T#79(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 80, data:[311, -805, -9, -90, -70, ...]\n",
      "  T#80(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 81, data:[7, ., ., ., N, ...]\n",
      "  T#81(model/BLOCK_3-5_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 82, data:[-5406, 197, -2336, -5583, -2612, ...]\n",
      "  T#82(model/BLOCK_3-5_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 83, data:[., ., ., ., ., ...]\n",
      "  T#83(model/BLOCK_3-4_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 84, data:[69, -1130, -439, 763, 277, ...]\n",
      "  T#84(model/BLOCK_3-4_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 85, data:[., ., ., ., ., ...]\n",
      "  T#85(model/BLOCK_3-4_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 86, data:[., <, ., ., &, ...]\n",
      "  T#86(model/BLOCK_3-4_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 87, data:[., ., ., ., ., ...]\n",
      "  T#87(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 88, data:[-270, -918, -151, -169, -128, ...]\n",
      "  T#88(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-4_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 89, data:[., ., ., ., ., ...]\n",
      "  T#89(model/BLOCK_3-4_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 90, data:[-1114, 6749, -720, 913, 404, ...]\n",
      "  T#90(model/BLOCK_3-4_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 91, data:[., ., ., ., ., ...]\n",
      "  T#91(model/BLOCK_3-3_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 92, data:[34, -55, -908, 1036, -2091, ...]\n",
      "  T#92(model/BLOCK_3-3_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 93, data:[5, ., ., ., ., ...]\n",
      "  T#93(model/BLOCK_3-3_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 94, data:[., ., ., ., ., ...]\n",
      "  T#94(model/BLOCK_3-3_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 95, data:[., ., ., ., \n",
      ", ...]\n",
      "  T#95(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 96, data:[-91, -344, -158, -793, -165, ...]\n",
      "  T#96(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-3_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 97, data:[., ., ., ., ., ...]\n",
      "  T#97(model/BLOCK_3-3_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 98, data:[4655, 2423, -3284, 1506, -524, ...]\n",
      "  T#98(model/BLOCK_3-3_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 99, data:[., ., ., ., ., ...]\n",
      "  T#99(model/BLOCK_3-2_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 100, data:[-1062, -33, -187, 607, -355, ...]\n",
      "  T#100(model/BLOCK_3-2_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 101, data:[., ., \", &, ., ...]\n",
      "  T#101(model/BLOCK_3-2_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 102, data:[., ., ., ., ., ...]\n",
      "  T#102(model/BLOCK_3-2_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 103, data:[\", ., 1, ., -, ...]\n",
      "  T#103(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 104, data:[42, 115, -223, 753, -878, ...]\n",
      "  T#104(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-2_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 105, data:[#, ., ., ., ., ...]\n",
      "  T#105(model/BLOCK_3-2_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 106, data:[-3734, 567, 2314, -1060, -395, ...]\n",
      "  T#106(model/BLOCK_3-2_CONV_1/Conv2D) shape:[640, 1, 1, 160], type:INT8 RO 102400 bytes, buffer: 107, data:[>, ., ., ., ., ...]\n",
      "  T#107(model/BLOCK_3-1_BN_3/FusedBatchNormV3) shape:[160], type:INT32 RO 640 bytes, buffer: 108, data:[143, -1218, -1383, -2425, -137, ...]\n",
      "  T#108(model/BLOCK_3-1_CONV_3/Conv2D) shape:[160, 1, 1, 640], type:INT8 RO 102400 bytes, buffer: 109, data:[/, ., ., ., (, ...]\n",
      "  T#109(model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[640], type:INT32 RO 2560 bytes, buffer: 110, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#110(model/BLOCK_3-5_SE_CONV_2/Conv2D2) shape:[640], type:INT32 RO 2560 bytes, buffer: 110, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#111(model/BLOCK_3-5_SE_CONV_2/Conv2D3) shape:[640], type:INT32 RO 2560 bytes, buffer: 110, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#112(model/BLOCK_3-5_SE_CONV_2/Conv2D4) shape:[640], type:INT32 RO 2560 bytes, buffer: 110, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#113(model/BLOCK_3-5_SE_CONV_2/Conv2D5) shape:[640], type:INT32 RO 2560 bytes, buffer: 110, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#114(model/BLOCK_3-1_SE_CONV_2/Conv2D) shape:[640, 1, 1, 40], type:INT8 RO 25600 bytes, buffer: 115, data:[G, s, >, ., ., ...]\n",
      "  T#115(model/BLOCK_3-5_SE_CONV_1/Conv2D) shape:[40], type:INT32 RO 160 bytes, buffer: 116, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#116(model/BLOCK_3-5_SE_CONV_1/Conv2D2) shape:[40], type:INT32 RO 160 bytes, buffer: 116, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#117(model/BLOCK_3-5_SE_CONV_1/Conv2D3) shape:[40], type:INT32 RO 160 bytes, buffer: 116, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#118(model/BLOCK_3-5_SE_CONV_1/Conv2D4) shape:[40], type:INT32 RO 160 bytes, buffer: 116, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#119(model/BLOCK_3-5_SE_CONV_1/Conv2D5) shape:[40], type:INT32 RO 160 bytes, buffer: 116, data:[0, 0, 0, 0, 0, ...]\n",
      "  T#120(model/BLOCK_3-1_SE_CONV_1/Conv2D) shape:[40, 1, 1, 640], type:INT8 RO 25600 bytes, buffer: 121, data:[., .,  , ., ., ...]\n",
      "  T#121(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 122, data:[1008, 356, 152, 337, 680, ...]\n",
      "  T#122(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-1_CONV_2/depthwise;model/BLOCK_3-5_SE_CONV_2/Conv2D) shape:[1, 3, 3, 640], type:INT8 RO 5760 bytes, buffer: 123, data:[., d, ., ., J, ...]\n",
      "  T#123(model/BLOCK_3-1_BN_1/FusedBatchNormV3) shape:[640], type:INT32 RO 2560 bytes, buffer: 124, data:[2545, -3452, 853, 458, -2576, ...]\n",
      "  T#124(model/BLOCK_3-1_CONV_1/Conv2D) shape:[640, 1, 1, 120], type:INT8 RO 76800 bytes, buffer: 125, data:[;, ., O, ?, v, ...]\n",
      "  T#125(model/BLOCK_2-4_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 126, data:[-3746, -3267, 1806, -1352, 1685, ...]\n",
      "  T#126(model/BLOCK_2-4_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 127, data:[I, ., ., ., ., ...]\n",
      "  T#127(model/BLOCK_2-4_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 128, data:[-513, -5281, -1122, 618, -3274, ...]\n",
      "  T#128(model/BLOCK_2-4_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:INT8 RO 259200 bytes, buffer: 129, data:[., ., !, ., ., ...]\n",
      "  T#129(model/BLOCK_2-3_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 130, data:[-1001, 1296, 1778, 2259, 1189, ...]\n",
      "  T#130(model/BLOCK_2-3_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 131, data:[., ., [, ,, J, ...]\n",
      "  T#131(model/BLOCK_2-3_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 132, data:[-4326, -11401, -41, -4785, 5131, ...]\n",
      "  T#132(model/BLOCK_2-3_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:INT8 RO 259200 bytes, buffer: 133, data:[., ., ., ., ., ...]\n",
      "  T#133(model/BLOCK_2-2_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 134, data:[-1505, 818, 581, -1272, 498, ...]\n",
      "  T#134(model/BLOCK_2-2_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 135, data:[., ., ., ., ., ...]\n",
      "  T#135(model/BLOCK_2-2_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 136, data:[-5752, 369, 561, -15249, 15195, ...]\n",
      "  T#136(model/BLOCK_2-2_CONV_1/Conv2D) shape:[240, 3, 3, 120], type:INT8 RO 259200 bytes, buffer: 137, data:[., ., ', ., ., ...]\n",
      "  T#137(model/BLOCK_2-1_BN_3/FusedBatchNormV3) shape:[120], type:INT32 RO 480 bytes, buffer: 138, data:[1883, 3889, -2416, -1082, -428, ...]\n",
      "  T#138(model/BLOCK_2-1_CONV_3/Conv2D) shape:[120, 1, 1, 240], type:INT8 RO 28800 bytes, buffer: 139, data:[., ., ., ., ., ...]\n",
      "  T#139(model/BLOCK_2-1_BN_1/FusedBatchNormV3) shape:[240], type:INT32 RO 960 bytes, buffer: 140, data:[8282, 10877, 12668, 9228, 12346, ...]\n",
      "  T#140(model/BLOCK_2-1_CONV_1/Conv2D) shape:[240, 3, 3, 60], type:INT8 RO 129600 bytes, buffer: 141, data:[., ., ', ., ., ...]\n",
      "  T#141(model/BLOCK_1-3_BN_3/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 142, data:[199, -649, -309, 1474, 159, ...]\n",
      "  T#142(model/BLOCK_1-3_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:INT8 RO 3600 bytes, buffer: 143, data:[., ., ., ., ., ...]\n",
      "  T#143(model/BLOCK_1-3_BN_1/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 144, data:[8772, 6210, 8018, -5468, 13215, ...]\n",
      "  T#144(model/BLOCK_1-3_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:INT8 RO 32400 bytes, buffer: 145, data:[\n",
      ", #, ., ., ), ...]\n",
      "  T#145(model/BLOCK_1-2_BN_3/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 146, data:[-1369, 2495, -4062, 4174, 1082, ...]\n",
      "  T#146(model/BLOCK_1-2_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:INT8 RO 3600 bytes, buffer: 147, data:[., ., ., ., ., ...]\n",
      "  T#147(model/BLOCK_1-2_BN_1/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 148, data:[-10989, -6367, 1151, 97, 4097, ...]\n",
      "  T#148(model/BLOCK_1-2_CONV_1/Conv2D) shape:[60, 3, 3, 60], type:INT8 RO 32400 bytes, buffer: 149, data:[., ., ., ., ., ...]\n",
      "  T#149(model/BLOCK_1-1_BN_3/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 150, data:[-781, -295, -1045, -847, 1161, ...]\n",
      "  T#150(model/BLOCK_1-1_CONV_3/Conv2D) shape:[60, 1, 1, 60], type:INT8 RO 3600 bytes, buffer: 151, data:[., ., K, &, ., ...]\n",
      "  T#151(model/BLOCK_1-1_BN_1/FusedBatchNormV3) shape:[60], type:INT32 RO 240 bytes, buffer: 152, data:[2453, 3517, 1547, 6589, 3246, ...]\n",
      "  T#152(model/BLOCK_1-1_CONV_1/Conv2D) shape:[60, 3, 3, 30], type:INT8 RO 16200 bytes, buffer: 153, data:[., ), ., ., ., ...]\n",
      "  T#153(model/pool_0_CONV/BiasAdd/ReadVariableOp) shape:[30], type:INT32 RO 120 bytes, buffer: 154, data:[275, -4, 2965, 181, -427, ...]\n",
      "  T#154(model/pool_0_CONV/Conv2D) shape:[30, 1, 1, 60], type:INT8 RO 1800 bytes, buffer: 155, data:[4, ., ., \n",
      ", ., ...]\n",
      "  T#155(model/BNORM_0/FusedBatchNormV3) shape:[30], type:INT32 RO 120 bytes, buffer: 156, data:[-55, 75, -18, 891, 8082, ...]\n",
      "  T#156(model/CONV_0/Conv2D) shape:[30, 4, 8, 1], type:INT8 RO 960 bytes, buffer: 157, data:[., ., ., ., ., ...]\n",
      "  T#157(model/BNORM_SPEC_NOQUANT/FusedBatchNormV31) shape:[1], type:INT8 RO 1 bytes, buffer: 158, data:[.]\n",
      "  T#158(model/BNORM_SPEC_NOQUANT/FusedBatchNormV3) shape:[1], type:INT8 RO 1 bytes, buffer: 30, data:[.]\n",
      "  T#159(stft/hann_window/sub_2;stft/hann_window/sub_2) shape:[512], type:INT8 RO 512 bytes, buffer: 160, data:[., ., ., ., ., ...]\n",
      "  T#160(tfl.quantize) shape_signature:[-1, 144000], type:INT8\n",
      "  T#161(Min;Min) shape_signature:[-1, 1], type:INT8\n",
      "  T#162(Sub;Sub) shape_signature:[-1, 144000], type:INT8\n",
      "  T#163(tfl.dequantize) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#164(Max;Max) shape_signature:[-1, 1], type:INT8\n",
      "  T#165(Max;Max1) shape_signature:[-1, 1], type:FLOAT32\n",
      "  T#166(truediv;truediv) shape_signature:[-1, 144000], type:FLOAT32\n",
      "  T#167(tfl.quantize1) shape_signature:[-1, 144000], type:INT8\n",
      "  T#168(stft/frame/Shape;stft/frame/Shape) shape:[2], type:INT32\n",
      "  T#169(stft/frame/split;stft/frame/split;stft/frame/split;stft/frame/split1;stft/frame/split;stft/frame/split2) shape:[1], type:INT32\n",
      "  T#170(stft/frame/split;stft/frame/split;stft/frame/split;stft/frame/split1;stft/frame/split;stft/frame/split21) shape:[1], type:INT32\n",
      "  T#171(stft/frame/split;stft/frame/split;stft/frame/split;stft/frame/split1;stft/frame/split;stft/frame/split22) shape:[0], type:INT32\n",
      "  T#172(stft/frame/Reshape;stft/frame/Reshape) shape:[], type:INT32\n",
      "  T#173(stft/frame/floordiv_3;stft/frame/floordiv_3) shape:[], type:INT32\n",
      "  T#174(stft/frame/concat_1/values_1;stft/frame/concat_1/values_1) shape:[2], type:INT32\n",
      "  T#175(stft/frame/mul;stft/frame/mul) shape:[], type:INT32\n",
      "  T#176(stft/frame/concat/values_1;stft/frame/concat/values_1) shape:[1], type:INT32\n",
      "  T#177(stft/frame/concat;stft/frame/concat) shape:[2], type:INT32\n",
      "  T#178(stft/frame/concat_1;stft/frame/concat_1) shape:[3], type:INT32\n",
      "  T#179(stft/frame/StridedSlice;stft/frame/StridedSlice) shape_signature:[-1, -1], type:INT8\n",
      "  T#180(stft/frame/Reshape_1;stft/frame/Reshape_1) shape_signature:[-1, -1, 8], type:INT8\n",
      "  T#181(stft/frame/sub_2;stft/frame/sub_2) shape:[], type:INT32\n",
      "  T#182(stft/frame/floordiv;stft/frame/floordiv) shape:[], type:INT32\n",
      "  T#183(stft/frame/add;stft/frame/add) shape:[], type:INT32\n",
      "  T#184(stft/frame/Maximum;stft/frame/Maximum) shape:[], type:INT32\n",
      "  T#185(stft/frame/Reshape_2/shape;stft/frame/Reshape_2/shape) shape:[2], type:INT32\n",
      "  T#186(stft/frame/concat_2/values_1;stft/frame/concat_2/values_1) shape:[2], type:INT32\n",
      "  T#187(stft/frame/concat_2;stft/frame/concat_2) shape:[3], type:INT32\n",
      "  T#188(stft/frame/range_1;stft/frame/range_1) shape_signature:[-1], type:INT32\n",
      "  T#189(stft/frame/mul_1;stft/frame/mul_1) shape_signature:[-1], type:INT32\n",
      "  T#190(stft/frame/Reshape_2;stft/frame/Reshape_2) shape_signature:[-1, 1], type:INT32\n",
      "  T#191(stft/frame/add_1;stft/frame/add_1) shape_signature:[-1, 64], type:INT32\n",
      "  T#192(stft/frame/GatherV2;stft/frame/GatherV2;model/BLOCK_3-1_SE_RESHAPE/Reshape/shape/1) shape_signature:[-1, -1, 64, 8], type:INT8\n",
      "  T#193(stft/frame/Reshape_4;stft/frame/Reshape_4) shape_signature:[-1, -1, 512], type:INT8\n",
      "  T#194(stft/mul;stft/mul) shape_signature:[-1, -1, 512], type:INT8\n",
      "  T#195(stft/rfft;stft/rfft2) shape_signature:[-1, -1, 1, 512], type:INT8\n",
      "  T#196(stft/rfft;stft/rfft21) shape_signature:[-1, -1, 1, 512], type:FLOAT32\n",
      "  T#197(stft/rfft;stft/rfft3) shape_signature:[-1, -1, 1, 257], type:COMPLEX64\n",
      "  T#198(stft/rfft;stft/rfft4) shape_signature:[-1, -1, 257], type:COMPLEX64\n",
      "  T#199(Cast;Cast) shape_signature:[-1, -1, 257], type:FLOAT32\n",
      "  T#200(tfl.quantize2) shape_signature:[-1, -1, 257], type:INT8\n",
      "  T#201(strided_slice;strided_slice) shape_signature:[-1, -1, 128], type:INT8\n",
      "  T#202(Pow;Pow;Pow/y;Pow/y) shape_signature:[-1, -1, 128], type:INT8\n",
      "  T#203(tfl.dequantize1) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#204(Pow_1;Pow_1) shape_signature:[-1, -1, 128], type:FLOAT32\n",
      "  T#205(tfl.quantize3) shape_signature:[-1, -1, 128], type:INT8\n",
      "  T#206(transpose;transpose) shape_signature:[-1, 128, -1], type:INT8\n",
      "  T#207(ExpandDims;ExpandDims) shape_signature:[-1, 128, -1, 1], type:INT8\n",
      "  T#208(model/BNORM_SPEC_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 128, -1, 1], type:INT8\n",
      "  T#209(model/BNORM_SPEC_NOQUANT/FusedBatchNormV33) shape_signature:[-1, 128, -1, 1], type:INT8\n",
      "  T#210(model/ACT_0/Relu;model/BNORM_0/FusedBatchNormV3;model/pool_0_CONV/Conv2D;model/CONV_0/Conv2D) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#211(model/pool_0_AVG/AvgPool) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#212(model/pool_0_MAX/MaxPool) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#213(model/pool_0_CONCAT/concat) shape_signature:[-1, 64, -1, 60], type:INT8\n",
      "  T#214(model/pool_0_CONV/BiasAdd;model/pool_0_CONV/Conv2D;model/pool_0_CONV/BiasAdd/ReadVariableOp) shape_signature:[-1, 64, -1, 30], type:INT8\n",
      "  T#215(model/BLOCK_1-1_BN_1/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-1_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#216(model/BLOCK_1-1_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#217(model/BLOCK_1-1_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#218(model/BLOCK_1-1_BN_3/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-1_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#219(model/BLOCK_1-2_BN_1/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-2_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#220(model/BLOCK_1-2_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#221(model/BLOCK_1-2_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#222(model/BLOCK_1-2_BN_3/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-2_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#223(model/BLOCK_1-2_ADD/add) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#224(model/BLOCK_1-3_BN_1/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D;model/BLOCK_1-3_CONV_1/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#225(model/BLOCK_1-3_ACT_1/Sigmoid) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#226(model/BLOCK_1-3_ACT_1/mul_1) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#227(model/BLOCK_1-3_BN_3/FusedBatchNormV3;model/BLOCK_1-3_CONV_3/Conv2D) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#228(model/BLOCK_1-3_ADD/add) shape_signature:[-1, 32, -1, 60], type:INT8\n",
      "  T#229(model/BLOCK_2-1_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D;model/BLOCK_2-1_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#230(model/BLOCK_2-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#231(model/BLOCK_2-1_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#232(model/BLOCK_2-1_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D;model/BLOCK_2-1_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#233(model/BLOCK_2-2_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D;model/BLOCK_2-2_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#234(model/BLOCK_2-2_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#235(model/BLOCK_2-2_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#236(model/BLOCK_2-2_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D;model/BLOCK_2-2_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#237(model/BLOCK_2-2_ADD/add) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#238(model/BLOCK_2-3_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D;model/BLOCK_2-3_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#239(model/BLOCK_2-3_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#240(model/BLOCK_2-3_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#241(model/BLOCK_2-3_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D;model/BLOCK_2-3_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#242(model/BLOCK_2-3_ADD/add) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#243(model/BLOCK_2-4_BN_1/FusedBatchNormV3;model/BLOCK_2-4_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#244(model/BLOCK_2-4_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#245(model/BLOCK_2-4_ACT_1/mul_1) shape_signature:[-1, 16, -1, 240], type:INT8\n",
      "  T#246(model/BLOCK_2-4_BN_3/FusedBatchNormV3;model/BLOCK_2-4_CONV_3/Conv2D) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#247(model/BLOCK_2-4_ADD/add) shape_signature:[-1, 16, -1, 120], type:INT8\n",
      "  T#248(model/BLOCK_3-1_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-1_CONV_1/Conv2D) shape_signature:[-1, 16, -1, 640], type:INT8\n",
      "  T#249(model/BLOCK_3-1_ACT_1/Sigmoid) shape_signature:[-1, 16, -1, 640], type:INT8\n",
      "  T#250(model/BLOCK_3-1_ACT_1/mul_1) shape_signature:[-1, 16, -1, 640], type:INT8\n",
      "  T#251(model/BLOCK_3-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-1_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#252(model/BLOCK_3-1_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#253(model/BLOCK_3-1_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#254(model/BLOCK_3-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#255(model/BLOCK_3-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#256(model/BLOCK_3-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#257(model/BLOCK_3-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#258(model/BLOCK_3-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#259(model/BLOCK_3-1_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#260(model/BLOCK_3-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#261(model/BLOCK_3-1_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#262(model/BLOCK_3-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#263(model/BLOCK_3-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#264(model/BLOCK_3-1_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#265(model/BLOCK_3-1_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-1_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#266(model/BLOCK_3-2_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-2_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#267(model/BLOCK_3-2_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#268(model/BLOCK_3-2_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#269(model/BLOCK_3-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-2_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#270(model/BLOCK_3-2_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#271(model/BLOCK_3-2_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#272(model/BLOCK_3-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#273(model/BLOCK_3-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#274(model/BLOCK_3-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#275(model/BLOCK_3-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#276(model/BLOCK_3-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#277(model/BLOCK_3-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#278(model/BLOCK_3-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#279(model/BLOCK_3-2_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#280(model/BLOCK_3-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#281(model/BLOCK_3-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#282(model/BLOCK_3-2_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#283(model/BLOCK_3-2_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-2_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#284(model/BLOCK_3-2_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#285(model/BLOCK_3-3_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-3_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#286(model/BLOCK_3-3_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#287(model/BLOCK_3-3_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#288(model/BLOCK_3-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-3_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#289(model/BLOCK_3-3_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#290(model/BLOCK_3-3_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#291(model/BLOCK_3-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#292(model/BLOCK_3-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#293(model/BLOCK_3-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#294(model/BLOCK_3-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#295(model/BLOCK_3-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#296(model/BLOCK_3-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#297(model/BLOCK_3-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#298(model/BLOCK_3-3_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#299(model/BLOCK_3-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#300(model/BLOCK_3-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#301(model/BLOCK_3-3_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#302(model/BLOCK_3-3_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-3_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#303(model/BLOCK_3-3_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#304(model/BLOCK_3-4_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-4_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#305(model/BLOCK_3-4_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#306(model/BLOCK_3-4_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#307(model/BLOCK_3-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-4_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#308(model/BLOCK_3-4_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#309(model/BLOCK_3-4_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#310(model/BLOCK_3-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#311(model/BLOCK_3-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#312(model/BLOCK_3-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#313(model/BLOCK_3-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#314(model/BLOCK_3-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#315(model/BLOCK_3-4_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#316(model/BLOCK_3-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#317(model/BLOCK_3-4_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#318(model/BLOCK_3-4_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#319(model/BLOCK_3-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#320(model/BLOCK_3-4_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#321(model/BLOCK_3-4_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D;model/BLOCK_3-4_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#322(model/BLOCK_3-4_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#323(model/BLOCK_3-5_BN_1/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-5_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#324(model/BLOCK_3-5_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#325(model/BLOCK_3-5_ACT_1/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#326(model/BLOCK_3-5_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_3-5_SE_CONV_2/Conv2D;model/BLOCK_3-5_CONV_2/depthwise) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#327(model/BLOCK_3-5_ACT_2/Sigmoid) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#328(model/BLOCK_3-5_ACT_2/mul_1) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#329(model/BLOCK_3-5_SE_AVG_POOL_1/Mean) shape_signature:[-1, 640], type:INT8\n",
      "  T#330(model/BLOCK_3-5_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#331(model/BLOCK_3-5_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#332(model/BLOCK_3-5_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#333(model/BLOCK_3-5_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#334(model/BLOCK_3-5_SE_CONV_1/Conv2D21) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#335(model/BLOCK_3-5_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#336(model/BLOCK_3-5_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 40], type:INT8\n",
      "  T#337(model/BLOCK_3-5_SE_CONV_2/Conv2D21) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#338(model/BLOCK_3-5_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 640], type:INT8\n",
      "  T#339(model/BLOCK_3-5_MULTIPLY/mul) shape_signature:[-1, 8, -1, 640], type:INT8\n",
      "  T#340(model/BLOCK_3-5_BN_3/FusedBatchNormV3;model/BLOCK_3-5_CONV_3/Conv2D) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#341(model/BLOCK_3-5_ADD/add) shape_signature:[-1, 8, -1, 160], type:INT8\n",
      "  T#342(model/BLOCK_4-1_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-1_CONV_1/Conv2D) shape_signature:[-1, 8, -1, 1120], type:INT8\n",
      "  T#343(model/BLOCK_4-1_ACT_1/Sigmoid) shape_signature:[-1, 8, -1, 1120], type:INT8\n",
      "  T#344(model/BLOCK_4-1_ACT_1/mul_1) shape_signature:[-1, 8, -1, 1120], type:INT8\n",
      "  T#345(model/BLOCK_4-1_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-1_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#346(model/BLOCK_4-1_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#347(model/BLOCK_4-1_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#348(model/BLOCK_4-1_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#349(model/BLOCK_4-1_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#350(model/BLOCK_4-1_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#351(model/BLOCK_4-1_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#352(model/BLOCK_4-1_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#353(model/BLOCK_4-1_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#354(model/BLOCK_4-1_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#355(model/BLOCK_4-1_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#356(model/BLOCK_4-1_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#357(model/BLOCK_4-1_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#358(model/BLOCK_4-1_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#359(model/BLOCK_4-1_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D;model/BLOCK_4-1_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#360(model/BLOCK_4-2_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-2_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#361(model/BLOCK_4-2_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#362(model/BLOCK_4-2_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#363(model/BLOCK_4-2_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-2_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#364(model/BLOCK_4-2_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#365(model/BLOCK_4-2_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#366(model/BLOCK_4-2_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#367(model/BLOCK_4-2_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#368(model/BLOCK_4-2_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#369(model/BLOCK_4-2_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#370(model/BLOCK_4-2_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#371(model/BLOCK_4-2_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#372(model/BLOCK_4-2_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#373(model/BLOCK_4-2_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#374(model/BLOCK_4-2_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#375(model/BLOCK_4-2_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#376(model/BLOCK_4-2_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#377(model/BLOCK_4-2_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D;model/BLOCK_4-2_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#378(model/BLOCK_4-2_ADD/add) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#379(model/BLOCK_4-3_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-3_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#380(model/BLOCK_4-3_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#381(model/BLOCK_4-3_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#382(model/BLOCK_4-3_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-3_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#383(model/BLOCK_4-3_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#384(model/BLOCK_4-3_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#385(model/BLOCK_4-3_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#386(model/BLOCK_4-3_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#387(model/BLOCK_4-3_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#388(model/BLOCK_4-3_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#389(model/BLOCK_4-3_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#390(model/BLOCK_4-3_SE_CONV_1/Conv2D1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#391(model/BLOCK_4-3_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#392(model/BLOCK_4-3_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#393(model/BLOCK_4-3_SE_CONV_2/Conv2D1) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#394(model/BLOCK_4-3_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#395(model/BLOCK_4-3_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#396(model/BLOCK_4-3_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D;model/BLOCK_4-3_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#397(model/BLOCK_4-3_ADD/add) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#398(model/BLOCK_4-4_BN_1/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-4_CONV_1/Conv2D) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#399(model/BLOCK_4-4_ACT_1/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#400(model/BLOCK_4-4_ACT_1/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#401(model/BLOCK_4-4_BN_2_NOQUANT/FusedBatchNormV3;model/BLOCK_4-4_SE_CONV_2/Conv2D;model/BLOCK_4-4_CONV_2/depthwise) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#402(model/BLOCK_4-4_ACT_2/Sigmoid) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#403(model/BLOCK_4-4_ACT_2/mul_1) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#404(model/BLOCK_4-4_SE_AVG_POOL_1/Mean) shape_signature:[-1, 1120], type:INT8\n",
      "  T#405(model/BLOCK_4-4_SE_RESHAPE/Shape) shape:[2], type:INT32\n",
      "  T#406(model/BLOCK_4-4_SE_RESHAPE/strided_slice) shape:[], type:INT32\n",
      "  T#407(model/BLOCK_4-4_SE_RESHAPE/Reshape/shape) shape:[4], type:INT32\n",
      "  T#408(model/BLOCK_4-4_SE_RESHAPE/Reshape) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#409(model/BLOCK_4-4_SE_CONV_1/Conv2D21) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#410(model/BLOCK_4-4_SE_CONV_1/Sigmoid) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#411(model/BLOCK_4-4_SE_CONV_1/mul_1) shape_signature:[-1, 1, 1, 70], type:INT8\n",
      "  T#412(model/BLOCK_4-4_SE_CONV_2/Conv2D21) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#413(model/BLOCK_4-4_SE_CONV_2/Sigmoid) shape_signature:[-1, 1, 1, 1120], type:INT8\n",
      "  T#414(model/BLOCK_4-4_MULTIPLY/mul) shape_signature:[-1, 4, -1, 1120], type:INT8\n",
      "  T#415(model/BLOCK_4-4_BN_3/FusedBatchNormV3;model/BLOCK_4-4_CONV_3/Conv2D) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#416(model/BLOCK_4-4_ADD/add) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#417(model/BNORM_POST_NOQUANT/FusedBatchNormV32) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#418(model/ACT_POST/Relu;model/BNORM_POST_NOQUANT/FusedBatchNormV3) shape_signature:[-1, 4, -1, 280], type:INT8\n",
      "  T#419(model/POST_ACT_1/Relu;model/POST_BN_1/FusedBatchNormV3;model/POST_CONV_1/Conv2D) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#420(Max;Max11) shape_signature:[-1, 1, 1, 420], type:INT8\n",
      "  T#421(Max_1;Max_1) shape_signature:[-1, 420], type:INT8\n",
      "  T#422(sub;sub) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#423(mul;mul) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#424(Exp;Exp) shape_signature:[-1, 2, -1, 420], type:INT8\n",
      "  T#425(Mean;Mean) shape_signature:[-1, 420], type:INT8\n",
      "  T#426(tfl.dequantize2) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#427(Log;Log) shape_signature:[-1, 420], type:FLOAT32\n",
      "  T#428(tfl.quantize4) shape_signature:[-1, 420], type:INT8\n",
      "  T#429(truediv;truediv;ReadVariableOp;ReadVariableOp1) shape_signature:[-1, 420], type:INT8\n",
      "  T#430(add;add) shape_signature:[-1, 420], type:INT8\n",
      "  T#431(model/dense/MatMul;model/dense/Relu;model/dense/BiasAdd) shape_signature:[-1, 3], type:INT8\n",
      "  T#432(model/dense_1/MatMul;model/dense_1/BiasAdd) shape_signature:[-1, 2], type:INT8\n",
      "  T#433(StatefulPartitionedCall:01) shape_signature:[-1, 2], type:INT8\n",
      "  T#434(StatefulPartitionedCall:0) shape_signature:[-1, 2], type:FLOAT32\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Your TFLite model has '1' signature_def(s).\n",
      "\n",
      "Signature#0 key: 'serving_default'\n",
      "- Subgraph: Subgraph#0\n",
      "- Inputs: \n",
      "    'INPUT' : T#0\n",
      "- Outputs: \n",
      "    'activation' : T#434\n",
      "\n",
      "---------------------------------------------------------------\n",
      "              Model size:    7331280 bytes\n",
      "    Non-data buffer size:     742224 bytes (10.12 %)\n",
      "  Total data buffer size:    6589056 bytes (89.88 %)\n",
      "    (Zero value buffers):       7504 bytes (00.10 %)\n",
      "\n",
      "* Buffers of TFLite model are mostly used for constant tensors.\n",
      "  And zero value buffers are buffers filled with zeros.\n",
      "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
      "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(model_path=tflite_model_INT8_path,\n",
    "                                      model_content=None,\n",
    "                                      gpu_compatibility=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b83c64ef-1ac5-4167-b9a4-00ac254e6967",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0001_703520.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.920_0057_645986.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.930_0263_741788.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.950_0002_645965.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/0.960_0024_103739801.wav\n",
      "Processed 500 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_-X5Ay0Wuew0_20.wav\n",
      "Processed 600 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0001_4TQzd0lB8IQ_30.wav\n",
      "Processed 700 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0002_1MF9_29YUZU_10.wav\n",
      "Processed 800 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_-8S_tLKfeJg_200.wav\n",
      "Processed 900 files. Currently processing file: /home/jovyan/cut-data/testing/non_target/1.000_0003_2hBkeX3k48M_180.wav\n",
      "Processed 0 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.540_0001_200624_1647_11.wav\n",
      "Processed 100 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.920_0282_R21_2022_02_25_08_07_04.wav\n",
      "Processed 200 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.940_0009_784426.wav\n",
      "Processed 300 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.950_0034_470177.wav\n",
      "Processed 400 files. Currently processing file: /home/jovyan/cut-data/testing/target/0.970_0015_419564251.wav\n",
      "Balance the test data...\n",
      "Balanced test data:\n",
      "balanced_x_test shape: (916,)\n",
      "balanced_y_test shape: (916, 2)\n",
      "balanced_file_paths_test shape: (916,)\n",
      "...Done. Loaded 916 test samples and 916 labels.\n",
      "Processing batch 1 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.920_0057_141420.wav\n",
      "Entry: 100\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.99609375 0.0703125 ]]\n",
      "Processing batch 11 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.930_0186_741788.wav\n",
      "Entry: 200\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.99609375 0.05859375]]\n",
      "Processing batch 21 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.950_0002_595388.wav\n",
      "Entry: 300\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.99609375 0.05859375]]\n",
      "Processing batch 31 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/0.960_0018_782604.wav\n",
      "Entry: 400\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.9765625  0.23828125]]\n",
      "Processing batch 41 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0001_-WmL01c-4ZE_20.wav\n",
      "Entry: 500\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.72265625 0.6328125 ]]\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0001_4M0njWKFsME_30.wav\n",
      "Entry: 600\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.7109375 0.6640625]]\n",
      "Processing batch 51 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0002_1C6VhOCffIE_60.wav\n",
      "Entry: 700\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.9765625 0.1640625]]\n",
      "Processing batch 61 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0003_-7z662AsuTE_380.wav\n",
      "Entry: 800\n",
      "True Label: 1\n",
      "Predicted Label: 1\n",
      "Output Tensor: [[0.52734375 0.78125   ]]\n",
      "Processing batch 71 of 77\n",
      "Input File Path: /home/jovyan/cut-data/testing/non_target/1.000_0003_2hBVVym00rc_30.wav\n",
      "Entry: 900\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "Output Tensor: [[0.9765625  0.17578125]]\n",
      "Accuracy: 55.35%\n",
      "Recall: 110.70%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[458   0]\n",
      " [409  49]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_target       0.53      1.00      0.69       458\n",
      "      target       1.00      0.11      0.19       458\n",
      "\n",
      "    accuracy                           0.55       916\n",
      "   macro avg       0.76      0.55      0.44       916\n",
      "weighted avg       0.76      0.55      0.44       916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import evaluateTFliteModel\n",
    "\n",
    "test_data_path = \"/home/jovyan/cut-data/testing/\"\n",
    "batch_size = 12\n",
    "\n",
    "evaluateTFliteModel.evaluate_tflite_model(tflite_model_INT8_path, test_data_path, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c5629d-65ce-420c-a871-19d866090919",
   "metadata": {},
   "source": [
    "### Partial integer 8-bit quantization of weights and activations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae65add-efbf-4a74-916c-b2b1202693d3",
   "metadata": {},
   "source": [
    "#### this is not possible with the TF Lite converter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
